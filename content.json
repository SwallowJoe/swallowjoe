{"meta":{"title":"SwallowJoe的博客","subtitle":"Be a real go-getter,<br>NEVER SETTLE!","description":"君子知命不惧，日日自新","author":"SwallowJoe","url":"https://swallowjoe.github.io","root":"/"},"pages":[{"title":"","date":"2022-02-26T09:28:27.221Z","updated":"2022-02-26T09:28:27.221Z","comments":true,"path":"404/index.html","permalink":"https://swallowjoe.github.io/404/index.html","excerpt":"","text":"layout: falsecomments: falsetitle: 404permalink: &#x2F;404 幽灵404页面 html,body{background:#28254C;font-family:'Ubuntu';}*{box-sizing:border-box;}.box{width:350px;height:100%;max-height:600px;min-height:450px;background:#332F63;border-radius:20px;position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);padding:30px 50px;}.box .box__ghost{padding:15px 25px 25px;position:absolute;left:50%;top:30%;transform:translate(-50%,-30%);}.box .box__ghost .symbol:nth-child(1){opacity:.2;animation:shine 4s ease-in-out 3s infinite;}.box .box__ghost .symbol:nth-child(1):before,.box .box__ghost .symbol:nth-child(1):after{content:'';width:12px;height:4px;background:#fff;position:absolute;border-radius:5px;bottom:65px;left:0;}.box .box__ghost .symbol:nth-child(1):before{transform:rotate(45deg);}.box .box__ghost .symbol:nth-child(1):after{transform:rotate(-45deg);}.box .box__ghost .symbol:nth-child(2){position:absolute;left:-5px;top:30px;height:18px;width:18px;border:4px solid;border-radius:50%;border-color:#fff;opacity:.2;animation:shine 4s ease-in-out 1.3s infinite;}.box .box__ghost .symbol:nth-child(3){opacity:.2;animation:shine 3s ease-in-out .5s infinite;}.box .box__ghost .symbol:nth-child(3):before,.box .box__ghost .symbol:nth-child(3):after{content:'';width:12px;height:4px;background:#fff;position:absolute;border-radius:5px;top:5px;left:40px;}.box .box__ghost .symbol:nth-child(3):before{transform:rotate(90deg);}.box .box__ghost .symbol:nth-child(3):after{transform:rotate(180deg);}.box .box__ghost .symbol:nth-child(4){opacity:.2;animation:shine 6s ease-in-out 1.6s infinite;}.box .box__ghost .symbol:nth-child(4):before,.box .box__ghost .symbol:nth-child(4):after{content:'';width:15px;height:4px;background:#fff;position:absolute;border-radius:5px;top:10px;right:30px;}.box .box__ghost .symbol:nth-child(4):before{transform:rotate(45deg);}.box .box__ghost .symbol:nth-child(4):after{transform:rotate(-45deg);}.box .box__ghost .symbol:nth-child(5){position:absolute;right:5px;top:40px;height:12px;width:12px;border:3px solid;border-radius:50%;border-color:#fff;opacity:.2;animation:shine 1.7s ease-in-out 7s infinite;}.box .box__ghost .symbol:nth-child(6){opacity:.2;animation:shine 2s ease-in-out 6s infinite;}.box .box__ghost .symbol:nth-child(6):before,.box .box__ghost .symbol:nth-child(6):after{content:'';width:15px;height:4px;background:#fff;position:absolute;border-radius:5px;bottom:65px;right:-5px;}.box .box__ghost .symbol:nth-child(6):before{transform:rotate(90deg);}.box .box__ghost .symbol:nth-child(6):after{transform:rotate(180deg);}.box .box__ghost .box__ghost-container{background:#fff;width:100px;height:100px;border-radius:100px 100px 0 0;position:relative;margin:0 auto;animation:upndown 3s ease-in-out infinite;}.box .box__ghost .box__ghost-container .box__ghost-eyes{position:absolute;left:50%;top:45%;height:12px;width:70px;}.box .box__ghost .box__ghost-container .box__ghost-eyes .box__eye-left{width:12px;height:12px;background:#332F63;border-radius:50%;margin:0 10px;position:absolute;left:0;}.box .box__ghost .box__ghost-container .box__ghost-eyes .box__eye-right{width:12px;height:12px;background:#332F63;border-radius:50%;margin:0 10px;position:absolute;right:0;}.box .box__ghost .box__ghost-container .box__ghost-bottom{display:flex;position:absolute;top:100%;left:0;right:0;}.box .box__ghost .box__ghost-container .box__ghost-bottom div{flex-grow:1;position:relative;top:-10px;height:20px;border-radius:100%;background-color:#fff;}.box .box__ghost .box__ghost-container .box__ghost-bottom div:nth-child(2n){top:-12px;margin:0 -0px;border-top:15px solid #332F63;background:transparent;}.box .box__ghost .box__ghost-shadow{height:20px;box-shadow:0 50px 15px 5px #3B3769;border-radius:50%;margin:0 auto;animation:smallnbig 3s ease-in-out infinite;}.box .box__description{position:absolute;bottom:30px;left:50%;transform:translateX(-50%);}.box .box__description .box__description-container{color:#fff;text-align:center;width:200px;font-size:16px;margin:0 auto;}.box .box__description .box__description-container .box__description-title{font-size:24px;letter-spacing:.5px;}.box .box__description .box__description-container .box__description-text{color:#8C8AA7;line-height:20px;margin-top:20px;}.box .box__description .box__button{display:block;position:relative;background:#FF5E65;border:1px solid transparent;border-radius:50px;height:50px;text-align:center;text-decoration:none;color:#fff;line-height:50px;font-size:18px;padding:0 70px;white-space:nowrap;margin-top:25px;transition:background .5s ease;overflow:hidden;}.box .box__description .box__button:before{content:'';position:absolute;width:20px;height:100px;background:#fff;bottom:-25px;left:0;border:2px solid #fff;transform:translateX(-50px) rotate(45deg);transition:transform .5s ease;}.box .box__description .box__button:hover{background:transparent;border-color:#fff;}.box .box__description .box__button:hover:before{transform:translateX(250px) rotate(45deg);}@keyframes upndown{0%{transform:translateY(5px);}50%{transform:translateY(15px);}100%{transform:translateY(5px);}}@keyframes smallnbig{0%{width:90px;}50%{width:100px;}100%{width:90px;}}@keyframes shine{0%{opacity:.2;}25%{opacity:.1;}50%{opacity:.2;}100%{opacity:.2;}} 404错误！ 看来我们找不到你要找的那一页 返回 var pageX =$(document).width();var pageY =$(document).height();var mouseY=0;var mouseX=0;$(document).mousemove(function(event ) {mouseY =event.pageY;yAxis =(pageY/2-mouseY)/pageY*300;mouseX =event.pageX / -pageX;xAxis =-mouseX *100 - 100;$('.box__ghost-eyes').css({'transform':'translate('+ xAxis +'%,-'+ yAxis +'%)' });});"},{"title":"categories","date":"2022-02-26T17:54:25.000Z","updated":"2022-02-26T17:55:06.933Z","comments":true,"path":"categories/index.html","permalink":"https://swallowjoe.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-02-26T17:54:37.000Z","updated":"2022-02-26T17:55:15.037Z","comments":true,"path":"tags/index.html","permalink":"https://swallowjoe.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"App申请帧率(4)--SF切换帧率","slug":"App申请帧率-4-SF切换帧率","date":"2022-02-26T19:54:03.000Z","updated":"2022-02-26T20:00:41.253Z","comments":true,"path":"2022/02/27/App申请帧率-4-SF切换帧率/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/App%E7%94%B3%E8%AF%B7%E5%B8%A7%E7%8E%87-4-SF%E5%88%87%E6%8D%A2%E5%B8%A7%E7%8E%87/","excerpt":"以下分析基于Android R. 简述上一章我们分析了SurfaceFlinger是如何根据Framework传入的帧率参数选择合适帧率的。 接来下我们详细看看SurfaceFlinger是如何通知硬件切换帧率的。","text":"以下分析基于Android R. 简述上一章我们分析了SurfaceFlinger是如何根据Framework传入的帧率参数选择合适帧率的。 接来下我们详细看看SurfaceFlinger是如何通知硬件切换帧率的。 一. SurfaceFlinger接受帧率变化接上一章，从 SurfaceFlinger::setDesiredActiveConfig 开始. 这里的ActiveConfigInfo就是SurfaceFlinger根据Framework传入的帧率范围以及各个Layer投票计算的最终帧率信息。 12345678struct ActiveConfigInfo &#123; HwcConfigIndexType configId; Scheduler::ConfigEvent event = Scheduler::ConfigEvent::None; bool operator!=(const ActiveConfigInfo&amp; other) const &#123; return configId != other.configId || event != other.event; &#125; &#125;; 1.1 SurfaceFlinger.setDesiredActiveConfig1234567891011121314151617181920212223242526272829303132333435363738394041void SurfaceFlinger::setDesiredActiveConfig(const ActiveConfigInfo&amp; info) &#123; ATRACE_CALL(); auto&amp; refreshRate = mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(info.configId); mVsyncPeriod = refreshRate.getVsyncPeriod(); ALOGV(&quot;setDesiredActiveConfig(%s)&quot;, refreshRate.getName().c_str()); std::lock_guard&lt;std::mutex&gt; lock(mActiveConfigLock); if (mDesiredActiveConfigChanged) &#123; // 如果帧率切换正在发生，缓存此次帧率切换 const Scheduler::ConfigEvent prevConfig = mDesiredActiveConfig.event; mDesiredActiveConfig = info; mDesiredActiveConfig.event = mDesiredActiveConfig.event | prevConfig; &#125; else &#123; // 如果当前帧率已经是请求的帧率了，直接返回 const auto display = getDefaultDisplayDeviceLocked(); if (!display || display-&gt;getActiveConfig() == refreshRate.getConfigId()) &#123; return; &#125; // 标记正在做帧率切换 mDesiredActiveConfigChanged = true; // 存储即将切换的帧率配置信息 mDesiredActiveConfig = info; // 1.2 触发HWC刷新而不重置空闲计时器。 repaintEverythingForHWC(); // 1.3 现在开始接收vsync样本，这可以检测到硬件周期切换。 mScheduler-&gt;resyncToHardwareVsync(true, refreshRate.getVsyncPeriod()); // 1.4 调用onRefreshRateChangeCompleted, 通知更新偏移量 mVSyncModulator-&gt;onRefreshRateChangeInitiated(); // 保存即将更新的Fps mPhaseConfiguration-&gt;setRefreshRateFps(refreshRate.getFps()); // 1.5 再次更新偏移量, 不过这一次是根据即将更新的Fps拿到的固定偏移量 mVSyncModulator-&gt;setPhaseOffsets(mPhaseConfiguration-&gt;getCurrentOffsets()); mScheduler-&gt;setConfigChangePending(true); &#125; if (mRefreshRateOverlay) &#123; mRefreshRateOverlay-&gt;changeRefreshRate(refreshRate); &#125;&#125; 1.2 SurfaceFlinger.repaintEverythingForHWC12345678void SurfaceFlinger::repaintEverythingForHWC() &#123; // 标记全部重绘制 mRepaintEverything = true; // 通知Power模组, Display将更新，OEM厂商自行实现这个标准接口 mPowerAdvisor.notifyDisplayUpdateImminent(); // EventThread请求下一帧Vsync mEventQueue-&gt;invalidate();&#125; 1.3 Scheduler.resyncToHardwareVsync123456789101112131415161718void Scheduler::resyncToHardwareVsync(bool makeAvailable, nsecs_t period) &#123; &#123; std::lock_guard&lt;std::mutex&gt; lock(mHWVsyncLock); if (makeAvailable) &#123; mHWVsyncAvailable = makeAvailable; &#125; else if (!mHWVsyncAvailable) &#123; // 硬件Vsync被禁止，直接返回 return; &#125; &#125; if (period &lt;= 0) &#123; // 参数不合法 return; &#125; // 通知到软件Vsync产生模块，更新Vsync周期 setVsyncPeriod(period);&#125; 1.3.1 Scheduler.setVsyncPeriod123456789101112void Scheduler::setVsyncPeriod(nsecs_t period) &#123; std::lock_guard&lt;std::mutex&gt; lock(mHWVsyncLock); // 1.3.2 更新软件Vsync周期 mPrimaryDispSync-&gt;setPeriod(period); if (!mPrimaryHWVsyncEnabled) &#123; // 硬件Vsync关闭的情况下, 直接更改软件vsync周期，这里我们加上是开启的 mPrimaryDispSync-&gt;beginResync(); mEventControlThread-&gt;setVsyncEnabled(true); mPrimaryHWVsyncEnabled = true; &#125;&#125; 现在R上软件Vsync产生更改了架构，由Q上DispSync改成VSyncReactor, 不过原理不变就不分析了, 具体可以参考文章-SurfaceFlinger(2)–DispSync。 可以通过将属性debug.sf.vsync_reactor置为false后重启，切回Q上的DispSync机制 1.3.2 VSyncReactor.setPeriod1234567891011121314void VSyncReactor::setPeriod(nsecs_t period) &#123; ATRACE_INT64(&quot;VSR-setPeriod&quot;, period); std::lock_guard lk(mMutex); mLastHwVsync.reset(); // mSupportKernelIdleTimer的是由属性控制的，Google源码中默认是true的 // PRODUCT_DEFAULT_PROPERTY_OVERRIDES += ro.surface_flinger.support_kernel_idle_timer=true if (!mSupportKernelIdleTimer &amp;&amp; period == getPeriod()) &#123; endPeriodTransition(); &#125; else &#123; // 开始更新 startPeriodTransition(period); &#125;&#125; 1.3.3 VSyncReactor.startPeriodTransition12345678910111213141516171819void VSyncReactor::startPeriodTransition(nsecs_t newPeriod) &#123; // 标记各个变量，并记录待更新的Fps对应一帧的刷新时长 mPeriodConfirmationInProgress = true; mPeriodTransitioningTo = newPeriod; mMoreSamplesNeeded = true; // 忽略当前Fence，其实就是清空mUnfiredFences中的fence setIgnorePresentFencesInternal(true);&#125;void VSyncReactor::setIgnorePresentFencesInternal(bool ignoration) &#123; mInternalIgnoreFences = ignoration; updateIgnorePresentFencesInternal();&#125;void VSyncReactor::updateIgnorePresentFencesInternal() &#123; if (mExternalIgnoreFences || mInternalIgnoreFences) &#123; mUnfiredFences.clear(); &#125;&#125; 1.4 VSyncModulator.onRefreshRateChangeInitiated12345678910111213141516171819202122232425262728293031323334353637void VSyncModulator::onRefreshRateChangeInitiated() &#123; if (mRefreshRateChangePending) &#123; return; &#125; mRefreshRateChangePending = true; updateOffsets();&#125;void VSyncModulator::updateOffsets() &#123; std::lock_guard&lt;std::mutex&gt; lock(mMutex); updateOffsetsLocked();&#125;void VSyncModulator::updateOffsetsLocked() &#123; // 1.4.1 选择偏移量 const Offsets&amp; offsets = getNextOffsets(); // 1.4.2 更新对应的偏移量，这个mPhaseOffsetControl其实就是Scheduler mPhaseOffsetControl.setPhaseOffset(mSfConnectionHandle, offsets.sf); mPhaseOffsetControl.setPhaseOffset(mAppConnectionHandle, offsets.app); // 更新偏移量 mOffsets = offsets; // 这个trace的debug开关是由属性: debug.sf.vsync_trace_detailed_info 0/1 决定的 if (!mTraceDetailedInfo) &#123; return; &#125; const bool isEarly = &amp;offsets == &amp;mOffsetsConfig.early; const bool isEarlyGl = &amp;offsets == &amp;mOffsetsConfig.earlyGl; const bool isLate = &amp;offsets == &amp;mOffsetsConfig.late; ATRACE_INT(&quot;Vsync-EarlyOffsetsOn&quot;, isEarly); ATRACE_INT(&quot;Vsync-EarlyGLOffsetsOn&quot;, isEarlyGl); ATRACE_INT(&quot;Vsync-LateOffsetsOn&quot;, isLate);&#125; 1.4.1 VSyncModulator.getNextOffsets1234567891011const VSyncModulator::Offsets&amp; VSyncModulator::getNextOffsets() const &#123; // 如果正在进行刷新率更改，或者最近开始了一个事务，则使用early偏移量。 if (mExplicitEarlyWakeup || mTransactionStart == Scheduler::TransactionStart::EarlyEnd || mRemainingEarlyFrameCount &gt; 0 || mRefreshRateChangePending) &#123; return mOffsetsConfig.early; &#125; else if (mRemainingRenderEngineUsageCount &gt; 0) &#123; return mOffsetsConfig.earlyGl; &#125; else &#123; return mOffsetsConfig.late; &#125;&#125; 1.4.2 DispSyncSource.setPhaseOffset12345678910111213141516171819202122232425void DispSyncSource::setPhaseOffset(nsecs_t phaseOffset) &#123; std::lock_guard lock(mVsyncMutex); const nsecs_t period = mDispSync-&gt;getPeriod(); // 正常来讲偏移量在 [-period, period) 之间 const int numPeriods = phaseOffset / period; phaseOffset -= numPeriods * period; if (mPhaseOffset == phaseOffset) &#123; return; &#125; mPhaseOffset = phaseOffset; // 尚未使能，就不需要通知给各个listener if (!mEnabled) &#123; return; &#125; // 1.4.3 DispSyncSource是继承了DispSync::Callback的 status_t err = mDispSync-&gt;changePhaseOffset(static_cast&lt;DispSync::Callback*&gt;(this), mPhaseOffset); if (err != NO_ERROR) &#123; ALOGE(&quot;error changing vsync offset: %s (%d)&quot;, strerror(-err), err); &#125;&#125; 1.4.3 VSyncReactor.changePhaseOffset123456789status_t VSyncReactor::changePhaseOffset(DispSync::Callback* callback, nsecs_t phase) &#123; std::lock_guard&lt;std::mutex&gt; lk(mMutex); auto const it = mCallbacks.find(callback); LOG_ALWAYS_FATAL_IF(it == mCallbacks.end(), &quot;callback was %p not registered&quot;, callback); // 调用start，更新VSyncDispatchTimerQueue中相关信息 it-&gt;second-&gt;start(phase); return NO_ERROR;&#125; 1.4.4 VSyncReactor.CallbackRepeater.start123456789void start(nsecs_t offset) &#123; std::lock_guard&lt;std::mutex&gt; lk(mMutex); mStopped = false; mOffset = offset; auto const schedule_result = mRegistration.schedule(calculateWorkload(), mLastCallTime); LOG_ALWAYS_FATAL_IF((schedule_result != ScheduleResult::Scheduled), &quot;Error scheduling callback: rc %X&quot;, schedule_result);&#125; 1.4.5 VSyncCallbackRegistration.schedule1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465ScheduleResult VSyncCallbackRegistration::schedule(nsecs_t workDuration, nsecs_t earliestVsync) &#123; if (!mValidToken) &#123; return ScheduleResult::Error; &#125; return mDispatch.get().schedule(mToken, workDuration, earliestVsync);&#125;ScheduleResult VSyncDispatchTimerQueue::schedule(CallbackToken token, nsecs_t workDuration, nsecs_t earliestVsync) &#123; auto result = ScheduleResult::Error; &#123; std::lock_guard&lt;decltype(mMutex)&gt; lk(mMutex); auto it = mCallbacks.find(token); if (it == mCallbacks.end()) &#123; return result; &#125; auto&amp; callback = it-&gt;second; auto const now = mTimeKeeper-&gt;now(); // 如果计时器线程即将运行，通过回调计时器重新计算应用此工作更新，以避免取消即将触发的回调。 auto const rearmImminent = now &gt; mIntendedWakeupTime; if (CC_UNLIKELY(rearmImminent)) &#123; callback-&gt;addPendingWorkloadUpdate(workDuration, earliestVsync); return ScheduleResult::Scheduled; &#125; result = callback-&gt;schedule(workDuration, earliestVsync, mTracker, now); if (result == ScheduleResult::CannotSchedule) &#123; return result; &#125; if (callback-&gt;wakeupTime() &lt; mIntendedWakeupTime - mTimerSlack) &#123; rearmTimerSkippingUpdateFor(now, it); &#125; &#125; return result;&#125;ScheduleResult VSyncDispatchTimerQueueEntry::schedule(nsecs_t workDuration, nsecs_t earliestVsync, VSyncTracker&amp; tracker, nsecs_t now) &#123; auto nextVsyncTime = tracker.nextAnticipatedVSyncTimeFrom(std::max(earliestVsync, now + workDuration)); bool const wouldSkipAVsyncTarget = mArmedInfo &amp;&amp; (nextVsyncTime &gt; (mArmedInfo-&gt;mActualVsyncTime + mMinVsyncDistance)); if (wouldSkipAVsyncTarget) &#123; return ScheduleResult::Scheduled; &#125; bool const alreadyDispatchedForVsync = mLastDispatchTime &amp;&amp; ((*mLastDispatchTime + mMinVsyncDistance) &gt;= nextVsyncTime &amp;&amp; (*mLastDispatchTime - mMinVsyncDistance) &lt;= nextVsyncTime); if (alreadyDispatchedForVsync) &#123; nextVsyncTime = tracker.nextAnticipatedVSyncTimeFrom(*mLastDispatchTime + mMinVsyncDistance); &#125; auto const nextWakeupTime = nextVsyncTime - workDuration; mWorkDuration = workDuration; mEarliestVsync = earliestVsync; mArmedInfo = &#123;nextWakeupTime, nextVsyncTime&#125;; return ScheduleResult::Scheduled;&#125; 1.5 VSyncModulator.setPhaseOffsets123456void VSyncModulator::setPhaseOffsets(const OffsetsConfig&amp; config) &#123; std::lock_guard&lt;std::mutex&gt; lock(mMutex); mOffsetsConfig = config; // 见 1.4 流程 updateOffsetsLocked();&#125; 这里传入的OffsetsConfig是通过PhaseOffsets拿到的 1.5.1 PhaseOffsets.getCurrentOffsets1234567891011121314151617181920212223242526Offsets getCurrentOffsets() const override &#123; return getOffsetsForRefreshRate(mRefreshRateFps); &#125;PhaseOffsets::Offsets PhaseOffsets::getOffsetsForRefreshRate(float fps) const &#123; const auto iter = std::find_if(mOffsets.begin(), mOffsets.end(), [&amp;fps](const std::pair&lt;float, Offsets&gt;&amp; candidateFps) &#123; return fpsEqualsWithMargin(fps, candidateFps.first); &#125;); if (iter != mOffsets.end()) &#123; return iter-&gt;second; &#125; // Unknown refresh rate. This might happen if we get a hotplug event for an external display. // In this case just construct the offset. ALOGW(&quot;Can&#x27;t find offset for %.2f fps&quot;, fps); return getPhaseOffsets(fps, static_cast&lt;nsecs_t&gt;(1e9f / fps));&#125;PhaseOffsets::Offsets PhaseOffsets::getPhaseOffsets(float fps, nsecs_t vsyncPeriod) const &#123; // 这里根据帧率大小，分两种情况获取偏移量，具体就不看了，和参数配置相关 if (fps &gt; 65.0f) &#123; return getHighFpsOffsets(vsyncPeriod); &#125; else &#123; return getDefaultOffsets(vsyncPeriod); &#125;&#125; 哦吼，到这里setDesiredActiveConfig的流程也算是差不多分析完了，主要做的事情也就下面这些： 触发HWC刷新而不重置空闲计时器。 软件Vsync产生模块记录更新的Vsync周期到mPeriodTransitioningTo中，且开始接收硬件vsync，这可以检测到硬件刷新率切换。 调用onRefreshRateChangeCompleted, 通知更新偏移量 保存即将更新的Fps到mPhaseConfiguration中 再次根据即将更新的Fps拿到的固定偏移量更新偏移量 二. 硬件切换帧率上面的流程跑完后，实际上硬件帧率在哪儿切换还是没有看到，包括mPeriodTransitioningTo是怎么更新到实际软件Vsync中的呢？ 注意到在步骤#1.2中也就是repaintEverythingForHWC会请求下一帧的Vsync，很自然的想法就是实际帧率切换应该是在下一帧到来的时候才开始的。 我们知道SurfaceFlinger接受到Vsync信号后，会调用onMessageInvalidate（Q上是onMessageReceived）方法开始更新、合成Layer。 回顾这个方法，很快就可以找到实际vsync切换在这一块代码中： 12345678910111213141516171819202122232425262728// 首先注意到这个参数默认是false的，也就是说// 调用setDesiredActiveConfig方法后的第一帧是无法进入该分支的// 我们先跳过这段代码if (mSetActiveConfigPending) &#123; if (framePending) &#123; mEventQueue-&gt;invalidate(); return; &#125; // 从HWC收到了当前的fence，假设它成功地更新了配置，因此更新SF各个状态 mSetActiveConfigPending = false; // 2.2 更新SurfaceFlinger的状态，此时HWC是已经更新了帧率 ON_MAIN_THREAD(setActiveConfigInternal());&#125;// ......&#123; Mutex::Autolock _l(mStateLock); // 因为Layer更新刷新率, 重新来选择刷新率 // 这里涉及到Layer的VoteType、权限等记录，有兴趣自行研究 mScheduler-&gt;chooseRefreshRateForContent();&#125;// 2.1 更新当前帧率设置ON_MAIN_THREAD(performSetActiveConfig());// ...... 2.1 SurfaceFlinger.performSetActiveConfig12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758void SurfaceFlinger::performSetActiveConfig() &#123; ATRACE_CALL(); ALOGV(&quot;performSetActiveConfig&quot;); // 判断mDesiredActiveConfigChanged是否为true，获取变量mDesiredActiveConfig // 否则返回nullopt, 说明不需要帧率切换 const auto desiredActiveConfig = getDesiredActiveConfig(); if (!desiredActiveConfig) &#123; // 如果不存在需要切换的帧率配置(mDesiredActiveConfig)，直接返回 return; &#125; auto&amp; refreshRate = mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(desiredActiveConfig-&gt;configId); ALOGV(&quot;performSetActiveConfig changing active config to %d(%s)&quot;, refreshRate.getConfigId().value(), refreshRate.getName().c_str()); const auto display = getDefaultDisplayDeviceLocked(); if (!display || display-&gt;getActiveConfig() == desiredActiveConfig-&gt;configId) &#123; // 显示设备无效，或者已经处于请求的帧率模式下，标记帧率请求已经完成 desiredActiveConfigChangeDone(); return; &#125; // 所需的活动配置已设置，它与当前使用的配置不同，但是在处理刷新时，允许的配置可能已更改。 // 确保所需的配置仍然被允许 if (!isDisplayConfigAllowed(desiredActiveConfig-&gt;configId)) &#123; desiredActiveConfigChangeDone(); return; &#125; mUpcomingActiveConfig = *desiredActiveConfig; const auto displayId = display-&gt;getId(); LOG_ALWAYS_FATAL_IF(!displayId); ATRACE_INT(&quot;ActiveConfigFPS_HWC&quot;, refreshRate.getFps()); // TODO(b/142753666) use constrains hal::VsyncPeriodChangeConstraints constraints; constraints.desiredTimeNanos = systemTime(); constraints.seamlessRequired = false; // 2.1.1 通知HWC更新帧率 hal::VsyncPeriodChangeTimeline outTimeline; auto status = getHwComposer().setActiveConfigWithConstraints(*displayId, mUpcomingActiveConfig.configId.value(), constraints, &amp;outTimeline); if (status != NO_ERROR) &#123; // setActiveConfigWithConstraints may fail if a hotplug event is just about // to be sent. We just log the error in this case. ALOGW(&quot;setActiveConfigWithConstraints failed: %d&quot;, status); return; &#125; mScheduler-&gt;onNewVsyncPeriodChangeTimeline(outTimeline); // 如果需要，Scheduler将向HWC提交一个空帧，回到onMessageInvalidate中处理 // 也就是在下一帧会处理，距离调用setDesiredActiveConfig就是第二个帧了。 mSetActiveConfigPending = true;&#125; 这里做一些合法性判断，最重要的是告诉HWC去更新帧率了。 2.1.1 HWComposer.setActiveConfigWithConstraints123456789101112131415161718status_t HWComposer::setActiveConfigWithConstraints( DisplayId displayId, size_t configId, const hal::VsyncPeriodChangeConstraints&amp; constraints, hal::VsyncPeriodChangeTimeline* outTimeline) &#123; RETURN_IF_INVALID_DISPLAY(displayId, BAD_INDEX); auto&amp; displayData = mDisplayData[displayId]; if (displayData.configMap.count(configId) == 0) &#123; LOG_DISPLAY_ERROR(displayId, (&quot;Invalid config &quot; + std::to_string(configId)).c_str()); return BAD_INDEX; &#125; // hwcDisplay是HWC2::impl::Display，用来描述硬件显示设备的 auto error = displayData.hwcDisplay-&gt;setActiveConfigWithConstraints(displayData.configMap[configId], constraints, outTimeline); RETURN_IF_HWC_ERROR(error, displayId, UNKNOWN_ERROR); return NO_ERROR;&#125; 2.1.2 HWC2::impl::Display.setActiveConfigWithConstraints12345678910111213141516171819202122232425262728293031Error Display::setActiveConfigWithConstraints( const std::shared_ptr&lt;const HWC2::Display::Config&gt;&amp; config, const VsyncPeriodChangeConstraints&amp; constraints, VsyncPeriodChangeTimeline* outTimeline) &#123; ALOGV(&quot;[%&quot; PRIu64 &quot;] setActiveConfigWithConstraints&quot;, mId); if (config-&gt;getDisplayId() != mId) &#123; ALOGE(&quot;setActiveConfigWithConstraints received config %u for the wrong display %&quot; PRIu64 &quot; (expected %&quot; PRIu64 &quot;)&quot;, config-&gt;getId(), config-&gt;getDisplayId(), mId); return Error::BAD_CONFIG; &#125; // 是否支持Vsync Period切换 // 我们假设支持，其实不支持的话无非是换成调用setActiveConfig if (isVsyncPeriodSwitchSupported()) &#123; Hwc2::IComposerClient::VsyncPeriodChangeConstraints hwc2Constraints; hwc2Constraints.desiredTimeNanos = constraints.desiredTimeNanos; hwc2Constraints.seamlessRequired = constraints.seamlessRequired; Hwc2::VsyncPeriodChangeTimeline vsyncPeriodChangeTimeline = &#123;&#125;; // 2.2.2 通知HWComposer切换帧率 auto intError = mComposer.setActiveConfigWithConstraints(mId, config-&gt;getId(), hwc2Constraints, &amp;vsyncPeriodChangeTimeline); outTimeline-&gt;newVsyncAppliedTimeNanos = vsyncPeriodChangeTimeline.newVsyncAppliedTimeNanos; outTimeline-&gt;refreshRequired = vsyncPeriodChangeTimeline.refreshRequired; outTimeline-&gt;refreshTimeNanos = vsyncPeriodChangeTimeline.refreshTimeNanos; return static_cast&lt;Error&gt;(intError); &#125; // ......&#125; 2.1.3 ComposerHal.setActiveConfigWithConstraints1234567891011121314151617181920212223V2_4::Error Composer::setActiveConfigWithConstraints( Display display, Config config, const IComposerClient::VsyncPeriodChangeConstraints&amp; vsyncPeriodChangeConstraints, VsyncPeriodChangeTimeline* outTimeline) &#123; using Error = V2_4::Error; if (!mClient_2_4) &#123; return Error::UNSUPPORTED; &#125; Error error = kDefaultError_2_4; // 转到composer service处理. 也就是给硬件厂商实现 mClient_2_4-&gt;setActiveConfigWithConstraints(display, config, vsyncPeriodChangeConstraints, [&amp;](const auto&amp; tmpError, const auto&amp; tmpTimeline) &#123; error = tmpError; if (error != Error::NONE) &#123; return; &#125; *outTimeline = tmpTimeline; &#125;); return error;&#125; 到这里HWC切换帧率已经完成了。 2.2 SurfaceFlinger.setActiveConfigInternal12345678910111213141516171819202122232425262728293031323334353637383940void SurfaceFlinger::setActiveConfigInternal() &#123; ATRACE_CALL(); const auto display = getDefaultDisplayDeviceLocked(); if (!display) &#123; return; &#125; auto&amp; oldRefreshRate = mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(display-&gt;getActiveConfig()); std::lock_guard&lt;std::mutex&gt; lock(mActiveConfigLock); // 更新配置为最新的帧率信息 mRefreshRateConfigs-&gt;setCurrentConfigId(mUpcomingActiveConfig.configId); mRefreshRateStats-&gt;setConfigMode(mUpcomingActiveConfig.configId); // 将新的帧率保存在DisplayDevice中 display-&gt;setActiveConfig(mUpcomingActiveConfig.configId); auto&amp; refreshRate = mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(mUpcomingActiveConfig.configId); if (refreshRate.getVsyncPeriod() != oldRefreshRate.getVsyncPeriod()) &#123; // 前后帧率不一致，记录此次帧率切换，就是次数（refreshRateSwitches）+1 mTimeStats-&gt;incrementRefreshRateSwitches(); &#125; // 偏移量管理类也要更新FPS信息 mPhaseConfiguration-&gt;setRefreshRateFps(refreshRate.getFps()); // HWC更新帧率了，偏移量再次更新 mVSyncModulator-&gt;setPhaseOffsets(mPhaseConfiguration-&gt;getCurrentOffsets()); ATRACE_INT(&quot;ActiveConfigFPS&quot;, refreshRate.getFps()); // 这里的event就是:Scheduler::ConfigEvent::Changed if (mUpcomingActiveConfig.event != Scheduler::ConfigEvent::None) &#123; const nsecs_t vsyncPeriod = mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(mUpcomingActiveConfig.configId) .getVsyncPeriod(); // 更新AppEventThread中的Vsync间隔信息 mScheduler-&gt;onPrimaryDisplayConfigChanged(mAppConnectionHandle, display-&gt;getId()-&gt;value, mUpcomingActiveConfig.configId, vsyncPeriod); &#125;&#125; 到此帧率切换的过程，差不多就告一段落，当然这里面还有很对细节的部分。 比如硬件Vsync是怎么影响到VsyncRecator产生软件Vsync的，或者软件Vsync和硬件Vsync是怎么校准的。 不过我们先总结一下： SurfaceFlinger收到setDesiredDisplayConfigSpecs更新帧率配置后，根据传入的帧率配置以及当前Layer选择一个最佳帧率 将这个最佳帧率信息存储在mDesiredActiveConfig中，然后请求下一帧Vsync，顺便更新一下偏移量 下一帧Vsync到来后，首先根据Layer再次计算一下最佳帧率，然后通知HWC更新帧率，在等待下一帧 第二个Vsync到来后，实际此时硬件HWC的Vsync已经更新了，现在就是同步更新SurfaceFlinger中各个变量中的状态，然后通知给AppEventThread更新 所以一个完整的帧率切换至少包含2个Vsync周期，不过这两个Vsync周期并不相同哦","categories":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/categories/Android/"},{"name":"Vsync","slug":"Android/Vsync","permalink":"https://swallowjoe.github.io/categories/Android/Vsync/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/tags/Android/"},{"name":"Vsync","slug":"Vsync","permalink":"https://swallowjoe.github.io/tags/Vsync/"}]},{"title":"App申请帧率(3)--SF计算最佳帧率","slug":"App申请帧率-3-SF计算最佳帧率","date":"2022-02-26T19:53:53.000Z","updated":"2022-02-26T20:00:06.780Z","comments":true,"path":"2022/02/27/App申请帧率-3-SF计算最佳帧率/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/App%E7%94%B3%E8%AF%B7%E5%B8%A7%E7%8E%87-3-SF%E8%AE%A1%E7%AE%97%E6%9C%80%E4%BD%B3%E5%B8%A7%E7%8E%87/","excerpt":"以下分析基于Android R. 简述上一章我们分析了App是如何通过更改一个小小的WindowManager的LayoutParam的属性，来影响Framework决策帧率变化的。 接来下我们详细看看SurfaceFlinger是如何根据Framework传入的帧率参数选择合适帧率的。","text":"以下分析基于Android R. 简述上一章我们分析了App是如何通过更改一个小小的WindowManager的LayoutParam的属性，来影响Framework决策帧率变化的。 接来下我们详细看看SurfaceFlinger是如何根据Framework传入的帧率参数选择合适帧率的。 一. SurfaceFlinger接受帧率变化接上一章，从 SurfaceFlinger::setAllowedDisplayConfigs 开始. 但是Android R上入口函数些许变化： 由SurfaceControl.setAllowedDisplayConfigs(getDisplayTokenLocked(), allowedPhysIndexes) &#x3D;》SurfaceControl.setDesiredDisplayConfigSpecs(displayToken, configSpecs); 这里的configSpecs是DesiredDisplayConfigSpecs类型 1.1 SurfaceControl.setDesiredDisplayConfigSpecs12345678public static boolean setDesiredDisplayConfigSpecs(IBinder displayToken, SurfaceControl.DesiredDisplayConfigSpecs desiredDisplayConfigSpecs) &#123; if (displayToken == null) &#123; throw new IllegalArgumentException(&quot;displayToken must not be null&quot;); &#125; return nativeSetDesiredDisplayConfigSpecs(displayToken, desiredDisplayConfigSpecs);&#125; 1.1.1 android_view_SurfaceControl.nativeSetDesiredDisplayConfigSpecs123456789101112131415161718192021222324252627static jboolean nativeSetDesiredDisplayConfigSpecs(JNIEnv* env, jclass clazz, jobject tokenObj, jobject desiredDisplayConfigSpecs) &#123; sp&lt;IBinder&gt; token(ibinderForJavaObject(env, tokenObj)); if (token == nullptr) return JNI_FALSE; jint defaultConfig = env-&gt;GetIntField(desiredDisplayConfigSpecs, gDesiredDisplayConfigSpecsClassInfo.defaultConfig); jfloat primaryRefreshRateMin = env-&gt;GetFloatField(desiredDisplayConfigSpecs, gDesiredDisplayConfigSpecsClassInfo.primaryRefreshRateMin); jfloat primaryRefreshRateMax = env-&gt;GetFloatField(desiredDisplayConfigSpecs, gDesiredDisplayConfigSpecsClassInfo.primaryRefreshRateMax); jfloat appRequestRefreshRateMin = env-&gt;GetFloatField(desiredDisplayConfigSpecs, gDesiredDisplayConfigSpecsClassInfo.appRequestRefreshRateMin); jfloat appRequestRefreshRateMax = env-&gt;GetFloatField(desiredDisplayConfigSpecs, gDesiredDisplayConfigSpecsClassInfo.appRequestRefreshRateMax); size_t result = SurfaceComposerClient::setDesiredDisplayConfigSpecs(token, defaultConfig, primaryRefreshRateMin, primaryRefreshRateMax, appRequestRefreshRateMin, appRequestRefreshRateMax); return result == NO_ERROR ? JNI_TRUE : JNI_FALSE;&#125; 1.1.2 SurfaceComposerClient.setDesiredDisplayConfigSpecs123456789101112status_t SurfaceComposerClient::setDesiredDisplayConfigSpecs(const sp&lt;IBinder&gt;&amp; displayToken, int32_t defaultConfig, float primaryRefreshRateMin, float primaryRefreshRateMax, float appRequestRefreshRateMin, float appRequestRefreshRateMax) &#123; // 转到SurfaceFlinger return ComposerService::getComposerService() -&gt;setDesiredDisplayConfigSpecs(displayToken, defaultConfig, primaryRefreshRateMin, primaryRefreshRateMax, appRequestRefreshRateMin, appRequestRefreshRateMax);&#125; 1.2 SurfaceFlinger.setDesiredDisplayConfigSpecs123456789101112131415161718192021222324252627282930313233343536status_t SurfaceFlinger::setDesiredDisplayConfigSpecs(const sp&lt;IBinder&gt;&amp; displayToken, int32_t defaultConfig, float primaryRefreshRateMin, float primaryRefreshRateMax, float appRequestRefreshRateMin, float appRequestRefreshRateMax) &#123; ATRACE_CALL(); if (!displayToken) &#123; return BAD_VALUE; &#125; // Lambda表达式 auto future = schedule([=]() -&gt; status_t &#123; const auto display = getDisplayDeviceLocked(displayToken); if (!display) &#123; ALOGE(&quot;Attempt to set desired display configs for invalid display token %p&quot;, displayToken.get()); return NAME_NOT_FOUND; &#125; else if (display-&gt;isVirtual()) &#123; ALOGW(&quot;Attempt to set desired display configs for virtual display&quot;); return INVALID_OPERATION; &#125; else &#123; using Policy = scheduler::RefreshRateConfigs::Policy; // 初始化policy const Policy policy&#123;HwcConfigIndexType(defaultConfig), &#123;primaryRefreshRateMin, primaryRefreshRateMax&#125;, &#123;appRequestRefreshRateMin, appRequestRefreshRateMax&#125;&#125;; constexpr bool kOverridePolicy = false; return setDesiredDisplayConfigSpecsInternal(display, policy, kOverridePolicy); &#125; &#125;); return future.get();&#125; 1.2.1 SurfaceFlinger.schedule1234567891011121314151617181920212223242526template &lt;typename F, typename T&gt;inline std::future&lt;T&gt; SurfaceFlinger::schedule(F&amp;&amp; f) &#123; auto [task, future] = makeTask(std::move(f)); mEventQueue-&gt;postMessage(std::move(task)); return std::move(future);&#125;// MessageQueue.htemplate &lt;typename F&gt;inline auto makeTask(F&amp;&amp; f) &#123; sp&lt;Task&lt;F&gt;&gt; task = new Task&lt;F&gt;(std::move(f)); return std::make_pair(task, task-&gt;mTask.get_future());&#125;// MessageQueue.htemplate &lt;typename F&gt;class Task : public MessageHandler &#123; template &lt;typename G&gt; friend auto makeTask(G&amp;&amp;); explicit Task(F&amp;&amp; f) : mTask(std::move(f)) &#123;&#125; void handleMessage(const Message&amp;) override &#123; mTask(); &#125; using T = std::invoke_result_t&lt;F&gt;; std::packaged_task&lt;T()&gt; mTask;&#125;; 1.3 SurfaceFlinger.setDesiredDisplayConfigSpecsInternal12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758status_t SurfaceFlinger::setDesiredDisplayConfigSpecsInternal( const sp&lt;DisplayDevice&gt;&amp; display, const std::optional&lt;scheduler::RefreshRateConfigs::Policy&gt;&amp; policy, bool overridePolicy) &#123; Mutex::Autolock lock(mStateLock); ...... // overridePolicy 一般都是false status_t setPolicyResult = overridePolicy ? mRefreshRateConfigs-&gt;setOverridePolicy(policy) // 1.3.1 更改当前帧率策略 : mRefreshRateConfigs-&gt;setDisplayManagerPolicy(*policy); if (setPolicyResult &lt; 0) &#123; return BAD_VALUE; &#125; if (setPolicyResult == scheduler::RefreshRateConfigs::CURRENT_POLICY_UNCHANGED) &#123; return NO_ERROR; &#125; scheduler::RefreshRateConfigs::Policy currentPolicy = mRefreshRateConfigs-&gt;getCurrentPolicy(); ALOGV(&quot;Setting desired display config specs: defaultConfig: %d primaryRange: [%.0f %.0f]&quot; &quot; expandedRange: [%.0f %.0f]&quot;, currentPolicy.defaultConfig.value(), currentPolicy.primaryRange.min, currentPolicy.primaryRange.max, currentPolicy.appRequestRange.min, currentPolicy.appRequestRange.max); // TODO(b/140204874): Leave the event in until we do proper testing with all apps that might // be depending in this callback. const nsecs_t vsyncPeriod = mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(display-&gt;getActiveConfig()) .getVsyncPeriod(); mScheduler-&gt;onPrimaryDisplayConfigChanged(mAppConnectionHandle, display-&gt;getId()-&gt;value, display-&gt;getActiveConfig(), vsyncPeriod); toggleKernelIdleTimer(); // 1.3.3 获取configId auto configId = mScheduler-&gt;getPreferredConfigId(); // configId是std::optional&lt;HwcConfigIndexType&gt;类型的，这里判断是否存在值，一般存在 // 根据HwcConfigIndexType获取实际的 RefreshRate 参数 auto&amp; preferredRefreshRate = configId ? mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(*configId) // NOTE: Choose the default config ID, if Scheduler doesn&#x27;t have one in mind. : mRefreshRateConfigs-&gt;getRefreshRateFromConfigId(currentPolicy.defaultConfig); ALOGV(&quot;trying to switch to Scheduler preferred config %d (%s)&quot;, preferredRefreshRate.getConfigId().value(), preferredRefreshRate.getName().c_str()); // 判断RefreshRate是否合法 if (isDisplayConfigAllowed(preferredRefreshRate.getConfigId())) &#123; ALOGV(&quot;switching to Scheduler preferred config %d&quot;, preferredRefreshRate.getConfigId().value()); // 1.4 设置帧率 setDesiredActiveConfig( &#123;preferredRefreshRate.getConfigId(), Scheduler::ConfigEvent::Changed&#125;); &#125; else &#123; LOG_ALWAYS_FATAL(&quot;Desired config not allowed: %d&quot;, preferredRefreshRate.getConfigId().value()); &#125; return NO_ERROR;&#125; 1.3.1 RefreshRateConfigs.setDisplayManagerPolicy12345678910111213141516status_t RefreshRateConfigs::setDisplayManagerPolicy(const Policy&amp; policy) &#123; std::lock_guard lock(mLock); if (!isPolicyValid(policy)) &#123; return BAD_VALUE; &#125; // 获取当前策略，如果mOverridePolicy是false，也就是没有覆写 // 就是用的mDisplayManagerPolicy Policy previousPolicy = *getCurrentPolicyLocked(); mDisplayManagerPolicy = policy; if (*getCurrentPolicyLocked() == previousPolicy) &#123; return CURRENT_POLICY_UNCHANGED; &#125; // 1.3.2 根据策略构建最终刷新率 constructAvailableRefreshRates(); return NO_ERROR;&#125; 1.3.2 RefreshRateConfigs.constructAvailableRefreshRates123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475void RefreshRateConfigs::constructAvailableRefreshRates() &#123; // Filter configs based on current policy and sort based on vsync period const Policy* policy = getCurrentPolicyLocked(); const auto&amp; defaultConfig = mRefreshRates.at(policy-&gt;defaultConfig)-&gt;hwcConfig; ALOGV(&quot;constructAvailableRefreshRates: default %d group %d primaryRange=[%.2f %.2f]&quot; &quot; appRequestRange=[%.2f %.2f]&quot;, policy-&gt;defaultConfig.value(), defaultConfig-&gt;getConfigGroup(), policy-&gt;primaryRange.min, policy-&gt;primaryRange.max, policy-&gt;appRequestRange.min, policy-&gt;appRequestRange.max); // lambuda A auto filterRefreshRates = [&amp;](float min, float max, const char* listName, std::vector&lt;const RefreshRate*&gt;* outRefreshRates) &#123; // lambuda B getSortedRefreshRateList( [&amp;](const RefreshRate&amp; refreshRate) REQUIRES(mLock) &#123; const auto&amp; hwcConfig = refreshRate.hwcConfig; return hwcConfig-&gt;getHeight() == defaultConfig-&gt;getHeight() &amp;&amp; hwcConfig-&gt;getWidth() == defaultConfig-&gt;getWidth() &amp;&amp; hwcConfig-&gt;getDpiX() == defaultConfig-&gt;getDpiX() &amp;&amp; hwcConfig-&gt;getDpiY() == defaultConfig-&gt;getDpiY() &amp;&amp; (policy-&gt;allowGroupSwitching || hwcConfig-&gt;getConfigGroup() == defaultConfig-&gt;getConfigGroup()) &amp;&amp; refreshRate.inPolicy(min, max); &#125;, outRefreshRates); LOG_ALWAYS_FATAL_IF(outRefreshRates-&gt;empty(), &quot;No matching configs for %s range: min=%.0f max=%.0f&quot;, listName, min, max); auto stringifyRefreshRates = [&amp;]() -&gt; std::string &#123; std::string str; for (auto refreshRate : *outRefreshRates) &#123; base::StringAppendF(&amp;str, &quot;%s &quot;, refreshRate-&gt;name.c_str()); &#125; return str; &#125;; ALOGV(&quot;%s refresh rates: %s&quot;, listName, stringifyRefreshRates().c_str()); &#125;; filterRefreshRates(policy-&gt;primaryRange.min, policy-&gt;primaryRange.max, &quot;primary&quot;, &amp;mPrimaryRefreshRates); filterRefreshRates(policy-&gt;appRequestRange.min, policy-&gt;appRequestRange.max, &quot;app request&quot;, &amp;mAppRequestRefreshRates);&#125;void RefreshRateConfigs::getSortedRefreshRateList( const std::function&lt;bool(const RefreshRate&amp;)&gt;&amp; shouldAddRefreshRate, std::vector&lt;const RefreshRate*&gt;* outRefreshRates) &#123; outRefreshRates-&gt;clear(); outRefreshRates-&gt;reserve(mRefreshRates.size()); // 遍历所有可能的RefreshRate for (const auto&amp; [type, refreshRate] : mRefreshRates) &#123; // 调用上面的lambuda B方法, 其实就是条件判断 if (shouldAddRefreshRate(*refreshRate)) &#123; ALOGV(&quot;getSortedRefreshRateList: config %d added to list policy&quot;, refreshRate-&gt;configId.value()); outRefreshRates-&gt;push_back(refreshRate.get()); &#125; &#125; // 按照帧率大小排序，VsyncPeriod越大，Fps越小。 // 这里就是按照Fps升序排序了 std::sort(outRefreshRates-&gt;begin(), outRefreshRates-&gt;end(), [](const auto refreshRate1, const auto refreshRate2) &#123; if (refreshRate1-&gt;hwcConfig-&gt;getVsyncPeriod() != refreshRate2-&gt;hwcConfig-&gt;getVsyncPeriod()) &#123; return refreshRate1-&gt;hwcConfig-&gt;getVsyncPeriod() &gt; refreshRate2-&gt;hwcConfig-&gt;getVsyncPeriod(); &#125; else &#123; return refreshRate1-&gt;hwcConfig-&gt;getConfigGroup() &gt; refreshRate2-&gt;hwcConfig-&gt;getConfigGroup(); &#125; &#125;);&#125; 这里吐槽一下，写的很丑。直接说明，在 mRefreshRates中寻找符合要求的configId(modeId)放入对应的集合中。 这里说的符合要求是指： 宽高与所设置的Policy中的defaultConfig的宽高一致 其帧率在所设置的Policy的最小和最大帧率之中 最终将结果保存在变量：mPrimaryRefreshRates以及mAppRequestRefreshRates中。 1.3.3 Scheduler.getPreferredConfigId1234567891011std::optional&lt;HwcConfigIndexType&gt; Scheduler::getPreferredConfigId() &#123; std::lock_guard&lt;std::mutex&gt; lock(mFeatureStateLock); // Make sure that the default config ID is first updated, before returned. // mFeatures 是一个结构体 if (mFeatures.configId.has_value()) &#123; // configId是一个 std:optional的变量 // 计算当前刷新率的configId mFeatures.configId = calculateRefreshRateConfigIndexType(); &#125; return mFeatures.configId;&#125; 这个地方原以为mFeatures.configId一般是存在value的，其实并不是。 1.3.4 Scheduler.calculateRefreshRateConfigIndexType123456789101112131415// consideredSignals 的默认参数是nullptr的HwcConfigIndexType Scheduler::calculateRefreshRateConfigIndexType( scheduler::RefreshRateConfigs::GlobalSignals* consideredSignals) &#123; ATRACE_CALL(); // ...... const bool touchActive = mTouchTimer &amp;&amp; mFeatures.touch == TouchState::Active; const bool idle = mIdleTimer &amp;&amp; mFeatures.idleTimer == TimerState::Expired; // ...... // 1.3.5 获取最佳ConfigId, 根据framework传来的帧率范围, 以及当下Layer投票产生 return mRefreshRateConfigs .getBestRefreshRate(mFeatures.contentRequirements, &#123;.touch = touchActive, .idle = idle&#125;, consideredSignals) .getConfigId();&#125; 1.3.5 RefreshRateConfigs.getBestRefreshRate123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251const RefreshRate&amp; RefreshRateConfigs::getBestRefreshRate( const std::vector&lt;LayerRequirement&gt;&amp; layers, const GlobalSignals&amp; globalSignals, GlobalSignals* outSignalsConsidered) const &#123; ATRACE_CALL(); ALOGV(&quot;getRefreshRateForContent %zu layers&quot;, layers.size()); // 注意传入的outSignalsConsidered是nullptr的 if (outSignalsConsidered) *outSignalsConsidered = &#123;&#125;; const auto setTouchConsidered = [&amp;] &#123; if (outSignalsConsidered) &#123; outSignalsConsidered-&gt;touch = true; &#125; &#125;; const auto setIdleConsidered = [&amp;] &#123; if (outSignalsConsidered) &#123; outSignalsConsidered-&gt;idle = true; &#125; &#125;; std::lock_guard lock(mLock); // 开始投票 // 首先计算所有不同LayerVoteType的数量 // 这里的Type稍后介绍 int noVoteLayers = 0; int minVoteLayers = 0; int maxVoteLayers = 0; int explicitDefaultVoteLayers = 0; int explicitExactOrMultipleVoteLayers = 0; // 记录最大的权重 float maxExplicitWeight = 0; for (const auto&amp; layer : layers) &#123; if (layer.vote == LayerVoteType::NoVote) &#123; noVoteLayers++; &#125; else if (layer.vote == LayerVoteType::Min) &#123; minVoteLayers++; &#125; else if (layer.vote == LayerVoteType::Max) &#123; maxVoteLayers++; &#125; else if (layer.vote == LayerVoteType::ExplicitDefault) &#123; explicitDefaultVoteLayers++; maxExplicitWeight = std::max(maxExplicitWeight, layer.weight); &#125; else if (layer.vote == LayerVoteType::ExplicitExactOrMultiple) &#123; explicitExactOrMultipleVoteLayers++; maxExplicitWeight = std::max(maxExplicitWeight, layer.weight); &#125; &#125; const bool hasExplicitVoteLayers = explicitDefaultVoteLayers &gt; 0 || explicitExactOrMultipleVoteLayers &gt; 0; // $1. 如果没有显式Layer, 考虑触摸事件, 如果存在触摸事件, 选择最大帧率 if (globalSignals.touch &amp;&amp; !hasExplicitVoteLayers) &#123; ALOGV(&quot;TouchBoost - choose %s&quot;, getMaxRefreshRateByPolicyLocked().getName().c_str()); setTouchConsidered(); return getMaxRefreshRateByPolicyLocked(); &#125; // 如果刷新率范围由单个刷新率组成，那么只有当层显式请求不同的刷新率时，才能选择超出范围 const Policy* policy = getCurrentPolicyLocked(); const bool primaryRangeIsSingleRate = policy-&gt;primaryRange.min == policy-&gt;primaryRange.max; // $2. 没有touch事件，屏幕处于idle状态, 刷新率存在一定范围或者不存在显示请求刷新率的Layer时 // 选择最小帧率 if (!globalSignals.touch &amp;&amp; globalSignals.idle &amp;&amp; !(primaryRangeIsSingleRate &amp;&amp; hasExplicitVoteLayers)) &#123; ALOGV(&quot;Idle - choose %s&quot;, getMinRefreshRateByPolicyLocked().getName().c_str()); setIdleConsidered(); return getMinRefreshRateByPolicyLocked(); &#125; // $3. 没有Layer或者所有Layer都没有投票(NoVote)时, 选择最大帧率？？？ if (layers.empty() || noVoteLayers == layers.size()) &#123; return getMaxRefreshRateByPolicyLocked(); &#125; // $4. 存在Layer且所有Layer要么不投票，要么请求最小帧率时，选择最小帧率 if (noVoteLayers + minVoteLayers == layers.size()) &#123; ALOGV(&quot;all layers Min - choose %s&quot;, getMinRefreshRateByPolicyLocked().getName().c_str()); return getMinRefreshRateByPolicyLocked(); &#125; // $5. 计算找到最佳刷新率 std::vector&lt;std::pair&lt;const RefreshRate*, float&gt;&gt; scores; scores.reserve(mAppRequestRefreshRates.size()); for (const auto refreshRate : mAppRequestRefreshRates) &#123; scores.emplace_back(refreshRate, 0.0f); &#125; // 遍历所有Layer for (const auto&amp; layer : layers) &#123; ALOGV(&quot;Calculating score for %s (%s, weight %.2f)&quot;, layer.name.c_str(), layerVoteTypeString(layer.vote).c_str(), layer.weight); // 忽略不投票或者投票选择最小帧率的Layer if (layer.vote == LayerVoteType::NoVote || layer.vote == LayerVoteType::Min) &#123; continue; &#125; auto weight = layer.weight; // 注意这里还有一层循环，分别计算每个AppRequestRefreshRate的得分 for (auto i = 0u; i &lt; scores.size(); i++) &#123; bool inPrimaryRange = scores[i].first-&gt;inPolicy(policy-&gt;primaryRange.min, policy-&gt;primaryRange.max); if ((primaryRangeIsSingleRate || !inPrimaryRange) &amp;&amp; !(layer.focused &amp;&amp; (layer.vote == LayerVoteType::ExplicitDefault || layer.vote == LayerVoteType::ExplicitExactOrMultiple))) &#123; // $$5.1 只有具有显式帧速率设置的聚焦层才允许对主范围之外的刷新率进行评分 // 换句话说，只有ExplicitDefault或者ExplicitExactOrMultiple类型的Layer，且该Layer是有焦点的 // 才允许投票超出刷新率请求范围的帧率 continue; &#125; // $$5.2 如果图层想要最大值，给更高的刷新率评分 if (layer.vote == LayerVoteType::Max) &#123; // 用当前layer(app)请求的帧率除以最后一个layer(app)请求的帧率 // 注意到mAppRequestRefreshRates中fps是按照升序排序的，最后一个是最大的 // 所以这里就是用 当前请求的帧率除以最大的请求帧率得到一个 (0, 1] 的比值 const auto ratio = scores[i].first-&gt;fps / scores.back().first-&gt;fps; // 使用比值的平方得到一个较低的分数 ==&gt; 为啥？ const auto layerScore = ratio * ratio; ALOGV(&quot;%s (Max, weight %.2f) gives %s score of %.2f&quot;, layer.name.c_str(), weight, scores[i].first-&gt;name.c_str(), layerScore); // 将比值的平方乘上权重系数，作为该layer的分数 scores[i].second += weight * layerScore; continue; &#125; // 屏幕刷新率 const auto displayPeriod = scores[i].first-&gt;hwcConfig-&gt;getVsyncPeriod(); // Layer所需的刷新率 const auto layerPeriod = round&lt;nsecs_t&gt;(1e9f / layer.desiredRefreshRate); // $$5.3 如果是ExplicitDefault类型的Layer if (layer.vote == LayerVoteType::ExplicitDefault) &#123; const auto layerScore = [&amp;]() &#123; // 找到Layer将渲染的实际速率，假设layerPeriod是渲染帧的最短时间 auto actualLayerPeriod = displayPeriod; int multiplier = 1; // 刷新时长依次翻倍，直到满足该Layer刷新的最低时长，也就是fps大小每次折半 // MARGIN_FOR_PERIOD_CALCULATION = 800us while (layerPeriod &gt; actualLayerPeriod + MARGIN_FOR_PERIOD_CALCULATION) &#123; multiplier++; actualLayerPeriod = displayPeriod * multiplier; &#125; // 此时layer分数为 layer所需的时长除以满足刷新要求的最长时长 return std::min(1.0f, static_cast&lt;float&gt;(layerPeriod) / static_cast&lt;float&gt;(actualLayerPeriod)); &#125;(); ALOGV(&quot;%s (ExplicitDefault, weight %.2f) %.2fHz gives %s score of %.2f&quot;, layer.name.c_str(), weight, 1e9f / layerPeriod, scores[i].first-&gt;name.c_str(), layerScore); // layer分数乘上权重作为该layer的最终分数 scores[i].second += weight * layerScore; continue; &#125; // $$5.4 如果是ExplicitExactOrMultiple或者Heuristic类型的Layer if (layer.vote == LayerVoteType::ExplicitExactOrMultiple || layer.vote == LayerVoteType::Heuristic) &#123; const auto layerScore = [&amp;] &#123; // 计算我们需要多少个显示vSync来显示这个层的一个帧 // 其实就是计算 layerPeriod/displayPeriod 得到商和余数 const auto [displayFramesQuot, displayFramesRem] = getDisplayFrames(layerPeriod, displayPeriod); static constexpr size_t MAX_FRAMES_TO_FIT = 10; // Stop calculating when score &lt; 0.1 if (displayFramesRem == 0) &#123; // 整除的时候，直接返回1? // 说明layer请求的fps是比display的fps小，得分直接拉满 return 1.0f; &#125; if (displayFramesQuot == 0) &#123; // 当layer请求的fps比display中的fps要大的时候 // 返回layer period除以display period的商的十一分之一 // 比如 layer = 120Hz， display = 90Hz // 8.33333 1.0 // return = ----------- * ---- // 11.1111 11 // 为啥怎么算呢，这里分数的极限值也就是1/11，最大限度排除这个layer请求的帧率？ return (static_cast&lt;float&gt;(layerPeriod) / static_cast&lt;float&gt;(displayPeriod)) * (1.0f / (MAX_FRAMES_TO_FIT + 1)); &#125; // layer所需的刷新率低于的显示刷新率，但又不是整数倍关系，检查它是否符合节奏 // 计算差值: 用 Pl 表述 layer period，Pd表示display period // diff = | (Pl mod Pd) * 2 - Pd | // 这里的意思是在计算多少帧内，display 刷新可以匹配 layer请求的刷新 auto diff = std::abs(displayFramesRem - (displayPeriod - displayFramesRem)); int iter = 2; while (diff &gt; MARGIN_FOR_PERIOD_CALCULATION &amp;&amp; iter &lt; MAX_FRAMES_TO_FIT) &#123; // 循环计算，总结公式： // 1. diff0 = 2 * (Pl mod Pd) - Pd, Pl &gt; Pd 且 K ∈ &#123;1,2,3,...,9&#125; // 2. 当diff0 &gt; 0 时, diff = (Pl mod Pd) * 2^k - Pd * (2^k-1) // 3. 当diff0 &lt; 0 时, diff = Pd - 2^k * (Pl mode Pd) diff = diff - (displayPeriod - diff); iter++; &#125; // 得分取值范围是[0.1, 0.5] return 1.0f / iter; &#125;(); ALOGV(&quot;%s (%s, weight %.2f) %.2fHz gives %s score of %.2f&quot;, layer.name.c_str(), layerVoteTypeString(layer.vote).c_str(), weight, 1e9f / layerPeriod, scores[i].first-&gt;name.c_str(), layerScore); // 照例，乘上权重作为分数 scores[i].second += weight * layerScore; continue; &#125; &#125; &#125; // $6 如果存在请求最大帧率的layer就反向遍历 // 找到得分最大的帧率 const RefreshRate* bestRefreshRate = maxVoteLayers &gt; 0 ? getBestRefreshRate(scores.rbegin(), scores.rend()) : getBestRefreshRate(scores.begin(), scores.end()); // 显示主刷新率没有范围，只有定值时 if (primaryRangeIsSingleRate) &#123; // 如果没有layer参与评分，从显示主刷新范围选取最大值 // 否则返回计算得出的最佳刷新率 if (std::all_of(scores.begin(), scores.end(), [](std::pair&lt;const RefreshRate*, float&gt; p) &#123; return p.second == 0; &#125;)) &#123; ALOGV(&quot;layers not scored - choose %s&quot;, getMaxRefreshRateByPolicyLocked().getName().c_str()); return getMaxRefreshRateByPolicyLocked(); &#125; else &#123; return *bestRefreshRate; &#125; &#125; // 如果没有explicitDefaultLayers，请考虑touch事件。 // ExplicitDefault主要是交互式的（与ExplicitExactOrMultiple相反），因此如果那些Layer发布了一个显式投票， // 那么存在touch事件，就不应该更改它。只有在触摸增强会增加刷新率超过正常选择时才应用。 const RefreshRate&amp; touchRefreshRate = getMaxRefreshRateByPolicyLocked(); // 存在touch事件，不存在ExplicitDefault的Layer且显示主范围刷新率最大值大于计算的刷新率时 // 采用最大刷新率 if (globalSignals.touch &amp;&amp; explicitDefaultVoteLayers == 0 &amp;&amp; bestRefreshRate-&gt;fps &lt; touchRefreshRate.fps) &#123; setTouchConsidered(); ALOGV(&quot;TouchBoost - choose %s&quot;, touchRefreshRate.getName().c_str()); return touchRefreshRate; &#125; return *bestRefreshRate;&#125; Emmmm…. 这一言难尽的代码。 总结一下，在上层计算传入两个刷新率范围后，这里主要是根据Layer投票以及一系列判断得到最终所需的刷新率。 说明一下几个概念： 显示主范围刷新率: DisplayModeDirector中投票算出的包含所有请求帧率的最小范围 layerPeriod: 根据当前layer.desiredRefreshRate计算出一帧的时长 displayPeriod: 当前AppReqeustRefereshRate中HwcConfig计算的一帧时长 整个投票过程简述: 首先计算所有不同LayerVoteType的数量 如果没有显式Layer,即ExplicitDefault和ExplicitExactOrMultiple类型,且存在触摸事件, 直接选择主范围刷新率最大帧率 没有touch事件且屏幕处于idle状态, 刷新率存在一定范围或者不存在显示请求刷新率的Layer时, 选择主范围刷新率最小帧率 没有Layer或者所有Layer都没有投票(NoVote)时, 选择最大帧率 存在Layer且所有Layer要么不投票，要么请求最小帧率时，选择最小帧率 当上述条件都不满足时，遍历所有Layer计算每个AppRequestRefreshRate的得分，找到最佳刷新率, 注意遍历时, 忽略不投票或者投票选择最小帧率的Layer 遍历所有AppRequestRefreshRate 只有ExplicitDefault或者ExplicitExactOrMultiple类型的Layer，且该Layer是有焦点的才允许投票超出刷新率请求范围的帧率，否则忽略该Layer 如果Layer是Max类型 用当前layer(app)请求的帧率除以最后一个layer(app)请求的帧率,得到的比值的平方乘以权重，计入当前AppRequestRefreshRate的分数 如果是ExplicitDefault类型的Layer 找到Layer将渲染的实际速率，首先假设layer.desiredRefreshRate计算的Period是渲染帧的最短时间 将该AppReqeustRefereshRate中的Display Period刷新时长依次翻倍，直到满足该Layer刷新的最低时长，也就是fps大小每次折半 此时layer分数为 layer所需的时长除以满足刷新要求的最长时长在乘以权重计入当前AppRequestRefreshRate的分数 如果是ExplicitExactOrMultiple或者Heuristic类型的Layer 首先计算需要多少个显示vSync来显示这个层的一个帧，即计算 layerPeriod&#x2F;displayPeriod 得到商 quot 和余数 rem 如果是整数倍关系，当前AppRequestRefreshRate的分数直接加上该Layer的权重 当layer请求的fps比AppReqeustRefereshRate中的实际display的fps要大的时候，得分是layer period除以display period的商的十一分之一乘以layer的权重 layer所需的刷新率低于的显示刷新率，但又不是整数倍关系时，用 Pl 表述 layer period，Pd表示display period diff0 &#x3D; 2 * (Pl mod Pd) - Pd, Pl &gt; Pd 且 K ∈ {1,2,3,…,9} 当diff0 &gt; 0 时, diff &#x3D; (Pl mod Pd) * 2^k - Pd * (2^k-1) 当diff0 &lt; 0 时, diff &#x3D; Pd - 2^k * (Pl mode Pd) 当diff小于800时(差值小于800us), 或者k&gt;9结束, 得分是当前Layer的权重乘以1&#x2F;(2K) 如果存在请求最大帧率的layer就反向遍历,找到得分最大的帧率 bestRefreshRate 如果显示主刷新率没有范围，比如最小值和最大值都是120Hz时 如果没有layer参与评分，从显示主刷新范围选取最大值 否则返回计算得出的最佳刷新率 如果存在touch事件, 不存在ExplicitDefault的Layer且显示主范围刷新率最大值大于计算的刷新率时, 采用最大刷新率 以上条件均不满足时，返回计算的bestRefreshRate 好了，本次分析到此为止，接下来就是继续看SurfaceFlinger如何通知HWC硬件切换帧率了。","categories":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/categories/Android/"},{"name":"Vsync","slug":"Android/Vsync","permalink":"https://swallowjoe.github.io/categories/Android/Vsync/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/tags/Android/"},{"name":"Vsync","slug":"Vsync","permalink":"https://swallowjoe.github.io/tags/Vsync/"}]},{"title":"App申请帧率(2)--Framework选择最近帧率范围","slug":"App申请帧率-2-Framework选择最近帧率范围","date":"2022-02-26T19:53:41.000Z","updated":"2022-02-26T19:58:50.653Z","comments":true,"path":"2022/02/27/App申请帧率-2-Framework选择最近帧率范围/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/App%E7%94%B3%E8%AF%B7%E5%B8%A7%E7%8E%87-2-Framework%E9%80%89%E6%8B%A9%E6%9C%80%E8%BF%91%E5%B8%A7%E7%8E%87%E8%8C%83%E5%9B%B4/","excerpt":"以下分析基于Android Q.","text":"以下分析基于Android Q. 一. preferredDisplayModeId改变上篇文章讲到，只要将window的Param设置就可以更改屏幕分辨率： 1wmParams!!.preferredDisplayModeId = highestMode.modeId 代码是和实现的呢, 在App接受vsync信号后，会回调Choreographer.CALLBACK_TRAVERSAL，也就会调用到ViewRootImpl.doTraversal. 调用栈如下: Choreographer.onVsync() Choreographer.doFrame() &#x2F;&#x2F; doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos); ViewRootImpl.doTraversal() ViewRootImpl.performTraversals() ViewRootImpl.relayoutWindow() &#x2F;&#x2F; 这里将当前Window的Attr传入WindowManagerService IWindowSession.relayout() &#x2F;&#x2F; 通过binder调用 Session.relayout WindowManagerService.relayoutWindow() &#x2F;&#x2F; 进入SystenServer进程 WindowSurfacePlacer.performSurfacePlacement() WindowSurfacePlacer.performSurfacePlacementLoop() RootWindowContainer.performSurfacePlacement() RootWindowContainer.performSurfacePlacementNoTrace() RootWindowContainer.applySurfaceChangesTransaction() DisplayContent.applySurfaceChangesTransaction() DisplayContent.mApplySurfaceChangesTransaction &#x2F;&#x2F; 对所有window遍历执行，如果有属性变化响应变化 DisplayManagerService.setDisplayProperties &#x2F;&#x2F; 计算并保存合适的modeId DisplayManagerInternal.performTraversal(mDisplayTransaction) &#x2F;&#x2F; 应用modeId变化 1.1 RootWindowContainer.applySurfaceChangesTransaction1234567891011121314private void applySurfaceChangesTransaction(boolean recoveringMemory) &#123; ...... final int count = mChildren.size(); for (int j = 0; j &lt; count; ++j) &#123; final DisplayContent dc = mChildren.get(j); // 1.2 对每个display都计算变化 dc.applySurfaceChangesTransaction(recoveringMemory); &#125; // 3.1 通知SurfaceFlinger改变ModeId mWmService.mDisplayManagerInternal.performTraversal(mDisplayTransaction); SurfaceControl.mergeToGlobalTransaction(mDisplayTransaction);&#125; 1.2 DisplayContent.applySurfaceChangesTransaction()1234567891011121314151617181920void applySurfaceChangesTransaction(boolean recoveringMemory) &#123; ...... Trace.traceBegin(TRACE_TAG_WINDOW_MANAGER, &quot;applyWindowSurfaceChanges&quot;); try &#123; // 1.3 遍历所有window, 按照Z轴从上到下 forAllWindows(mApplySurfaceChangesTransaction, true /* traverseTopToBottom */); &#125; finally &#123; Trace.traceEnd(TRACE_TAG_WINDOW_MANAGER); &#125; prepareSurfaces(); mLastHasContent = mTmpApplySurfaceChangesTransactionState.displayHasContent; // 1.4 应用需要Display属性变化 mWmService.mDisplayManagerInternal.setDisplayProperties(mDisplayId, mLastHasContent, mTmpApplySurfaceChangesTransactionState.preferredRefreshRate, mTmpApplySurfaceChangesTransactionState.preferredModeId, true /* inTraversal, must call performTraversalInTrans... below */); ......&#125; 1.3 DisplayContent.mApplySurfaceChangesTransaction12345678910111213141516private final Consumer&lt;WindowState&gt; mApplySurfaceChangesTransaction = w -&gt; &#123; ...... if (!mTmpApplySurfaceChangesTransactionState.obscured) &#123; ...... // 获取wmParams.preferredDisplayModeId中的modeId final int preferredModeId = getDisplayPolicy().getRefreshRatePolicy() .getPreferredModeId(w); // 注意这里是按照Z轴从上到下遍历Window，所以只会取第一个可见的有Surface的且被设置的window的modeId if (mTmpApplySurfaceChangesTransactionState.preferredModeId == 0 &amp;&amp; preferredModeId != 0) &#123; // 标记preferredModeId mTmpApplySurfaceChangesTransactionState.preferredModeId = preferredModeId; &#125; &#125; ......&#125; 1.4 DisplayManagerService.setDisplayProperties12345678910111213141516171819202122232425262728293031323334353637@Overridepublic void setDisplayProperties(int displayId, boolean hasContent, float requestedRefreshRate, int requestedMode, boolean inTraversal) &#123; setDisplayPropertiesInternal(displayId, hasContent, requestedRefreshRate, requestedMode, inTraversal);&#125;private void setDisplayPropertiesInternal(int displayId, boolean hasContent, float requestedRefreshRate, int requestedModeId, boolean inTraversal) &#123; synchronized (mSyncRoot) &#123; LogicalDisplay display = mLogicalDisplays.get(displayId); if (display == null) &#123; return; &#125; if (display.hasContentLocked() != hasContent) &#123; if (DEBUG) &#123; Slog.d(TAG, &quot;Display &quot; + displayId + &quot; hasContent flag changed: &quot; + &quot;hasContent=&quot; + hasContent + &quot;, inTraversal=&quot; + inTraversal); &#125; display.setHasContentLocked(hasContent); scheduleTraversalLocked(inTraversal); &#125; // 当应用仅仅设置了刷新率，而没有设置modeId时，需要找到一个合适的modeId // 为什么这么做呢，因为modeId不仅仅包含刷新率，还有分辨率。 // 当请求刷新率变化时，是不能或不必要改变分辨率的，所以就需要找到分辨率不变的modeId if (requestedModeId == 0 &amp;&amp; requestedRefreshRate != 0) &#123; // Scan supported modes returned by display.getInfo() to find a mode with the same // size as the default display mode but with the specified refresh rate instead. requestedModeId = display.getDisplayInfoLocked().findDefaultModeByRefreshRate( requestedRefreshRate); &#125; // 2.1 发现有应用请求Display改变modeId mDisplayModeDirector.getAppRequestObserver().setAppRequestedMode( displayId, requestedModeId); &#125;&#125; 二. DisplayModeDirector这个类是用于决策当前设备刷新率的 2.1 DisplayModeDirector.AppRequestObserver.setAppRequestedMode12345678910111213141516171819202122232425262728293031323334public void setAppRequestedMode(int displayId, int modeId) &#123; synchronized (mLock) &#123; setAppRequestedModeLocked(displayId, modeId); &#125;&#125;private void setAppRequestedModeLocked(int displayId, int modeId) &#123; // 做一个参数检查，确保displayId和modeId参数是可接受的 final Display.Mode requestedMode = findModeByIdLocked(displayId, modeId); // 如果当前displayId下的modeId已经是App所需的modeId，就不用继续了 if (Objects.equals(requestedMode, mAppRequestedModeByDisplay.get(displayId))) &#123; return; &#125; final Vote refreshRateVote; final Vote sizeVote; if (requestedMode != null) &#123; // 保存当前App设置的参数 mAppRequestedModeByDisplay.put(displayId, requestedMode); float refreshRate = requestedMode.getRefreshRate(); // 创建刷新率Vote refreshRateVote = Vote.forRefreshRates(refreshRate, refreshRate); sizeVote = Vote.forSize(requestedMode.getPhysicalWidth(), requestedMode.getPhysicalHeight()); &#125; else &#123; mAppRequestedModeByDisplay.remove(displayId); refreshRateVote = null; sizeVote = null; &#125; updateVoteLocked(displayId, Vote.PRIORITY_APP_REQUEST_REFRESH_RATE, refreshRateVote); updateVoteLocked(displayId, Vote.PRIORITY_APP_REQUEST_SIZE, sizeVote); return;&#125; 2.2 DisplayModeDirector.Vote.updateVoteLocked更新Vote策略 1234567891011121314151617181920212223242526272829303132private void updateVoteLocked(int displayId, int priority, Vote vote) &#123; if (DEBUG) &#123; Slog.i(TAG, &quot;updateVoteLocked(displayId=&quot; + displayId + &quot;, priority=&quot; + Vote.priorityToString(priority) + &quot;, vote=&quot; + vote + &quot;)&quot;); &#125; if (priority &lt; Vote.MIN_PRIORITY || priority &gt; Vote.MAX_PRIORITY) &#123; Slog.w(TAG, &quot;Received a vote with an invalid priority, ignoring:&quot; + &quot; priority=&quot; + Vote.priorityToString(priority) + &quot;, vote=&quot; + vote, new Throwable()); return; &#125; // 获取当前display的所有Vote final SparseArray&lt;Vote&gt; votes = getOrCreateVotesByDisplay(displayId); // 获取PRIORITY_APP_REQUEST_REFRESH_RATE优先级的Vote，不过根本没有用？ Vote currentVote = votes.get(priority); // 传入的Vote不为空，说明有符合要求的ModeId,就保存，没有就移除当前优先级的Vote if (vote != null) &#123; votes.put(priority, vote); &#125; else &#123; votes.remove(priority); &#125; if (votes.size() == 0) &#123; if (DEBUG) &#123; Slog.i(TAG, &quot;No votes left for display &quot; + displayId + &quot;, removing.&quot;); &#125; mVotesByDisplay.remove(displayId); &#125; // 通知ModeId改变 notifyAllowedModesChangedLocked();&#125; 2.3 DisplayModeDirector.Vote.notifyAllowedModesChangedLocked123456789101112131415161718192021222324252627private void notifyAllowedModesChangedLocked() &#123; if (mListener != null &amp;&amp; !mHandler.hasMessages(MSG_ALLOWED_MODES_CHANGED)) &#123; // We need to post this to a handler to avoid calling out while holding the lock // since we know there are things that both listen for changes as well as provide // information. If we did call out while holding the lock, then there&#x27;s no guaranteed // lock order and we run the real of risk deadlock. Message msg = mHandler.obtainMessage(MSG_ALLOWED_MODES_CHANGED, mListener); msg.sendToTarget(); &#125;&#125;private final class DisplayModeDirectorHandler extends Handler &#123; DisplayModeDirectorHandler(Looper looper) &#123; super(looper, null, true /*async*/); &#125; @Override public void handleMessage(Message msg) &#123; switch (msg.what) &#123; case MSG_ALLOWED_MODES_CHANGED: Listener listener = (Listener) msg.obj; listener.onAllowedDisplayModesChanged(); break; ...... &#125; &#125;&#125; 转到DisplayThread线程处理，也就是回调onAllowedDisplayModesChanged.这里的mListener是调用DisplayModeDirector.setListener设置的，这个是在DisplayManagerService中: 12345678910111213141516171819/** * Called when the system is ready to go. */public void systemReady(boolean safeMode, boolean onlyCore) &#123; synchronized (mSyncRoot) &#123; mSafeMode = safeMode; mOnlyCore = onlyCore; mSystemReady = true; // Just in case the top inset changed before the system was ready. At this point, any // relevant configuration should be in place. recordTopInsetLocked(mLogicalDisplays.get(Display.DEFAULT_DISPLAY)); &#125; // 这里： mDisplayModeDirector.setListener(new AllowedDisplayModeObserver()); mDisplayModeDirector.start(mSensorManager); mHandler.sendEmptyMessage(MSG_REGISTER_ADDITIONAL_DISPLAY_ADAPTERS);&#125; 2.4 DisplayManagerService.onAllowedDisplayModesChangedInternal1234567891011121314151617181920212223242526private void onAllowedDisplayModesChangedInternal() &#123; boolean changed = false; synchronized (mSyncRoot) &#123; final int count = mLogicalDisplays.size(); // 遍历所有的Display，依次设置 for (int i = 0; i &lt; count; i++) &#123; LogicalDisplay display = mLogicalDisplays.valueAt(i); int displayId = mLogicalDisplays.keyAt(i); // 2.5 获取displayId对应的ModeIds int[] allowedModes = mDisplayModeDirector.getAllowedModes(displayId); // Note that order is important here since not all display devices are capable of // automatically switching, so we do actually want to check for equality and not // just equivalent contents (regardless of order). if (!Arrays.equals(allowedModes, display.getAllowedDisplayModesLocked())) &#123; // 保存modeId集，以便判断是否有modeId变化，这个判断条件内getAllowedDisplayModesLocked // 拿到的modeId数组就是上一次在这里保存的 display.setAllowedDisplayModesLocked(allowedModes); changed = true; &#125; &#125; // 有改变, 请求下一次Vsync, 以确保通知到SurfaceFlinger有modeId更改 if (changed) &#123; scheduleTraversalLocked(false); &#125; &#125;&#125; 2.5 DisplayModeDirector.getAllowedModes12345678910111213141516@NonNullpublic int[] getAllowedModes(int displayId) &#123; synchronized (mLock) &#123; // 取出displayId对应的所有Vote，注意这里包含GLOBAL_ID(-1), 即全局生效的Vote SparseArray&lt;Vote&gt; votes = getVotesLocked(displayId); Display.Mode[] modes = mSupportedModesByDisplay.get(displayId); Display.Mode defaultMode = mDefaultModeByDisplay.get(displayId); if (modes == null || defaultMode == null) &#123; Slog.e(TAG, &quot;Asked about unknown display, returning empty allowed set! (id=&quot; + displayId + &quot;)&quot;); return new int[0]; &#125; // 2.5.1 计算 return getAllowedModesLocked(votes, modes, defaultMode); &#125;&#125; 计算displayId对应允许的可自由切换的modeId列表 2.5.1 DisplayModeDirector.getAllowedModesLocked123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@NonNullprivate int[] getAllowedModesLocked(@NonNull SparseArray&lt;Vote&gt; votes, @NonNull Display.Mode[] modes, @NonNull Display.Mode defaultMode) &#123; // 从最低优先级开始遍历，不过为什么会有两层循环？ int lowestConsideredPriority = Vote.MIN_PRIORITY; while (lowestConsideredPriority &lt;= Vote.MAX_PRIORITY) &#123; float minRefreshRate = 0f; float maxRefreshRate = Float.POSITIVE_INFINITY; int height = Vote.INVALID_SIZE; int width = Vote.INVALID_SIZE; // 从优先级最大的开始遍历 for (int priority = Vote.MAX_PRIORITY; priority &gt;= lowestConsideredPriority; priority--) &#123; Vote vote = votes.get(priority); if (vote == null) &#123; continue; &#125; // 刷新率最小值取两者中的较大值 minRefreshRate = Math.max(minRefreshRate, vote.minRefreshRate); // 刷新率最大值取两者中的较小值 maxRefreshRate = Math.min(maxRefreshRate, vote.maxRefreshRate); // 显示大小只需要取第一个值 if (height == Vote.INVALID_SIZE &amp;&amp; width == Vote.INVALID_SIZE &amp;&amp; vote.height &gt; 0 &amp;&amp; vote.width &gt; 0) &#123; width = vote.width; height = vote.height; &#125; &#125; // If we don&#x27;t have anything specifying the width / height of the display, just use the // default width and height. We don&#x27;t want these switching out from underneath us since // it&#x27;s a pretty disruptive behavior. if (height == Vote.INVALID_SIZE || width == Vote.INVALID_SIZE) &#123; width = defaultMode.getPhysicalWidth(); height = defaultMode.getPhysicalHeight(); &#125; // 2.5.2 获取可取的mode int[] availableModes = filterModes(modes, width, height, minRefreshRate, maxRefreshRate); if (availableModes.length &gt; 0) &#123; return availableModes; &#125; // 当前优先级下没有找到合适的modeId时，提高优先级重新搜索 lowestConsideredPriority++; &#125; // If we still haven&#x27;t found anything that matches our current set of votes, just fall back // to the default mode. return new int[] &#123; defaultMode.getModeId() &#125;;&#125; 这里刷新率的算法是，遍历所有优先级的Vote，最终的minRefreshRate取所有Vote的最小刷新率中的最大值。maxRefreshRate取所有Vote中最大刷新率的最小值。 这里有个地方一开始比较难理解，就是为什么是用双层循环，而且第一层循环是从优先级最低的开始，最内层是优先级最大的开始。不着急我们先看#2.5.2 2.5.2 DisplayModeDirector.filterModes12345678910111213141516171819202122232425262728private int[] filterModes(Display.Mode[] supportedModes, int width, int height, float minRefreshRate, float maxRefreshRate) &#123; ArrayList&lt;Display.Mode&gt; availableModes = new ArrayList&lt;&gt;(); for (Display.Mode mode : supportedModes) &#123; if (mode.getPhysicalWidth() != width || mode.getPhysicalHeight() != height) &#123; continue; &#125; final float refreshRate = mode.getRefreshRate(); // EPSILON = 0.001f // 为啥会有这呢，因为小数计算会有误差 // 比如60Hz的刷新的vsync间隔是16.666666ms // 计算得来的refreshRate就是：1000/16.666666 = 60.0000024 // 不是恰好为60，所以需要去掉这个误差 if (refreshRate &lt; (minRefreshRate - EPSILON) || refreshRate &gt; (maxRefreshRate + EPSILON)) &#123; // 当该mode的刷新率不符合边界条件时，抛弃该mode continue; &#125; availableModes.add(mode); &#125; final int size = availableModes.size(); int[] availableModeIds = new int[size]; for (int i = 0; i &lt; size; i++) &#123; availableModeIds[i] = availableModes.get(i).getModeId(); &#125; // 返回符合要求的modeId集合 return availableModeIds;&#125; 其实实际推演一下就不难理解了, 假设我们有如下Votes: 12345678910111213141516mSupportedModesByDisplay: 0 -&gt; [ &#123;id=1, width=1080, height=2376, fps=60.000004&#125;, &#123;id=2, width=1440, height=3168, fps=120.00001&#125;, &#123;id=3, width=1440, height=3168, fps=60.000004&#125;, &#123;id=4, width=1080, height=2376, fps=120.00001&#125;] mVotesByDisplay: -1: PRIORITY_LOW_POWER_MODE -&gt; Vote&#123;width=-1, height=-1, minRefreshRate=0.0, maxRefreshRate=60.0&#125; PRIORITY_USER_SETTING_PEAK_REFRESH_RATE -&gt; Vote&#123;width=-1, height=-1, minRefreshRate=0.0, maxRefreshRate=120.0&#125; PRIORITY_USER_SETTING_MIN_REFRESH_RATE -&gt; Vote&#123;width=-1, height=-1, minRefreshRate=0.0, maxRefreshRate=Infinity&#125; 0: PRIORITY_APP_REQUEST_SIZE -&gt; Vote&#123;width=1080, height=2376, minRefreshRate=0.0, maxRefreshRate=Infinity&#125; PRIORITY_APP_REQUEST_REFRESH_RATE -&gt; Vote&#123;width=-1, height=-1, minRefreshRate=120.00001, maxRefreshRate=120.00001&#125; 注意这里的优先级: name Value PRIORITY_LOW_BRIGHTNESS 0 PRIORITY_USER_SETTING_MIN_REFRESH_RATE 1 PRIORITY_APP_REQUEST_REFRESH_RATE 2 PRIORITY_APP_REQUEST_SIZE 3 PRIORITY_USER_SETTING_PEAK_REFRESH_RATE 4 PRIORITY_LOW_POWER_MODE 5 当外层循环第一次执行时：lowestConsideredPriority &#x3D; PRIORITY_LOW_BRIGHTNESS &#x3D; 0 内层循环会遍历所有Vote(包含-1，和当前displayId,这里是0): 算出的minRefreshRate &#x3D; Infinity, maxRefreshRate &#x3D;0 当然，在filterModes中是找不到合适的mode的，所以优先级+1，继续搜索 外层循环第二次执行时：lowestConsideredPriority &#x3D; PRIORITY_USER_SETTING_MIN_REFRESH_RATE &#x3D; 1 此时排除优先级为0的所有Vote，其实结果还是一样，所以lowestConsideredPriority继续+1 外层循环第三次执行时：lowestConsideredPriority &#x3D; PRIORITY_APP_REQUEST_REFRESH_RATE &#x3D; 2 此时排除优先级小于PRIORITY_APP_REQUEST_REFRESH_RATE的所有Vote，结果还是一样，所以lowestConsideredPriority继续+1 外层循环第四次执行时：lowestConsideredPriority &#x3D; PRIORITY_APP_REQUEST_SIZE &#x3D; 3 此时排除优先级小于PRIORITY_APP_REQUEST_SIZE的所有Vote，结果还是一样，所以lowestConsideredPriority继续+1 外层循环第五次执行时：lowestConsideredPriority &#x3D; PRIORITY_USER_SETTING_PEAK_REFRESH_RATE &#x3D; 4 此时排除优先级小于PRIORITY_USER_SETTING_PEAK_REFRESH_RATE的所有Vote 内层循环其实只有两个选项： PRIORITY_LOW_POWER_MODE -&gt; Vote{width&#x3D;-1, height&#x3D;-1, minRefreshRate&#x3D;0.0, maxRefreshRate&#x3D;60.0} PRIORITY_USER_SETTING_PEAK_REFRESH_RATE -&gt; Vote{width&#x3D;-1, height&#x3D;-1, minRefreshRate&#x3D;0.0, maxRefreshRate&#x3D;120.0} 此时结果为minRefreshRate &#x3D; 60, maxRefreshRate &#x3D;0，当然还是没有有效的modeId 外层循环第六次执行时：lowestConsideredPriority &#x3D; PRIORITY_LOW_POWER_MODE &#x3D; 5 只有选项：PRIORITY_LOW_POWER_MODE -&gt; Vote{width&#x3D;-1, height&#x3D;-1, minRefreshRate&#x3D;0.0, maxRefreshRate&#x3D;60.0} 所以最终的minRefreshRate &#x3D; 0.0, maxRefreshRate &#x3D; 60.0，width&#x3D;1080, height&#x3D;2376 最后满足条件的modeId就只有mSupportedModesByDisplay中的0了. 最终算出来了modeId, 这里面计算复杂，弯弯绕绕，为什么Google如此设计呢，个人猜测是为了尽可能满足低优先级下的刷新率要求，并不是优先级最高就能决定modeId的取值,而是找到尽快满足更多优先级下合适刷新率的modeId集提供给SurfaceFlinger选择. 继续往下看，framework将这个modeId集传给SurfaceFlinger. 三. 通知SurfaceFlinger变化3.1 DisplayManagerInternal.performTraversal1234@Overridepublic void performTraversal(SurfaceControl.Transaction t) &#123; performTraversalInternal(t);&#125; 3.2 DisplayManagerService.performTraversalInternal12345678910111213141516@VisibleForTestingvoid performTraversalInternal(SurfaceControl.Transaction t) &#123; synchronized (mSyncRoot) &#123; if (!mPendingTraversal) &#123; return; &#125; mPendingTraversal = false; // 3.2.1 通知SF有相关状态变化 performTraversalLocked(t); &#125; // List is self-synchronized copy-on-write. for (DisplayTransactionListener listener : mDisplayTransactionListeners) &#123; listener.onDisplayTransaction(t); &#125;&#125; 3.2.1 DisplayManagerService.performTraversalLocked123456789101112131415private void performTraversalLocked(SurfaceControl.Transaction t) &#123; // Clear all viewports before configuring displays so that we can keep // track of which ones we have configured. clearViewportsLocked(); // 3.2.2 对每个Display都做配置 final int count = mDisplayDevices.size(); for (int i = 0; i &lt; count; i++) &#123; DisplayDevice device = mDisplayDevices.get(i); // 与SurfaceFlinger通信，这里的device我们视为默认的LocalDisplayDevice configureDisplayLocked(t, device); device.performTraversalLocked(t); &#125; ......&#125; 3.2.2 DisplayManagerService.configureDisplayLocked123456789private void configureDisplayLocked(SurfaceControl.Transaction t, DisplayDevice device) &#123; ...... // 拿到对应LogicalDisplay LogicalDisplay display = findLogicalDisplayForDeviceLocked(device); ...... // 3.2.3 应用状态变化 display.configureDisplayLocked(t, device, info.state == Display.STATE_OFF); ......&#125; 3.2.3 LogicalDisplay.configureDisplayLocked1234567891011121314151617public void configureDisplayLocked(SurfaceControl.Transaction t, DisplayDevice device, boolean isBlanked) &#123; // Set the layer stack. device.setLayerStackLocked(t, isBlanked ? BLANK_LAYER_STACK : mLayerStack); // 3.3 应用配置变化，注意这里的device是LocalDisplayDevice if (device == mPrimaryDisplayDevice) &#123; device.setAllowedDisplayModesLocked(mAllowedDisplayModes); device.setRequestedColorModeLocked(mRequestedColorMode); &#125; else &#123; // Reset to default for non primary displays device.setAllowedDisplayModesLocked(new int[] &#123;0&#125;); device.setRequestedColorModeLocked(0); &#125; ......&#125; 3.3 LocalDisplayAdapter.LocalDisplayDevice.setAllowedDisplayModesLocked12345678910111213141516171819202122232425262728293031323334353637@Overridepublic void setAllowedDisplayModesLocked(int[] modes) &#123; updateAllowedModesLocked(modes);&#125;public void updateAllowedModesLocked(int[] allowedModes) &#123; if (Arrays.equals(allowedModes, mAllowedModeIds) &amp;&amp; !mAllowedModeIdsInvalid) &#123; return; &#125; if (updateAllowedModesInternalLocked(allowedModes)) &#123; updateDeviceInfoLocked(); &#125;&#125;public boolean updateAllowedModesInternalLocked(int[] allowedModes) &#123; if (DEBUG) &#123; Slog.w(TAG, &quot;updateAllowedModesInternalLocked(allowedModes=&quot; + Arrays.toString(allowedModes) + &quot;)&quot;); &#125; int[] allowedPhysIndexes = new int[allowedModes.length]; int size = 0; // 将modeId转化为物理modeId，简单来说就是 physicalId = modeId - 1 for (int modeId : allowedModes) &#123; int physIndex = findDisplayInfoIndexLocked(modeId); if (physIndex &lt; 0) &#123; Slog.w(TAG, &quot;Requested mode ID &quot; + modeId + &quot; not available,&quot; + &quot; dropping from allowed set.&quot;); &#125; else &#123; allowedPhysIndexes[size++] = physIndex; &#125; &#125; ...... // 3.4 通过SurfaceControl通知SurfaceFlinger有modeId变化，binder通信 SurfaceControl.setAllowedDisplayConfigs(getDisplayTokenLocked(), allowedPhysIndexes); int activePhysIndex = SurfaceControl.getActiveConfig(getDisplayTokenLocked()); return updateActiveModeLocked(activePhysIndex);&#125; 3.4 SurfaceControl.setAllowedDisplayConfigs12345678910111213private static native boolean nativeSetAllowedDisplayConfigs(IBinder displayToken, int[] allowedConfigs);public static boolean setAllowedDisplayConfigs(IBinder displayToken, int[] allowedConfigs) &#123; if (displayToken == null) &#123; throw new IllegalArgumentException(&quot;displayToken must not be null&quot;); &#125; if (allowedConfigs == null) &#123; throw new IllegalArgumentException(&quot;allowedConfigs must not be null&quot;); &#125; // JNI调用 return nativeSetAllowedDisplayConfigs(displayToken, allowedConfigs);&#125; 3.5 android_view_SurfaceControl::nativeSetAllowedDisplayConfigs123456789101112131415161718static jboolean nativeSetAllowedDisplayConfigs(JNIEnv* env, jclass clazz, jobject tokenObj, jintArray configArray) &#123; sp&lt;IBinder&gt; token(ibinderForJavaObject(env, tokenObj)); if (token == nullptr) return JNI_FALSE; std::vector&lt;int32_t&gt; allowedConfigs; jsize configArraySize = env-&gt;GetArrayLength(configArray); allowedConfigs.reserve(configArraySize); jint* configArrayElements = env-&gt;GetIntArrayElements(configArray, 0); for (int i = 0; i &lt; configArraySize; i++) &#123; allowedConfigs.push_back(configArrayElements[i]); &#125; env-&gt;ReleaseIntArrayElements(configArray, configArrayElements, 0); // 3.5.1 通过SurfaceComposerClient size_t result = SurfaceComposerClient::setAllowedDisplayConfigs(token, allowedConfigs); return result == NO_ERROR ? JNI_TRUE : JNI_FALSE;&#125; 3.5.1 SurfaceComposerClient::setAllowedDisplayConfigs123456status_t SurfaceComposerClient::setAllowedDisplayConfigs( const sp&lt;IBinder&gt;&amp; displayToken, const std::vector&lt;int32_t&gt;&amp; allowedConfigs) &#123; // 通过binder调用到SurfaceFlinger return ComposerService::getComposerService()-&gt;setAllowedDisplayConfigs(displayToken, allowedConfigs);&#125; 3.6 SurfaceFlinger::setAllowedDisplayConfigs12345678910111213141516171819202122232425262728status_t SurfaceFlinger::setAllowedDisplayConfigs(const sp&lt;IBinder&gt;&amp; displayToken, const std::vector&lt;int32_t&gt;&amp; allowedConfigs) &#123; ATRACE_CALL(); if (!displayToken || allowedConfigs.empty()) &#123; return BAD_VALUE; &#125; if (mDebugDisplayConfigSetByBackdoor) &#123; // ignore this request as config is overridden by backdoor return NO_ERROR; &#125; postMessageSync(new LambdaMessage([&amp;]() &#123; const auto display = getDisplayDeviceLocked(displayToken); if (!display) &#123; ALOGE(&quot;Attempt to set allowed display configs for invalid display token %p&quot;, displayToken.get()); &#125; else if (display-&gt;isVirtual()) &#123; ALOGW(&quot;Attempt to set allowed display configs for virtual display&quot;); &#125; else &#123; Mutex::Autolock lock(mStateLock); setAllowedDisplayConfigsInternal(display, allowedConfigs); &#125; &#125;)); return NO_ERROR;&#125; 好了，app设置屏幕显示刷新的流程就走完了，接下来就是SurfaceFlinger去和硬件交互，通知切换刷新率了。","categories":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/categories/Android/"},{"name":"Vsync","slug":"Android/Vsync","permalink":"https://swallowjoe.github.io/categories/Android/Vsync/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/tags/Android/"},{"name":"Vsync","slug":"Vsync","permalink":"https://swallowjoe.github.io/tags/Vsync/"}]},{"title":"App申请帧率(1)--简述","slug":"App申请帧率-1-简述","date":"2022-02-26T19:53:29.000Z","updated":"2022-02-26T19:58:12.384Z","comments":true,"path":"2022/02/27/App申请帧率-1-简述/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/App%E7%94%B3%E8%AF%B7%E5%B8%A7%E7%8E%87-1-%E7%AE%80%E8%BF%B0/","excerpt":"背景 参考资料 查看设备可支持的刷新率和分辨率 App设置设备帧率 Android Q及以下版本 Android R 背景随着手机屏幕硬件能力的提升，越来越多的厂商提供支持多档次刷新率的Android设备。而在Android Q上也是支持App指定当前屏幕帧率的，也有一套帧率分辨率切换的逻辑。","text":"背景 参考资料 查看设备可支持的刷新率和分辨率 App设置设备帧率 Android Q及以下版本 Android R 背景随着手机屏幕硬件能力的提升，越来越多的厂商提供支持多档次刷新率的Android设备。而在Android Q上也是支持App指定当前屏幕帧率的，也有一套帧率分辨率切换的逻辑。 参考资料 https://zhuanlan.zhihu.com/p/142212769?from_voters_page=true 查看设备可支持的刷新率和分辨率使用命令：adb shell dumpsys display dump |grep -A 10 -iE “mSupportedModes” 这里设备使用的是OnePlus8Pro，结果如下: 12345mSupportedModes= DisplayModeRecord&#123;mMode=&#123;id=1, width=1080, height=2376, fps=60.000004&#125;&#125; DisplayModeRecord&#123;mMode=&#123;id=2, width=1440, height=3168, fps=120.00001&#125;&#125; DisplayModeRecord&#123;mMode=&#123;id=3, width=1440, height=3168, fps=60.000004&#125;&#125; DisplayModeRecord&#123;mMode=&#123;id=4, width=1080, height=2376, fps=120.00001&#125;&#125; 可以看到是有四种模式： 1080 + 60Hz 2K + 120Hz 2K + 60Hz 1080 + 120Hz App设置设备帧率Android Q及以下版本在Android Q或更低版本上，可以通过指定当前Window的帧率来设置屏幕刷新率，如选择设备可支持的最高刷新率： 12345678var highestMode: Display.Mode = mWindowManager!!.defaultDisplay.supportedModes[0]for (mode in mWindowManager!!.defaultDisplay.supportedModes) &#123; if (mode.refreshRate &gt; highestMode.refreshRate) &#123; highestMode = mode &#125;&#125;wmParams!!.preferredDisplayModeId = highestMode.modeId Android R如 Google建议利用可变刷新率 在较旧的 Android 版本 (Android 11 之前) 中并不存在 setFrameRate API，这时应用仍然可以通过直接将WindowManager.LayoutParams.preferredDisplayModeId设置为Display.getSupportedModes中的可用模式之一来影响刷新率。 从 Android 11 开始，我们不建议大家采用这种方法，因为平台会不知道应用的渲染意图。 例如，如果一个设备支持 48Hz、60Hz 和 120Hz，屏幕上有两个应用分别调用 setFrameRate(60, …) 和 setFrameRate(24, …)，那么平台可以选择 120Hz 来同时满足这两个应用。 而如果这些应用使用了preferredDisplayModeId，它们很可能会把模式设置为 60Hz 和 48Hz，那这时平台就无法使用 120Hz 了。这时平台只能从 60Hz 或 48Hz 中选择一个，从而影响到另一个应用的显示效果。 获取刷新率： SDK 通过 DisplayManager.DisplayListener 注册一个显示监听器，并通过 Display.getRefreshRate 查询刷新率。 2. NDK使用 AChoreographer_registerRefreshRateCallback 注册回调 (API 级别30)。 设置刷新率应用可以调用以下方法之一: SDK Surface.setFrameRate SurfaceControl.Transaction.setFrameRate NDK ANativeWindow_setRrameRate ASurfaceTransaction_setFrameRate","categories":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/categories/Android/"},{"name":"Vsync","slug":"Android/Vsync","permalink":"https://swallowjoe.github.io/categories/Android/Vsync/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/tags/Android/"},{"name":"Vsync","slug":"Vsync","permalink":"https://swallowjoe.github.io/tags/Vsync/"}]},{"title":"Looper-Android中的消息机制","slug":"Looper-Android中的消息机制","date":"2022-02-26T19:48:26.000Z","updated":"2022-02-26T19:57:34.959Z","comments":true,"path":"2022/02/27/Looper-Android中的消息机制/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Looper-Android%E4%B8%AD%E7%9A%84%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6/","excerpt":"简述本文详细分析android的消息机制Looper的底层原理。","text":"简述本文详细分析android的消息机制Looper的底层原理。 以下分析基于Android S. 初学Android的时候, 比较容易遇到如下错误: 1234567E AndroidRuntime: FATAL EXCEPTION: 非UI线程E AndroidRuntime: Process: com.android.demo, PID: 23939E AndroidRuntime: android.view.ViewRootImpl$CalledFromWrongThreadException: Only the original thread that created a view hierarchy can touch its views.E AndroidRuntime: at android.view.ViewRootImpl.checkThread(ViewRootImpl.java:9587)E AndroidRuntime: at android.view.ViewRootImpl.requestLayout(ViewRootImpl.java:1894)......E AndroidRuntime: at java.lang.Thread.run(Thread.java:923) 往往是我们在非UI线程更新UI组件导致的。解决的方案也很简单，将更新组件的操作移入UI线程执行即可。此时就需要用到Android中非常基础又非常重要的Handler、Looper、Message这三个类: 12345678910111213141516171819var uiHandler = UiHandler(Looper.getMainLooper())val message = uiHandler.obtainMessage(MSG_UPDATE_UI)message.obj = &quot;我在UI线程中更新UI组件哦!&quot;uiHandler.sendMessage(message)companion object &#123; const val MSG_UPDATE_UI = 0x1&#125;inner class UiHandler(looper: Looper) : Handler(looper) &#123; override fun handleMessage(msg: Message) &#123; super.handleMessage(msg) when (msg.what) &#123; MSG_UPDATE_UI -&gt; &#123; textview.text = msg.obj as String &#125; &#125; &#125;&#125; 如上，设置Handler的Looper为MainLooper，然后通过sendMessage将封装数据的Message发送到MainLooper代表的UI线程中处理，就这样切换了线程。接下来我们研究下其中的原理，为什么Looper有main looper, Handler的sendMessage是怎么找到对应线程，然后调用handleMessage的。 或者通过Looper prepare的方式， 其实也是获取主线程的Looper实现的: 123456789101112131415161718192021class Keep extends Thread &#123; public static final int MSG_A = 0x00; public static final int MSG_B = 0x00; public Handler handler; @Override public void run() &#123; Looper.prepare(); handler = new Handler() &#123; @Override public void handleMessage(Message msg) &#123; switch (msg.what) &#123; case MSG_A: &#123; /* .... */ &#125; break; case MSG_B: &#123; /* .... */ &#125; break; &#125; &#125; &#125;; Looper.loop(); &#125;&#125; 这样我们在需要的时候执行: handler.sendMessage(handler.obtain(MSG_A)) 即可以实现线程交换了, 除了sendMessage，还有如下方式: Android系统中大量使用Message来进行跨线程通信，实现交互，设计四个类：Message、Handler、Looper和MessageQueue, 类图如下: Message: 消息，封装待传递的数据 Handler: 消息辅助类，向消息池(MessageQueue)中存入消息和接收消息进行处理 Looper: 如其名，封装一个不断循环的函数体，不停的从消息池(MessageQueue)中取出合适的消息交给Handler处理 MessageQueue: 消息池，维护了一个由消息组成的链表，该链表按照消息执行的时间顺序排列 我们首先看看UI线程的Looper获取：Looper.getMainLooper() 一. Main Looper的创建1.1 Looper.getMainLooper12345public static Looper getMainLooper() &#123; synchronized (Looper.class) &#123; return sMainLooper; &#125;&#125; 返回的就是Looper中静态变量sMainLooper。那么该sMainLooper是何时创建的呢： 1.2 sMainLooper1234567891011public static void prepareMainLooper() &#123; // 1.2.1 Looper准备工作 prepare(false); synchronized (Looper.class) &#123; if (sMainLooper != null) &#123; throw new IllegalStateException(&quot;The main Looper has already been prepared.&quot;); &#125; // 1.2.3 myLooper拿的就是当前线程的Looper. sMainLooper = myLooper(); &#125;&#125; sMainLooper是在Looper.prepareMainLooper被第一次调用时赋值的。而prepareMainLooper是在ActivityThread.main函数中调用的: 123456789// ActivityThread.javapublic static void main(String[] args) &#123; ...... Looper.prepareMainLooper(); ...... // 1.3 执行loop Looper.loop(); throw new RuntimeException(&quot;Main thread loop unexpectedly exited&quot;);&#125; 在Zygote启动进程时，进程的入口函数是ActivityThread.main，也就是说三方进程启动后第一时间就会调用Looper.prepareMainLooper()设置sMainLooper。 1.2.1 Looper.prepare123456789101112public static void prepare() &#123; prepare(true);&#125;// quitAllowed 这个参数表明该Looper是否允许退出private static void prepare(boolean quitAllowed) &#123; if (sThreadLocal.get() != null) &#123; throw new RuntimeException(&quot;Only one Looper may be created per thread&quot;); &#125; // 1.2.2 注意这里创建了一个Looper, 并保存在sThreadLocal中 sThreadLocal.set(new Looper(quitAllowed));&#125; quitAllowed 这个参数表明该Looper是否允许退出，自然UI线程(主线程)是不允许退出的，除非被kill或者进程自杀。 这里稍微提一下，sThreadLocal是ThreadLocal类型，实现了线程本地存储区(Thread Local Storage, 简称TLS)。每个线程都有自己私有的存储区域，不同线程之间彼此不能访问对方的TSL区域。简单来说，可以将这里的 sThreadLocal 视为一个Map集合，其中key为Thread, value是Looper, 每次set和get都是获取当前线程对应的Looper 1.2.2 Looper 的创建12345private Looper(boolean quitAllowed) &#123; // 3.1 MessageQueue创建 mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread();&#125; 简单的创建了一个MessageQueue,并保存创建该Looper的线程。 1.2.3 Looper.myLooper123public static @Nullable Looper myLooper() &#123; return sThreadLocal.get();&#125; 通过sThreadLocal获取当前线程对应的Looper. 1.3 Looper.loop1234567891011121314151617181920212223242526public static void loop() &#123; // 获取当前线程的Looper final Looper me = myLooper(); // Looper一定存在某个线程中，线程不一定拥有Looper if (me == null) &#123; throw new RuntimeException(&quot;No Looper; Looper.prepare() wasn&#x27;t called on this thread.&quot;); &#125; // adb shell &#x27;setprop log.looper.1000.main.slow 1 &amp;&amp; stop &amp;&amp; start&#x27; // 用于修改记录Looper中的Message是否执行慢或者超时的时长 final int thresholdOverride = SystemProperties.getInt(&quot;log.looper.&quot; + Process.myUid() + &quot;.&quot; + Thread.currentThread().getName() + &quot;.slow&quot;, 0); // 如果有message分发超时，这个变量就会被标记为true me.mSlowDeliveryDetected = false; // 这个就是Loop名称的由来，一直循环 for (;;) &#123; if (!loopOnce(me, ident, thresholdOverride)) &#123; return; &#125; &#125;&#125; loop()函数很简单，就一直循环执行loopOnce就可 1.4 Looper.loopOnce123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100private static boolean loopOnce(final Looper me, final long ident, final int thresholdOverride) &#123; // 5.1 通过MessageQueue获取下一个Message, 这里稍后分析 Message msg = me.mQueue.next(); if (msg == null) &#123; // 获取的下一个Message为null，说明该Looper将要退出 return false; &#125; // mLogging是Printer的对象，可以通过: looper.setMessageLogging(printer)设置 // 用于打印Looper日志，如下： final Printer logging = me.mLogging; if (logging != null) &#123; logging.println(&quot;&gt;&gt;&gt;&gt;&gt; Dispatching to &quot; + msg.target + &quot; &quot; + msg.callback + &quot;: &quot; + msg.what); &#125; // Make sure the observer won&#x27;t change while processing a transaction. final Observer observer = sObserver; // traceTag用于抓取systrace，通过looper.setTraceTag设置 final long traceTag = me.mTraceTag; // mSlowDispatchThresholdMs和mSlowDeliveryThresholdMs默认都是0 // 可以通过setSlowLogThresholdMs设置 // 比如SystemServer主线程的looper就被分别设置为100ms，200ms long slowDispatchThresholdMs = me.mSlowDispatchThresholdMs; long slowDeliveryThresholdMs = me.mSlowDeliveryThresholdMs; if (thresholdOverride &gt; 0) &#123; // thresholdOverride可以通过属性修改:setprop log.looper.1000.main.slow 1 slowDispatchThresholdMs = thresholdOverride; slowDeliveryThresholdMs = thresholdOverride; &#125; final boolean logSlowDelivery = (slowDeliveryThresholdMs &gt; 0) &amp;&amp; (msg.when &gt; 0); final boolean logSlowDispatch = (slowDispatchThresholdMs &gt; 0); final boolean needStartTime = logSlowDelivery || logSlowDispatch; final boolean needEndTime = logSlowDispatch; // 开始抓取trace if (traceTag != 0 &amp;&amp; Trace.isTagEnabled(traceTag)) &#123; Trace.traceBegin(traceTag, msg.target.getTraceName(msg)); &#125; // 记录Message分发开始的时间 final long dispatchStart = needStartTime ? SystemClock.uptimeMillis() : 0; final long dispatchEnd; Object token = null; if (observer != null) &#123; token = observer.messageDispatchStarting(); &#125; long origWorkSource = ThreadLocalWorkSource.setUid(msg.workSourceUid); try &#123; // 1.4.1 分发message， 这里的target就是Handler msg.target.dispatchMessage(msg); if (observer != null) &#123; observer.messageDispatched(token, msg); &#125; // 记录消息分发结束时间 dispatchEnd = needEndTime ? SystemClock.uptimeMillis() : 0; &#125; catch (Exception exception) &#123; if (observer != null) &#123; observer.dispatchingThrewException(token, msg, exception); &#125; throw exception; &#125; finally &#123; ThreadLocalWorkSource.restore(origWorkSource); if (traceTag != 0) &#123; Trace.traceEnd(traceTag); &#125; &#125; if (logSlowDelivery) &#123; // mSlowDeliveryDetected 表明之前就有消息等待分发超时了 if (me.mSlowDeliveryDetected) &#123; // message分发时间和该message需要执行的时间相差不超过10ms，说明Message分发及时 // 去掉之前标记的消息分发超时 if ((dispatchStart - msg.when) &lt;= 10) &#123; Slog.w(TAG, &quot;Drained&quot;); me.mSlowDeliveryDetected = false; &#125; &#125; else &#123; // 这里就是检测Message等待分发是否超过阈值 // 打印的日志如： Looper: Slow delivery took 233ms android.ui h=com.XXX c=null m=31 if (showSlowLog(slowDeliveryThresholdMs, msg.when, dispatchStart, &quot;delivery&quot;, msg)) &#123; // Once we write a slow delivery log, suppress until the queue drains. me.mSlowDeliveryDetected = true; &#125; &#125; &#125; // 消息分发是否超时 // 打印的日志如： Looper: Slow dispatch took 233ms android.ui h=com.XXX c=null m=31 if (logSlowDispatch) &#123; showSlowLog(slowDispatchThresholdMs, dispatchStart, dispatchEnd, &quot;dispatch&quot;, msg); &#125; if (logging != null) &#123; logging.println(&quot;&lt;&lt;&lt;&lt;&lt; Finished to &quot; + msg.target + &quot; &quot; + msg.callback); &#125; ...... // 回收该Message msg.recycleUnchecked(); return true;&#125; loopOnce函数看起来也很简单，一直从MessageQueue中获取Message并执行Handler.handleMessage函数。除非拿到的message是null时返回false，否则永远返回true。注意弄清 delivery 和 dispatch 的区别： delivery: 消息被拿出准备分发的时间与消息期望被执行的时间差 dispatch: 消息处理的总时间，即handle.dispatchMessage的执行时长 1.4.1 Handler.dispatchMessage12345678910111213public void dispatchMessage(@NonNull Message msg) &#123; if (msg.callback != null) &#123; handleCallback(msg); &#125; else &#123; if (mCallback != null) &#123; if (mCallback.handleMessage(msg)) &#123; return; &#125; &#125; // 执行我们重载的函数了 handleMessage(msg); &#125;&#125; 我们知道在Handler.handleMessage这里已经转到Handler对应Looper所在的线程了。这样看起来，线程切换的奥秘都被隐藏在MessageQueue中了。 二. Message在分析MessageQueue之前，简单看一下Message的设计。 变量 类型 作用 what int 标明消息类别 arg1 int 参数1 arg2 int 参数2 obj Object 消息内容 when long 消息期望触发时间 data Bundle 消息附带内容 target Handler 消息触发执行的Handler callback Runnable 消息执行的Runnable next Message 下一个消息, 消息链表结构基础 2.1 消息链表结构1234567891011121314151617181920212223@UnsupportedAppUsage/*package*/ Message next;/** @hide */public static final Object sPoolSync = new Object();private static Message sPool;private static int sPoolSize = 0;private static final int MAX_POOL_SIZE = 50;public static Message obtain() &#123; synchronized (sPoolSync) &#123; if (sPool != null) &#123; Message m = sPool; sPool = m.next; m.next = null; m.flags = 0; // clear in-use flag sPoolSize--; return m; &#125; &#125; return new Message();&#125; 通过维护一个大小为50的Message缓冲池，来缓解Message频繁创建销毁带来的资源损耗，所以在开发过程中尽可能选择使用obtain来创建Message。 三. MessageQueue既然Message自己就维护了一个链表结构，还需要MessageQueue做什么呢？ 3.1 MessageQueue12345MessageQueue(boolean quitAllowed) &#123; mQuitAllowed = quitAllowed; // 3.2 通过JNI进入native实例化 mPtr = nativeInit();&#125; 设置mQuitAllowed, 主线程的Looper不允许退出(调用quit，主动退出)。然后通过JNI进入native层初始化 3.2 android_os_MessageQueue_nativeInit12345678910static jlong android_os_MessageQueue_nativeInit(JNIEnv* env, jclass clazz) &#123; NativeMessageQueue* nativeMessageQueue = new NativeMessageQueue(); if (!nativeMessageQueue) &#123; jniThrowRuntimeException(env, &quot;Unable to allocate native queue&quot;); return 0; &#125; nativeMessageQueue-&gt;incStrong(env); return reinterpret_cast&lt;jlong&gt;(nativeMessageQueue);&#125; 也就是创建了一个NativeMessageQueue的对象。 3.3 NativeMessageQueue1234567891011NativeMessageQueue::NativeMessageQueue() : mPollEnv(NULL), mPollObj(NULL), mExceptionObj(NULL) &#123; // 注意这里是native层的Loop了, 同样的也是通过TLS方式存储的 mLooper = Looper::getForThread(); if (mLooper == NULL) &#123; // 3.4 创建Looper mLooper = new Looper(false); // 保存在当前线程的TLS中 Looper::setForThread(mLooper); &#125;&#125; 3.4 Looper.cpp123456789101112131415161718Looper::Looper(bool allowNonCallbacks) : mAllowNonCallbacks(allowNonCallbacks), mSendingMessage(false), mPolling(false), mEpollRebuildRequired(false), mNextRequestSeq(0), mResponseIndex(0), mNextMessageUptime(LLONG_MAX) &#123; // eventfd函数会创建一个eventfd, 这里保存在mWakeEventFd中 // EFD_NONBLOCK: 设置FD对象为非阻塞状态 // EFD_CLOEXEC: 调用exec后会自动关闭文件描述符，防止泄漏 mWakeEventFd.reset(eventfd(0, EFD_NONBLOCK | EFD_CLOEXEC)); LOG_ALWAYS_FATAL_IF(mWakeEventFd.get() &lt; 0, &quot;Could not make wake event fd: %s&quot;, strerror(errno)); AutoMutex _l(mLock); // 3.4.1 重建epoll rebuildEpollLocked();&#125; eventfd 是 Linux 的一个系统调用，创建一个文件描述符用于事件通知，自 Linux 2.6.22 以后开始支持。该函数会创建一个 eventfd 对象，用户空间的应用程序可以用这个 eventfd 来实现事件的等待或通知机制，也可以用于内核通知新的事件到用户空间应用程序。 看来初始化该Looper的线程是通过这个eventfd来实现被唤醒的。 3.4.1 Looper.cpp:rebuildEpollLocked123456789101112131415161718192021222324252627282930313233void Looper::rebuildEpollLocked() &#123; // 如果原有fd存在，则关闭 if (mEpollFd &gt;= 0) &#123; mEpollFd.reset(); &#125; // 创建一个新的epoll实例, 并获取该实例的fd标记 mEpollFd.reset(epoll_create1(EPOLL_CLOEXEC)); LOG_ALWAYS_FATAL_IF(mEpollFd &lt; 0, &quot;Could not create epoll instance: %s&quot;, strerror(errno)); struct epoll_event eventItem; memset(&amp; eventItem, 0, sizeof(epoll_event)); // EPOLLIN 表明fd文件可读 eventItem.events = EPOLLIN; eventItem.data.fd = mWakeEventFd.get(); // 在epoll实例上注册mWakeEventFd文件描述符，并将EPOLL_CTL_ADD事件关联到mWakeEventFd int result = epoll_ctl(mEpollFd.get(), EPOLL_CTL_ADD, mWakeEventFd.get(), &amp;eventItem); LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not add wake event fd to epoll instance: %s&quot;, strerror(errno)); // 对所有mRequests的fd进行重定向, 均关联到新创建的epoll实例上 for (size_t i = 0; i &lt; mRequests.size(); i++) &#123; const Request&amp; request = mRequests.valueAt(i); struct epoll_event eventItem; request.initEventItem(&amp;eventItem); int epollResult = epoll_ctl(mEpollFd.get(), EPOLL_CTL_ADD, request.fd, &amp;eventItem); if (epollResult &lt; 0) &#123; ALOGE(&quot;Error adding epoll events for fd %d while rebuilding epoll set: %s&quot;, request.fd, strerror(errno)); &#125; &#125;&#125; 这里主要是创建了一个epoll实例，并将该Looper的mWakeEventFd（即eventfd）关联到该epoll实例上。如果该Looper的mRequests存在Request时，也对所有mRequests的fd进行重定向, 均关联到新创建的epoll实例上。 所以MessageQueue的初始化就是在Native层创建了一个NativeMessageQueue的对象，该对象持有一个Native层的Looper对象。而Native层的Looper里有两个文件描述符: 通过eventfd创建的mWakeEventFd; 通过epoll_create1创建的代表epoll实例的mEpollFd。 四. sendMessageAtTime发送消息现在回到Handler发送消息，假设Handler中的Looper是MainLooper, 现在是在非UI线程，比如bg线程读取网络数据后更新到UI组件上：uiHandler.sendMessageAtTime 123456789101112131415161718192021222324public boolean sendMessageAtTime(@NonNull Message msg, long uptimeMillis) &#123; MessageQueue queue = mQueue; if (queue == null) &#123; RuntimeException e = new RuntimeException( this + &quot; sendMessageAtTime() called with no mQueue&quot;); Log.w(&quot;Looper&quot;, e.getMessage(), e); return false; &#125; return enqueueMessage(queue, msg, uptimeMillis);&#125;private boolean enqueueMessage(@NonNull MessageQueue queue, @NonNull Message msg, long uptimeMillis) &#123; // 将Message的target设置为自己 msg.target = this; msg.workSourceUid = ThreadLocalWorkSource.getUid(); // mAsynchronous表明是否异步执行 if (mAsynchronous) &#123; msg.setAsynchronous(true); &#125; // 交给Handler的MessageQueue执行 return queue.enqueueMessage(msg, uptimeMillis);&#125; 4.1 MessageQueue.enqueueMessage12345678910111213141516171819202122232425262728293031323334353637383940414243444546boolean enqueueMessage(Message msg, long when) &#123; ...... synchronized (this) &#123; ...... // 标记该Message正在使用, 避免缓冲池重复使用该Message msg.markInUse(); // 记录该Message期望执行的时间 msg.when = when; // mMessages是一个Message对象，代表该MessageQueue队列的头节点 Message p = mMessages; boolean needWake; if (p == null || when == 0 || when &lt; p.when) &#123; // 如果头节点是空的、传入的Message执行时间是0（立刻执行） // 或者执行时间在头节点消息执行之前，将该Message作为链表新的头节点 msg.next = p; mMessages = msg; // mBlocked为false代表Handler所在线程已经拿到合适的Message执行了 needWake = mBlocked; &#125; else &#123; // 将Message插入到链表头节点之后 needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous(); Message prev; // 找到该Message的位置，即其执行时间在链表中的顺序排列位置 for (;;) &#123; prev = p; p = p.next; if (p == null || when &lt; p.when) &#123; break; &#125; if (needWake &amp;&amp; p.isAsynchronous()) &#123; needWake = false; &#125; &#125; msg.next = p; // invariant: p == prev.next prev.next = msg; &#125; // 是否需要唤醒, 唤醒什么，当然是Handler的Looper对应线程了！ if (needWake) &#123; // 进入JNI, 通过epoll唤醒线程 nativeWake(mPtr); &#125; &#125; return true;&#125; 所以Handler.sendMessage仅仅是将Message插入MessageQueue中Message链表的合适位置，即保持mMessages链表中的Message期望执行时间从小到大排列，等待执行。 4.2 android_os_MessageQueue_nativeWake12345678static void android_os_MessageQueue_nativeWake(JNIEnv* env, jclass clazz, jlong ptr) &#123; NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); nativeMessageQueue-&gt;wake();&#125;void NativeMessageQueue::wake() &#123; mLooper-&gt;wake();&#125; 转到native层的loop执行。 4.3 Looper.cpp:wake1234567891011void Looper::wake() &#123; uint64_t inc = 1; // 通过write向该Looper的mWakeEventFd中写入1 ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd.get(), &amp;inc, sizeof(uint64_t))); if (nWrite != sizeof(uint64_t)) &#123; if (errno != EAGAIN) &#123; LOG_ALWAYS_FATAL(&quot;Could not write wake signal to fd %d (returned %zd): %s&quot;, mWakeEventFd.get(), nWrite, strerror(errno)); &#125; &#125;&#125; 到这里，bg线程中uiHandler发送Message的流程就结束了。 五. UI线程处理Message那么此时我们UI线程在做什么呢? 对了，就是一直在循环执行 Looper中的 loopOnce 函数！ 123456private static boolean loopOnce(final Looper me, final long ident, final int thresholdOverride) &#123; // 5.1 通过MessageQueue获取下一个Message Message msg = me.mQueue.next(); ......&#125; 5.1 MessageQueue.next1234567891011Message next() &#123; ...... int pendingIdleHandlerCount = -1; // -1 only during first iteration int nextPollTimeoutMillis = 0; for (;;) &#123; ...... // 5.2 转到Native中执行，获取下一次poll的时间 nativePollOnce(ptr, nextPollTimeoutMillis); ...... &#125;&#125; 直接转到native层执行pollOnce. 5.2 android_os_MessageQueue_nativePollOnce1234567891011121314151617181920static void android_os_MessageQueue_nativePollOnce(JNIEnv* env, jobject obj, jlong ptr, jint timeoutMillis) &#123; NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); nativeMessageQueue-&gt;pollOnce(env, obj, timeoutMillis);&#125;void NativeMessageQueue::pollOnce(JNIEnv* env, jobject pollObj, int timeoutMillis) &#123; mPollEnv = env; mPollObj = pollObj; // 还是用到Native层的Looper mLooper-&gt;pollOnce(timeoutMillis); mPollObj = NULL; mPollEnv = NULL; if (mExceptionObj) &#123; env-&gt;Throw(mExceptionObj); env-&gt;DeleteLocalRef(mExceptionObj); mExceptionObj = NULL; &#125;&#125; 5.3 Looper.cpp:pollOnce123456789101112131415161718192021222324252627282930313233inline int pollOnce(int timeoutMillis) &#123; return pollOnce(timeoutMillis, nullptr, nullptr, nullptr);&#125;int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) &#123; int result = 0; for (;;) &#123; // 当前mResponses还是空的，mResponseIndex为0 while (mResponseIndex &lt; mResponses.size()) &#123; const Response&amp; response = mResponses.itemAt(mResponseIndex++); int ident = response.request.ident; if (ident &gt;= 0) &#123; int fd = response.request.fd; int events = response.events; void* data = response.request.data; if (outFd != nullptr) *outFd = fd; if (outEvents != nullptr) *outEvents = events; if (outData != nullptr) *outData = data; return ident; &#125; &#125; // result为0, 表明poll超时 if (result != 0) &#123; if (outFd != nullptr) *outFd = 0; if (outEvents != nullptr) *outEvents = 0; if (outData != nullptr) *outData = nullptr; return result; &#125; // 先执行这里 result = pollInner(timeoutMillis); &#125;&#125; 5.4 Looper.cpp:pollInner123456789101112131415161718192021222324252627282930313233343536373839404142int Looper::pollInner(int timeoutMillis) &#123; ...... // Poll. int result = POLL_WAKE; mResponses.clear(); mResponseIndex = 0; // 标记正在poll mPolling = true; // EPOLL_MAX_EVENTS默认是16 struct epoll_event eventItems[EPOLL_MAX_EVENTS]; // 通过epoll_wait监听mEpollFd文件描述符等待被唤醒, 注意这里timeoutMillis是0 // 也就是说当mEpollFd没有事件时，立刻返回超时 0 int eventCount = epoll_wait(mEpollFd.get(), eventItems, EPOLL_MAX_EVENTS, timeoutMillis); ...... // poll超时，在执行一次Looper.pollOnce的循环 if (eventCount == 0) &#123; result = POLL_TIMEOUT; goto Done; &#125; // epoll中存在事件 for (int i = 0; i &lt; eventCount; i++) &#123; int fd = eventItems[i].data.fd; uint32_t epollEvents = eventItems[i].events; // 当epoll中事件描述符是当前Looper的mWakeEventFd时, 说明有线程通过write向该fd写入值 if (fd == mWakeEventFd.get()) &#123; if (epollEvents &amp; EPOLLIN) &#123; // 5.5 执行被唤醒后的处理 awoken(); &#125; else &#123; ALOGW(&quot;Ignoring unexpected epoll events 0x%x on wake event fd.&quot;, epollEvents); &#125; &#125; ...... &#125;Done: ; ...... return result;&#125; int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待事件的产生，类似于select()调用。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。如果返回–1，则表示出现错误。 epfd是 epoll的描述符。 events则是分配好的 epoll_event结构体数组，epoll将会把发生的事件复制到 events数组中 maxevents表示本次可以返回的最大事件数目，通常 maxevents参数与预分配的events数组的大小是相等的。 timeout表示在没有检测到事件发生时最多等待的时间（单位为毫秒），如果 timeout为0，则表示 epoll_wait在 rdllist链表中为空，立刻返回，不会等待。 5.5 Looper.cpp:awoken1234void Looper::awoken() &#123; uint64_t counter; TEMP_FAILURE_RETRY(read(mWakeEventFd.get(), &amp;counter, sizeof(uint64_t)));&#125; 读取mWakeEventFd中的值，也就是之前bg线程通过write写入的1. 然后回到Looper.cpp:pollOnce返回1. 这样UI线程就从epoll_wait阻塞状态(或者一直执行Looper.cpp:pollOnce函数的状态)退出，之后回到java层的MessageQueue.next中继续执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445Message next() &#123; ...... int pendingIdleHandlerCount = -1; // -1 only during first iteration int nextPollTimeoutMillis = 0; for (;;) &#123; ...... // 5.2 转到Native中执行，获取下一次poll的时间 nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) &#123; // 记录当前系统时间 final long now = SystemClock.uptimeMillis(); Message prevMsg = null; Message msg = mMessages; ...... // 尝试找到抵达执行时间的Message if (msg != null) &#123; if (now &lt; msg.when) &#123; // 如果头节点Message的执行时间尚未到来，那么下一次epoll_wait的等待时间就是 // 该message执行时间和当前时间的差值 nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); &#125; else &#123; // 找到可执行的Message了 mBlocked = false; if (prevMsg != null) &#123; prevMsg.next = msg.next; &#125; else &#123; // 头节点标记为下一个 mMessages = msg.next; &#125; msg.next = null; if (DEBUG) Log.v(TAG, &quot;Returning message: &quot; + msg); msg.markInUse(); // 打破循环，返回该Message，回到Looper.loopOnce中 // 即执行 [1.4.1] Handler.dispatchMessage return msg; &#125; &#125; else &#123; // No more messages. nextPollTimeoutMillis = -1; &#125; ...... &#125; &#125;&#125; 自此，Android的线程切换就结束了。 六. 小结通过上述分析，画一张图来展示一次Message的执行: 6.1 Epoll机制关于Eopll推荐大家阅读这篇文: Epoll本质 https://zhuanlan.zhihu.com/p/63179839 cpu running Ui Thread: epoll_wait Bg Thread: write fd Ui Thread: read","categories":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/categories/Android/"},{"name":"Looper","slug":"Android/Looper","permalink":"https://swallowjoe.github.io/categories/Android/Looper/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/tags/Android/"},{"name":"Looper","slug":"Looper","permalink":"https://swallowjoe.github.io/tags/Looper/"}]},{"title":"Vulkan入门(15)-图像视图和采样器","slug":"Vulkan入门-15-图像视图和采样器","date":"2022-02-26T19:35:34.000Z","updated":"2022-02-26T19:44:47.967Z","comments":true,"path":"2022/02/27/Vulkan入门-15-图像视图和采样器/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-15-%E5%9B%BE%E5%83%8F%E8%A7%86%E5%9B%BE%E5%92%8C%E9%87%87%E6%A0%B7%E5%99%A8/","excerpt":"简述回顾上一篇章中的读取图像的步骤: 首先利用stb-image库读取图片，将其内容存储在临时缓存区VkBuffer中，注意需要开辟GPU可见内存 通过VkImageCreateInfo结构指明图像格式并通过vkCreateImage创建VkImage对象 用VkBuffer图像文件中的像素填充创建的VkImage图像对象 填充图像对象需要使用VkImageMemoryBarrier 使用vkCmdPipelineBarrier使得图像填充Barrier生效 通过vkCmdCopyBufferToImage完成图像像素从VkBuffer到VkImage的拷贝(填充) 再通过VkImageMemoryBarrier指定图像是能够从着色器中的纹理图像开始采样 创建图像视图和图像采样器 添加一个组合的图像采样器描述符来从纹理中采样颜色 在图像采样器创建之前，我们首先看看纹理图像视图，这个是在我们创建交换链的时候见过:","text":"简述回顾上一篇章中的读取图像的步骤: 首先利用stb-image库读取图片，将其内容存储在临时缓存区VkBuffer中，注意需要开辟GPU可见内存 通过VkImageCreateInfo结构指明图像格式并通过vkCreateImage创建VkImage对象 用VkBuffer图像文件中的像素填充创建的VkImage图像对象 填充图像对象需要使用VkImageMemoryBarrier 使用vkCmdPipelineBarrier使得图像填充Barrier生效 通过vkCmdCopyBufferToImage完成图像像素从VkBuffer到VkImage的拷贝(填充) 再通过VkImageMemoryBarrier指定图像是能够从着色器中的纹理图像开始采样 创建图像视图和图像采样器 添加一个组合的图像采样器描述符来从纹理中采样颜色 在图像采样器创建之前，我们首先看看纹理图像视图，这个是在我们创建交换链的时候见过: 一. 纹理图像视图 Texture Image View通过VkImageView类来存储纹理图像视图, 它描述了如何访问图像以及要访问的图像部分，创建VkImageView的方式也是通过一个结构体：VkImageViewCreateInfo, 来指明细节. 这部分我们在之前的交换链创建图像视图中有过接触，如果忘记了的话可以回顾一下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061VkImageView textureImageView;void initVulkan() &#123; ... createTextureImage(); createTextureImageView(); createVertexBuffer(); ...&#125;VkImageView createImageView(VkImage image, VkFormat format) &#123; VkImageView imageView; VkImageViewCreateInfo viewInfo = &#123;&#125;; viewInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO; viewInfo.image = image; // 绑定 VkImage // viewType和format字段指定应如何解释图像数据 // viewType参数指定图像为一维纹理，二维纹理，三维纹理或立方体贴图 viewInfo.viewType = VK_IMAGE_VIEW_TYPE_2D; // 图像格式 viewInfo.format = format; // subresourceRange字段描述了图像的目的是什么以及应该访问图像的哪个部分。 // 这里图像将用作颜色目标，没有任何mipmapping级别或多个层。 viewInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; viewInfo.subresourceRange.baseMipLevel = 0; viewInfo.subresourceRange.levelCount = 1; viewInfo.subresourceRange.baseArrayLayer = 0; viewInfo.subresourceRange.layerCount = 1; // 注意，通过vkCreateXXX创建的对象，不需要时要主动去释放 if (vkCreateImageView(device, &amp;viewInfo, nullptr, &amp;imageView) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create image views!&quot;); &#125; return imageView;&#125;void createImageViews() &#123; // 设置集合大小 swapChainImageViews.resize(swapChainImages.size()); for (size_t i = 0; i &lt; swapChainImageViews.size(); i++) &#123; swapChainImageViews[i] = createImageView(swapChainImages[i], swapChainImageFormat); &#125;&#125;void createTextureImageView() &#123; textureImageView = createImageView(textureImage, VK_FORMAT_R8G8B8A8_UNORM);&#125;// 在 vulkan 中推荐在创建的资源不需要后主动释放void cleanup() &#123; // 清理交换链关联资源 cleanupSwapChain(); // 清理纹理贴图 vkDestroyImageView(device, textureImageView, nullptr); vkDestroyImage(device, textureImage, nullptr); vkFreeMemory(device, textureImageMemory, nullptr); ...&#125; 如上，纹理图像的视图创建成功了，很简单。接下来就是采样器的创建了。 二. 采样器着色器可以直接从图像读取纹理像素，但是当将其用作纹理时，一般不会直接读取。 通常通过采样器访问纹理，采样器将应用过滤和转换以计算最终获取的颜色。 这些过滤器有助于处理过采样等问题。 考虑一个映射到几何图形的纹理，该纹理的碎片多于纹理像素。 如果只是在每个片段中使用最接近的纹理像素作为纹理坐标，那么将获得下图左边图像的结果： 而通过线性插值法将4个最接近的纹理像素组合在一起，那么将获得如上右图所示的更平滑的结果。 当然，您的应用程序可能具有更适合左侧风格的艺术风格要求（比如Minecraft，哈哈），但是在常规图形应用程序中，右侧风格是首选，图像越精细越好。 从纹理读取颜色时，采样器对象会自动为您应用此过滤。 抽样不足(欠采样)则是相反的问题，比如纹理像素多于片段。这将导致在以锐角采样高频图案(如棋盘纹理)时产生伪影: 如左图所示，纹理在远处变得模糊混乱。解决这个问题的方法是各向异性滤波，它也可以由采样器自动应用。 除了这些过滤器，采样器还可以处理转换。它决定当你试图通过它的寻址模式读取图像外的texel时会发生什么。下面的图片显示了一些可能性: 2.1 createTextureSampler现在创建一个函数createTextureSampler来设置这样的采样对象。稍后我们将在着色器中使用采样器从纹理中读取颜色: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061VkImageView textureImageView;VkSampler textureSampler;...void initVulkan() &#123; ... createTextureImage(); createTextureImageView(); createTextureSampler(); ...&#125;void createTextureSampler() &#123; // 采样器通过VkSamplerCreateInfo结构进行配置，该结构指定了应应用的所有过滤器和转换。 VkSamplerCreateInfo samplerInfo = &#123;&#125;; samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO; // magFilter和minFilter字段指定如何对放大或缩小的纹理像素进行插值。 // 放大倍数与上面描述的过采样问题有关，而缩小倍数与欠采样有关。 // 指定要应用于查找的放大滤镜为线性过滤 samplerInfo.magFilter = VK_FILTER_LINEAR; // 指定要应用于查找的缩小过滤器为线性过滤 samplerInfo.minFilter = VK_FILTER_LINEAR; // 指定U、V、W坐标的[0..1]范围之外的寻址模式, 指定当超出图像尺寸时，重复纹理 // 注意，轴称为U，V和W，而不是X，Y和Z。这是纹理空间坐标的约定 samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT; samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT; samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT; // anisotropyEnable为true, 采样器使用使用各向异性过滤 samplerInfo.anisotropyEnable = VK_TRUE; samplerInfo.maxAnisotropy = 16; // borderColor字段指定在使用边界寻址模式对图像进行采样以外时返回的颜色。 // 可以以float或int格式返回黑色，白色或透明。 samplerInfo.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK; // 指定要用于处理图像中纹理像素的坐标系 // 为VK_FALSE，则将使用所有轴上的[0，1）范围对纹理像素进行寻址 samplerInfo.unnormalizedCoordinates = VK_FALSE; // 如果启用了比较功能，则将首先将纹理像素与一个值进行比较，并且该比较的结果将用于过滤操作中。 主要用于阴影贴图上的百分比封闭器过滤。 samplerInfo.compareEnable = VK_FALSE; samplerInfo.compareOp = VK_COMPARE_OP_ALWAYS; // 所有这些字段都适用于mipmapping。以后讨论mipmapping samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR; samplerInfo.mipLodBias = 0.0f; samplerInfo.minLod = 0.0f; samplerInfo.maxLod = 0.0f; // 创建采样器，注意清理 if (vkCreateSampler(device, &amp;samplerInfo, nullptr, &amp;textureSampler) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create texture sampler!&quot;); &#125;&#125;void cleanup() &#123; cleanupSwapChain(); // 清理采样器 vkDestroySampler(device, textureSampler, nullptr); ...&#125; samplerInfo中的anisotropyEnable和maxAnisotropy这两个字段指定是否应该使用各向异性过滤。最大各向异性字段限制了可以用来计算最终颜色的texel样本的数量。数值越低，性能越好，但质量越低。目前没有任何图形硬件可以使用超过16个样本，因为超过这个值的差异就可以忽略不计了。 unnormalizedCoordinates字段指定要用于处理图像中纹理像素的坐标系。 如果此字段为VK_TRUE，则可以简单地使用[0，texWidth）和[0，texHeight）范围内的坐标。 如果为VK_FALSE，则将使用所有轴上的[0，1）范围对纹理像素进行寻址。 实际应用中几乎总是使用归一化的坐标，因为这样一来，便可以使用分辨率完全相同的不同分辨率的纹理。 请注意，采样器未在任何地方引用VkImage。 采样器是一个独特的对象，它提供了一个接口来从纹理中提取颜色。 它可以应用于所需的任何图像，无论是1D，2D还是3D。 这与许多较早的API不同，后者将纹理图像和过滤合并为一个状态。 2.2 VkSamplerCreateInfoVkSamplerCreateInfo结构体指定了采样器对象的状态： 1234567891011121314151617181920typedef struct VkSamplerCreateInfo &#123; VkStructureType sType; const void* pNext; VkSamplerCreateFlags flags; VkFilter magFilter; VkFilter minFilter; VkSamplerMipmapMode mipmapMode; VkSamplerAddressMode addressModeU; VkSamplerAddressMode addressModeV; VkSamplerAddressMode addressModeW; float mipLodBias; VkBool32 anisotropyEnable; float maxAnisotropy; VkBool32 compareEnable; VkCompareOp compareOp; float minLod; float maxLod; VkBorderColor borderColor; VkBool32 unnormalizedCoordinates;&#125; VkSamplerCreateInfo; sType是此结构的类型， VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO pNext是NULL或指向扩展特定结构的指针 flag是VkSamplerCreateFlagBits的位掩码，描述了采样器的其他参数 magFilter是VkFilter值，用于指定要应用于查找的放大滤镜 VK_FILTER_NEAREST 指定最近的过滤 VK_FILTER_LINEAR 指定线性过滤 VK_FILTER_CUBIC_EXT 指定三次过滤 VK_FILTER_CUBIC_IMG 指定三次过滤，同VK_FILTER_CUBIC_EXT minFilter是一个VkFilter值，用于指定要应用于查找的缩小过滤器 mipmapMode是VkSamplerMipmapMode值，指定要应用于查找的mipmap过滤器 addressModeU是VkSamplerAddressMode值，用于为U坐标指定[0..1]范围之外的寻址模式 VK_SAMPLER_ADDRESS_MODE_REPEAT 当超出图像尺寸时，重复纹理 VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT 类似于重复，但是当超出尺寸时会反转坐标以镜像图像 VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE 在图像尺寸之外，获取最靠近坐标的边缘的颜色 VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER 当采样超出图像尺寸时，返回纯色 VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE 类似CLAMP_TO_EDGE，但使用与最近边缘相反的边缘,仅在启用samplerMirrorClampToEdge或启用[VK_KHR_sampler_mirror_clamp_to_edge]扩展名后才有效 addressModeV是VkSamplerAddressMode值，用于指定V坐标的[0..1]范围之外的寻址模式 addressModeW是VkSamplerAddressMode值，它为W坐标指定[0..1]范围之外的寻址模式 mipLodBias是要添加到mipmap LOD（详细程度）计算中的偏差，以及由SPIR-V中的图像采样功能提供的偏差 anisotropyEnable为VK_TRUE以启用各向异性过滤，如“ Texel各向异性过滤”部分所述，否则为VK_FALSE maxAnisotropy是anisotropyEnable为VK_TRUE时采样器使用的各向异性值钳位。如果anisotropyEnable为VK_FALSE，则maxAnisotropy被忽略 compareEnable为VK_TRUE，以允许在查找过程中与参考值进行比较，否则为VK_FALSE 注意：如果此成员不匹配，则某些实现将默认为着色器状态 compareOp是一个VkCompareOp值，它指定比较功能，以按“深度比较操作”部分所述在过滤之前将其应用于获取的数据 minLod和maxLod是用于钳位计算的LOD值的值 borderColor是VkBorderColor值，用于指定要使用的预定义边框颜色 unnormalizedCoordinates指定要用于处理图像中纹理像素的坐标系。设置为VK_TRUE时，用于查找纹理像素的图像坐标的范围在0到x，y和z的图像尺寸的范围内。设置为VK_FALSE时，图像坐标范围为零到一。 当unnormalizedCoordinates为VK_TRUE时，在着色器中使用采样器的图像具有以下要求： viewType必须为VK_IMAGE_VIEW_TYPE_1D或VK_IMAGE_VIEW_TYPE_2D 图像视图必须具有单个图层和单个mip级别 当unnormalizedCoordinates为VK_TRUE时，使用采样器的着色器中的图像内置函数具有以下要求： 这些功能不得使用投影 这些函数不得使用偏移量 2.3 vkCreateSamplerVkSampler对象表示图像采样器的状态，实现可使用该对象读取图像数据并为着色器应用过滤和其他转换。 12345VkResult vkCreateSampler( VkDevice device, const VkSamplerCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSampler* pSampler); device是创建采样器的逻辑设备 pCreateInfo是指向VkSamplerCreateInfo结构的指针，该结构指定采样器对象的状态 pAllocator控制主机内存分配 pSampler是指向VkSampler句柄的指针，在该句柄中返回生成的采样器对象 2.4 设备功能之各向异性过滤如果现在运行程序，则会看到如下所示的验证层消息： 这是因为各向异性过滤实际上是一个可选的设备特性。我们需要更新createLogicalDevice函数来请求它: 12VkPhysicalDeviceFeatures deviceFeatures = &#123;&#125;;deviceFeatures.samplerAnisotropy = VK_TRUE; 即使现在的显卡不支持它的可能性很小，我们也应该更新isDeviceSuitable来检查它是否可用: 1234567bool isDeviceSuitable(VkPhysicalDevice device) &#123; ... VkPhysicalDeviceFeatures supportedFeatures; vkGetPhysicalDeviceFeatures(device, &amp;supportedFeatures); return indices.isComplete() &amp;&amp; extensionsSupported &amp;&amp; swapChainAdequate &amp;&amp; supportedFeatures.samplerAnisotropy;&#125; vkGetPhysicalDeviceFeatures重新调整VkPhysicalDeviceFeatures结构的用途，通过设置布尔值来指示支持哪些功能，而不是请求哪些功能。 除了强制各向异性过滤的可用性，也可以通过条件设置不使用它: 12samplerInfo.anisotropyEnable = VK_FALSE;samplerInfo.maxAnisotropy = 1; 2.5 小结现在图像有了，接下来，我们将向着色器公开图像和采样器对象，以便将纹理绘制到正方形上并呈现出来。 三. 组合图像采样器我们在统一缓冲区部分中了解了描述符。 现在我们看一种新型的描述符：组合图像采样器。 该描述符使着色器可以通过采样器对象访问图像资源。 我们将从修改描述符布局，描述符池和描述符集开始，以包括此类组合的图像采样器描述符。 之后，我们将向顶点添加纹理坐标，并修改片段着色器以从纹理读取颜色，而不仅仅是插入顶点颜色。 3.1 更新描述符回到createDescriptorSetLayout函数，为组合的图像采样器描述符添加VkDescriptorSetLayoutBinding。 将其放在统一缓冲区之后的绑定中： 12345678910111213141516171819202122232425262728293031323334void createDescriptorSetLayout() &#123; VkDescriptorSetLayoutBinding uboLayoutBinding = &#123;&#125;; // 指定在着色器中使用的绑定 uboLayoutBinding.binding = 0; // 描述符的类型 uboLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; uboLayoutBinding.descriptorCount = 1; // 指定描述符将在顶点着色器阶段被引用 uboLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT; // pImmutableSamplers仅与图像采样描述符有关 uboLayoutBinding.pImmutableSamplers = nullptr; // 创建采样器描述符 VkDescriptorSetLayoutBinding samplerLayoutBinding = &#123;&#125;; samplerLayoutBinding.binding = 1; samplerLayoutBinding.descriptorCount = 1; samplerLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER; samplerLayoutBinding.pImmutableSamplers = nullptr; // 指明片段着色器阶段可以使用组合的图像采样器描述符, 那就是片段颜色确定的地方。 // 可以在顶点着色器中使用纹理采样，例如通过高度图使顶点网格动态变形。 samplerLayoutBinding.stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT; std::array&lt;VkDescriptorSetLayoutBinding, 2&gt; bindings = &#123;uboLayoutBinding, samplerLayoutBinding&#125;; VkDescriptorSetLayoutCreateInfo layoutInfo = &#123;&#125;; layoutInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO; layoutInfo.bindingCount = static_cast&lt;uint32_t&gt;(bindings.size()); layoutInfo.pBindings = bindings.data(); // 创建描述符集布局 if (vkCreateDescriptorSetLayout(device, &amp;layoutInfo, nullptr, &amp;descriptorSetLayout) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create descriptor set layout!&quot;); &#125;&#125; 如果您现在运行带有验证层的应用程序，那么会发现描述符池无法使用此布局分配描述符集，因为它没有任何组合的图像采样器描述符。 转到createDescriptorPool函数并对其进行修改，以包括此描述符的VkDescriptorPoolSize： 1234567891011121314151617181920212223242526void createDescriptorPool() &#123; VkDescriptorPoolSize poolSize = &#123;&#125;; // 我们创建的是统一缓冲的描述符 poolSize.type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; poolSize.descriptorCount = static_cast&lt;uint32_t&gt;(swapChainImages.size()); std::array&lt;VkDescriptorPoolSize, 2&gt; poolSizes = &#123;&#125;; // 第一个是统一缓冲区描述符 poolSizes[0].type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; poolSizes[0].descriptorCount = static_cast&lt;uint32_t&gt;(swapChainImages.size()); // 第二个是纹理图像采样器描述符 poolSizes[1].type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER; poolSizes[1].descriptorCount = static_cast&lt;uint32_t&gt;(swapChainImages.size()); VkDescriptorPoolCreateInfo poolInfo = &#123;&#125;; poolInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO; poolInfo.poolSizeCount = static_cast&lt;uint32_t&gt;(poolSizes.size()); poolInfo.pPoolSizes = poolSizes.data(); // 除了可用的单个描述符的最大数量外，还需要指定可以分配的最大描述符集数量：与交换链图像数量一致 poolInfo.maxSets = static_cast&lt;uint32_t&gt;(swapChainImages.size()); // 创建描述符池 if (vkCreateDescriptorPool(device, &amp;poolInfo, nullptr, &amp;descriptorPool) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create descriptor pool!&quot;); &#125;&#125; 最后一步是将实际图像和采样器资源绑定到描述符集中的描述符。 转到createDescriptorSets函数: 123456789101112131415161718192021222324252627282930313233343536373839void createDescriptorSets() &#123; ... // 配置描述符 for (size_t i = 0; i &lt; descriptorSets.size(); i++) &#123; ... // 绑定图像视图和采样器到描述符中 VkDescriptorImageInfo imageInfo = &#123;&#125;; imageInfo.imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL; // 必须在VkDescriptorImageInfo结构中指定用于组合图像采样器结构的资源 imageInfo.imageView = textureImageView; imageInfo.sampler = textureSampler; std::array&lt;VkWriteDescriptorSet, 2&gt; descriptorWrites = &#123;&#125;; descriptorWrites[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET; descriptorWrites[0].dstSet = descriptorSets[i]; descriptorWrites[0].dstBinding = 0; descriptorWrites[0].dstArrayElement = 0; // 绑定统一缓冲区至描述符 descriptorWrites[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; descriptorWrites[0].descriptorCount = 1; descriptorWrites[0].pBufferInfo = &amp;bufferInfo; descriptorWrites[1].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET; descriptorWrites[1].dstSet = descriptorSets[i]; descriptorWrites[1].dstBinding = 1; descriptorWrites[1].dstArrayElement = 0; // 绑定图像视图和相应的采样器至描述符 descriptorWrites[1].descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER; descriptorWrites[1].descriptorCount = 1; descriptorWrites[1].pImageInfo = &amp;imageInfo; // 应用描述符集更新 vkUpdateDescriptorSets(device, static_cast&lt;uint32_t&gt;(descriptorWrites.size()), descriptorWrites.data(), 0, nullptr); &#125;&#125; 必须在VkDescriptorImageInfo结构中指定用于组合图像采样器结构的资源，就像在VkDescriptorBufferInfo结构中指定用于统一缓冲区描述符的缓冲区资源一样。 3.2 纹理坐标纹理映射还有一个重要要素就是每个顶点的实际坐标。 坐标决定了图像如何实际映射到几何体: 123456789101112131415161718192021222324252627282930313233343536struct Vertex &#123; glm::vec2 pos; glm::vec3 color; glm::vec2 texCoord; static VkVertexInputBindingDescription getBindingDescription() &#123; VkVertexInputBindingDescription bindingDescription = &#123;&#125;; bindingDescription.binding = 0; bindingDescription.stride = sizeof(Vertex); bindingDescription.inputRate = VK_VERTEX_INPUT_RATE_VERTEX; return bindingDescription; &#125; static std::array&lt;VkVertexInputAttributeDescription, 3&gt; getAttributeDescriptions() &#123; std::array&lt;VkVertexInputAttributeDescription, 3&gt; attributeDescriptions = &#123;&#125;; // position 顶点输入位置属性描述符 attributeDescriptions[0].binding = 0; attributeDescriptions[0].location = 0; attributeDescriptions[0].format = VK_FORMAT_R32G32_SFLOAT; attributeDescriptions[0].offset = offsetof(Vertex, pos); // color 顶点输入颜色属性描述符 attributeDescriptions[1].binding = 0; attributeDescriptions[1].location = 1; attributeDescriptions[1].format = VK_FORMAT_R32G32B32_SFLOAT; attributeDescriptions[1].offset = offsetof(Vertex, color); // coordinates 顶点输入坐标属性描述符 attributeDescriptions[2].binding = 0; attributeDescriptions[2].location = 2; attributeDescriptions[2].format = VK_FORMAT_R32G32_SFLOAT; attributeDescriptions[2].offset = offsetof(Vertex, texCoord); return attributeDescriptions; &#125;&#125;; 修改“顶点”结构，使其包含用于纹理坐标的vec2（texCoord）。 确保还添加了VkVertexInputAttributeDescription，以便我们可以将访问纹理坐标用作顶点着色器中的输入。 要将它们传递到片段着色器以便在正方形表面上进行插值，这是必要的。 123456const std::vector&lt;Vertex&gt; vertices = &#123; &#123;&#123;-0.5f, -0.5f&#125;, &#123;1.0f, 0.0f, 0.0f&#125;, &#123;1.0f, 0.0f&#125;&#125;, &#123;&#123;0.5f, -0.5f&#125;, &#123;0.0f, 1.0f, 0.0f&#125;, &#123;0.0f, 0.0f&#125;&#125;, &#123;&#123;0.5f, 0.5f&#125;, &#123;0.0f, 0.0f, 1.0f&#125;, &#123;0.0f, 1.0f&#125;&#125;, &#123;&#123;-0.5f, 0.5f&#125;, &#123;1.0f, 1.0f, 1.0f&#125;, &#123;1.0f, 1.0f&#125;&#125;&#125;; 先使用从左上角的0、0到右下角的1、1的坐标简单地用纹理填充正方形。 随意尝试使用不同的坐标。 稍后我们看看低于0或高于1的坐标下的实际的寻址模式！ 3.3 着色器最后一步是修改着色器，以从纹理中采样颜色。 我们首先需要修改顶点着色器，以将纹理坐标传递到片段着色器： 123456789101112layout(location = 0) in vec2 inPosition;layout(location = 1) in vec3 inColor;layout(location = 2) in vec2 inTexCoord;layout(location = 0) out vec3 fragColor;layout(location = 1) out vec2 fragTexCoord;void main() &#123; gl_Position = ubo.proj * ubo.view * ubo.model * vec4(inPosition, 0.0, 1.0); fragColor = inColor; fragTexCoord = inTexCoord;&#125; 就像每个顶点的颜色一样，栅格化器会将fragTexCoord值平滑地插入到正方形区域中。 我们可以通过使片段着色器将纹理坐标输出为颜色来形象化： 1234567891011#version 450#extension GL_ARB_separate_shader_objects : enablelayout(location = 0) in vec3 fragColor;layout(location = 1) in vec2 fragTexCoord;layout(location = 0) out vec4 outColor;void main() &#123; outColor = vec4(fragTexCoord, 0.0, 1.0);&#125; 现在我们编译下着色器，然后运行下程序: 3.3.1 片段着色器中的图像采样器描述符组合的图像采样器描述符在GLSL中由采样器统一表示。 在片段着色器中添加对它的引用： 123456# 对于其他类型的图像，存在等效的sampler1D和sampler3D类型。 确保在此处使用正确的绑定。 layout(binding = 1) uniform sampler2D texSampler;void main() &#123; outColor = texture(texSampler, fragTexCoord);&#125; 编译一下shader然后运行程序: 哒哒，一个旋转的贴图出现了！","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(14)-VkImage图像的创建","slug":"Vulkan入门-14-VkImage图像的创建","date":"2022-02-26T19:35:18.000Z","updated":"2022-02-26T19:44:04.385Z","comments":true,"path":"2022/02/27/Vulkan入门-14-VkImage图像的创建/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-14-VkImage%E5%9B%BE%E5%83%8F%E7%9A%84%E5%88%9B%E5%BB%BA/","excerpt":"简述在之前我们使用顶点着色器以及描述符来实现绘制有颜色的几何体，还实现了旋转动画。接下来我们学习一下纹理贴图，这个将是我们实现加载绘制基本3D模型的基础。","text":"简述在之前我们使用顶点着色器以及描述符来实现绘制有颜色的几何体，还实现了旋转动画。接下来我们学习一下纹理贴图，这个将是我们实现加载绘制基本3D模型的基础。 添加纹理的基本步骤有: 创建由设备内存支持的图像对象 用图像文件中的像素填充创建的图像对象 创建图像采样器 添加一个组合的图像采样器描述符来从纹理中采样颜色 我们以前已经使用过图像对象，但是这些对象是由swap chain扩展自动创建的。这次需要手动创建，创建图像并填充数据类似于创建顶点缓冲区。我们将通过创建一个暂存资源和填充它与像素数据，然后我们复制这到我们将用于渲染的最终图像对象。 可以创建一个暂存图像，不过Vulkan允许将像素从VkBuffer复制到image中，而且这个API在某些硬件上实际上更快。我们将首先创建这个缓冲区并填充像素值，然后我们将创建一个图像复制像素到。创建image与创建缓冲区并没有太大的不同。它包括查询内存需求、分配设备内存并绑定它，就像我们之前看到的那样。 图像可以有不同的布局，影响像素在内存中的存储方式。例如，由于图形硬件的工作方式，简单地逐行存储像素可能不会带来最好的性能。当对图像执行任何操作时，确保它们具有在该操作中使用的最佳布局。比如指定渲染通道时其中一些布局有: VK_IMAGE_LAYOUT_PRESENT_SRC_KHR: 适合呈现（present） VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL:片段着色器中写入颜色的最佳附件 VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL: 作为传输操作的最佳源，如vkCmdCopyImageToBuffer VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL: 作为传输操作的最佳目的地，如vkCmdCopyBufferToImage VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL: 适合着色器采样 转换图像布局的最常见方法之一是管道屏障（pipeline barrier）。管道屏障主要用于同步对资源的访问，例如确保在读取图像之前将其写入。后面我们将了解如何将管道壁垒用于转换布局。 使用VK_SHARING_MODE_EXCLUSIVE时，可以另外使用屏障来转移队列系列的所有权。 一. 纹理贴图1.1 图像库有许多库可用于加载图像，您甚至可以编写自己的代码来加载BMP和PPM等简单格式。 这里我们将使用stb集合中的stb_image库。 这样做的好处是所有代码都在一个文件中，因此不需要任何棘手的构建配置。 下载stb_image.h并将其存储在方便的位置，例如保存GLFW和GLM的目录。 将位置添加到您的包含路径。 stb_image库地址: https://github.com/nothings/stb 下载后解压，放在指定目录，然后修改我们的Makefile文件： 1234VULKAN_SDK_PATH = /home/jh/Program/vulkan/1.2.170.0/x86_64STB_IMAGE_PATH = /home/jh/Program/stb-imageCFLAGS = -std=c++17 -I$(VULKAN_SDK_PATH)/include -I$(STB_IMAGE_PATH) 1.1 读取图片在shaders目录旁边创建一个新的目录textures来存储纹理图像： 首先添加头文件: 12#define STB_IMAGE_IMPLEMENTATION#include &lt;stb_image.h&gt; 默认情况下，头文件只定义函数的原型。一个代码文件需要包含STB_IMAGE_IMPLEMENTATION定义的头文件来包含函数体，否则会有链接错误。 12345678910111213141516171819void initVulkan() &#123; ... createCommandPool(); // 因为需要使用指令缓冲，所以在创建指令池之后调用 createTextureImage(); createVertexBuffer(); ...&#125;void createTextureImage() &#123; int texWidth, texHeight, texChannels; // 加载texture.jpg图像 stbi_uc* pixels = stbi_load(&quot;textures/texture.jpg&quot;, &amp;texWidth, &amp;texHeight, &amp;texChannels, STBI_rgb_alpha); // 每个像素4个字节 VkDeviceSize imageSize = texWidth * texHeight * 4; if (!pixels) &#123; throw std::runtime_error(&quot;failed to load texture image!&quot;); &#125;&#125; stbi_load函数将文件路径和要加载的通道数量作为参数。STBI_rgb_alpha值会强制为图像加载Alpha通道，即使它没有通道也是如此, 与其他纹理保持一致性。中间的三个参数是输出图像中通道的宽度、高度和实际数量。返回的指针是像素值数组中的第一个元素。在STBI_rgba_alpha中，像素逐行排列，每个像素4个字节，总共texWidth * texHeight * 4个值。 1.2 缓存读取的图片现在，我们将在主机可见内存中创建一个缓冲区，以便我们可以使用vkMapMemory并将像素复制到其中。 将此临时缓冲区的变量添加到createTextureImage函数： 12345678910111213141516171819202122232425void createTextureImage() &#123; int texWidth, texHeight, texChannels; // 加载texture.jpg图像 stbi_uc* pixels = stbi_load(&quot;textures/texture.jpg&quot;, &amp;texWidth, &amp;texHeight, &amp;texChannels, STBI_rgb_alpha); // 每个像素4个字节 VkDeviceSize imageSize = texWidth * texHeight * 4; if (!pixels) &#123; throw std::runtime_error(&quot;failed to load texture image!&quot;); &#125; VkBuffer stagingBuffer; VkDeviceMemory stagingBufferMemory; // 缓冲区应该在主机可见内存中，以便我们可以映射它，并且它应该可用作传输源，以便我们以后可以复制 createBuffer(imageSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, stagingBufferMemory); // 内存映射 void* data; vkMapMemory(device, stagingBufferMemory, 0, imageSize, 0, &amp;data); memcpy(data, pixels, static_cast&lt;size_t&gt;(imageSize)); vkUnmapMemory(device, stagingBufferMemory); // 最后释放原始像素数据 stbi_image_free(pixels);&#125; 1.3 纹理图像(Texture Image)尽管我们可以设置着色器来访问缓冲区中的像素值，但为此目的最好使用Vulkan中的图像对象-VkImage。 通过使用2D坐标，图像对象将使检索颜色更加容易和快捷。 图像对象中的像素称为纹理像素： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849VkImage textureImage;VkDeviceMemory textureImageMemory;void createTextureImage() &#123; ... VkImageCreateInfo imageInfo = &#123;&#125;; imageInfo.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO; imageInfo.imageType = VK_IMAGE_TYPE_2D; //二维图像 imageInfo.extent.width = static_cast&lt;uint32_t&gt;(texWidth); imageInfo.extent.height = static_cast&lt;uint32_t&gt;(texHeight); imageInfo.extent.depth = 1; // 图像的最小采样的细节级别 imageInfo.mipLevels = 1; // 图像中的层数 imageInfo.arrayLayers = 1; // 指定图像格式，对于像素像素，使用与缓冲区中像素相同的格式，否则复制操作将失败 imageInfo.format = VK_FORMAT_R8G8B8A8_UNORM; // 图像平铺模式,这里指定图像像素最佳内存拼接布局 // 与图像的布局不同，平铺模式不能在以后更改。如果希望能够直接访问图像内存中的texel，则必须使用VK_IMAGE_TILING_OPTIMAL imageInfo.tiling = VK_IMAGE_TILING_OPTIMAL; // 图像的initialLayout只有两个可能的值：VK_IMAGE_LAYOUT_UNDEFINED || VK_IMAGE_LAYOUT_PREINITIALIZED imageInfo.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED; imageInfo.usage = VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_SAMPLED_BIT; // 图像将仅由一个队列族使用, 因此独占模式 imageInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE; // 图像采样 imageInfo.samples = VK_SAMPLE_COUNT_1_BIT; imageInfo.flags = 0; // Optional // 创建图像 if (vkCreateImage(device, &amp;imageInfo, nullptr, &amp;textureImage) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create image!&quot;); &#125; // 同样的，需要给Image分配内存空间 VkMemoryRequirements memRequirements; vkGetImageMemoryRequirements(device, textureImage, &amp;memRequirements); VkMemoryAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO; allocInfo.allocationSize = memRequirements.size; allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT); if (vkAllocateMemory(device, &amp;allocInfo, nullptr, &amp;textureImageMemory) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate image memory!&quot;); &#125; // 绑定图像和内存 vkBindImageMemory(device, textureImage, textureImageMemory, 0);&#125; 对于initialLayout，很少有情况需要在第一次过渡期间保留纹理像素，但是如果想将图像与VK_IMAGE_TILING_LINEAR布局结合使用作为缓存图像。 在这种情况下，将纹理像素数据上传到其中，然后将图像转换为传输源而又不丢失数据。但是，我们首先将图像转换为传输目标，然后从缓冲区对象将纹理像素数据复制到该图像，因此使用VK_IMAGE_LAYOUT_UNDEFINED。 对于usage, 与缓冲区创建期间的含义相同。 该图像将用作缓冲区副本的目的地，因此应将其设置为传输目的地。 我们还希望能够从着色器访问图像来为网格着色，因此用法应包括VK_IMAGE_USAGE_SAMPLED_BIT。 采样标志与多重采样有关。 这仅与将用作附件的图像有关，这里使用一个样本。 对于与稀疏图像有关的图像，有一些可选的标志。 稀疏图像是其中实际上仅某些区域由内存支持的图像。 例如，如果将3D纹理用于体素地形，则可以使用它来避免分配内存来存储大量的“空”值，这里我们设置为0。 1.3.1 VkImageCreateInfo创建图像的一系列参数是在VkImageCreateInfo中指明的： 1234567891011121314151617typedef struct VkImageCreateInfo &#123; VkStructureType sType; const void* pNext; VkImageCreateFlags flags; VkImageType imageType; VkFormat format; VkExtent3D extent; uint32_t mipLevels; uint32_t arrayLayers; VkSampleCountFlagBits samples; VkImageTiling tiling; VkImageUsageFlags usage; VkSharingMode sharingMode; uint32_t queueFamilyIndexCount; const uint32_t* pQueueFamilyIndices; VkImageLayout initialLayout;&#125; VkImageCreateInfo; sType是此结构的类型,VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO pNext是NULL或指向扩展特定结构的指针 flag是VkImageCreateFlagBits的位掩码，用于描述图像的其他参数 imageType是VkImageType值，用于指定图像的基本尺寸。就图像类型而言，阵列纹理中的图层不算作尺寸 VK_IMAGE_TYPE_1D指定一维图像 VK_IMAGE_TYPE_2D指定二维图像 VK_IMAGE_TYPE_3D指定三维图像 format是一种VkFormat，它描述了将包含在图像中的texel块的格式和类型 extent是一个VkExtent3D，它描述基本级别的每个维度中的数据元素数量 mipLevels描述可用于图像的最小采样的细节级别的数量 arrayLayers是图像中的层数 samples是VkSampleCountFlagBits，用于指定每个纹理像素的样本数 tiling是一个VkImageTiling值，它指定内存中纹理元素块的平铺模式 VK_IMAGE_TILING_LINEAR: 以主要行顺序排列像素 VK_IMAGE_TILING_OPTIMAL: 指定最佳平铺（纹理像素以实现相关的安排进行布局，以实现更好的内存访问） VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT: 表示图片的拼贴是由Linux DRM格式修饰符定义的 usage是VkImageUsageFlagBits的位掩码，用于描述图像的预期用法 SharingMode是VkSharingMode值，用于指定多个队列系列将访问图像时的图像共享模式 queueFamilyIndexCount是pQueueFamilyIndi​​ces数组中的条目数 pQueueFamilyIndi​​ces是将访问此图像的队列系列的列表（如果sharedMode不是VK_SHARING_MODE_CONCURRENT，则将被忽略） initialLayout是一个VkImageLayout值，它指定图像的所有图像子资源的初始VkImageLayout。请参阅图像布局 VK_IMAGE_LAYOUT_UNDEFINED: GPU不可用，第一次转换将丢弃纹理像素 VK_IMAGE_LAYOUT_PREINITIALIZED:GPU无法使用，但第一个过渡将保留纹理像素 1.3.2 vkCreateImage图像表示多维（最多3个）数据数组，可用于各种目的（例如附件、纹理），通过描述符集将其绑定到图形或计算管道，或直接将其指定为特定命令的参数。 12345VkResult vkCreateImage( VkDevice device, const VkImageCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkImage* pImage); device是创建Image的逻辑设备 pCreateInfo是指向VkImageCreateInfo结构的指针，该结构包含用于创建图像的参数 pAllocator如“内存分配”一章中所述控制主机内存分配 pImage是指向VkImage句柄的指针，在该句柄中返回生成的图像对象 1.3.3 createImage现在我们重构下createTextureImage, 将创建VkImage的部分单独做个函数: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778void createImage(uint32_t width, uint32_t height, VkFormat format, VkImageTiling tiling, VkImageUsageFlags usage, VkMemoryPropertyFlags properties, VkImage&amp; image, VkDeviceMemory&amp; imageMemory) &#123; VkImageCreateInfo imageInfo = &#123;&#125;; imageInfo.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO; imageInfo.imageType = VK_IMAGE_TYPE_2D; //二维图像 imageInfo.extent.width = static_cast&lt;uint32_t&gt;(width); imageInfo.extent.height = static_cast&lt;uint32_t&gt;(height); imageInfo.extent.depth = 1; // 图像的最小采样的细节级别 imageInfo.mipLevels = 1; // 图像中的层数 imageInfo.arrayLayers = 1; imageInfo.format = format; // 图像平铺模式,这里指定图像像素最佳内存拼接布局 // 与图像的布局不同，平铺模式不能在以后更改。如果希望能够直接访问图像内存中的texel，则必须使用VK_IMAGE_TILING_OPTIMAL imageInfo.tiling = tiling; // 图像的initialLayout只有两个可能的值：VK_IMAGE_LAYOUT_UNDEFINED || VK_IMAGE_LAYOUT_PREINITIALIZED imageInfo.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED; imageInfo.usage = usage; // 图像将仅由一个队列族使用, 因此独占模式 imageInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE; // 图像采样 imageInfo.samples = VK_SAMPLE_COUNT_1_BIT; imageInfo.flags = 0; // Optional // 创建图像 if (vkCreateImage(device, &amp;imageInfo, nullptr, &amp;image) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create image!&quot;); &#125; // 同样的，需要给Image分配内存空间 VkMemoryRequirements memRequirements; vkGetImageMemoryRequirements(device, image, &amp;memRequirements); VkMemoryAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO; allocInfo.allocationSize = memRequirements.size; allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT); if (vkAllocateMemory(device, &amp;allocInfo, nullptr, &amp;imageMemory) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate image memory!&quot;); &#125; // 绑定图像和内存 vkBindImageMemory(device, image, imageMemory, 0);&#125;void createTextureImage() &#123; int texWidth, texHeight, texChannels; // 加载texture.jpg图像 stbi_uc* pixels = stbi_load(&quot;textures/texture.jpg&quot;, &amp;texWidth, &amp;texHeight, &amp;texChannels, STBI_rgb_alpha); // 每个像素4个字节 VkDeviceSize imageSize = texWidth * texHeight * 4; if (!pixels) &#123; throw std::runtime_error(&quot;failed to load texture image!&quot;); &#125; VkBuffer stagingBuffer; VkDeviceMemory stagingBufferMemory; // 缓冲区应该在主机可见内存中，以便我们可以映射它，并且它应该可用作传输源，以便我们以后可以复制 createBuffer(imageSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, stagingBufferMemory, VK_SHARING_MODE_EXCLUSIVE); // 内存映射 void* data; vkMapMemory(device, stagingBufferMemory, 0, imageSize, 0, &amp;data); memcpy(data, pixels, static_cast&lt;size_t&gt;(imageSize)); vkUnmapMemory(device, stagingBufferMemory); // 最后释放原始像素数据 stbi_image_free(pixels); createImage(texWidth, texHeight, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_TILING_OPTIMAL, VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_SAMPLED_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, textureImage, textureImageMemory);&#125; 1.4 布局转换我们需要再次记录和执行一个命令缓冲区以完成布局转换功能，所以最好是将执行指令缓冲区的部分逻辑抽离: 123456789101112131415161718192021222324252627282930VkCommandBuffer beginSingleTimeCommands() &#123; VkCommandBufferAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO; allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY; allocInfo.commandPool = commandPool; allocInfo.commandBufferCount = 1; VkCommandBuffer commandBuffer; vkAllocateCommandBuffers(device, &amp;allocInfo, &amp;commandBuffer); VkCommandBufferBeginInfo beginInfo = &#123;&#125;; beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO; beginInfo.flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT; vkBeginCommandBuffer(commandBuffer, &amp;beginInfo); return commandBuffer;&#125;void endSingleTimeCommands(VkCommandBuffer commandBuffer) &#123; vkEndCommandBuffer(commandBuffer); VkSubmitInfo submitInfo = &#123;&#125;; submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO; submitInfo.commandBufferCount = 1; submitInfo.pCommandBuffers = &amp;commandBuffer; vkQueueSubmit(graphicsQueue, 1, &amp;submitInfo, VK_NULL_HANDLE); vkQueueWaitIdle(graphicsQueue); vkFreeCommandBuffers(device, commandPool, 1, &amp;commandBuffer);&#125; 现在有了beginSingleTimeCommands和endSingleTimeCommands函数，可以对执行单条指令缓冲区的函数进行优化： 1234567891011121314void copyBuffer(VkBuffer srcBuffer, VkBuffer dstBuffer, VkDeviceSize size) &#123; VkCommandBuffer commandBuffer= beginSingleTimeCommands(); // 缓冲拷贝指令 VkBufferCopy copyRegion = &#123;&#125;; copyRegion.srcOffset = 0; // Optional copyRegion.dstOffset = 0; // Optional copyRegion.size = size; // std::cout&lt;&lt;&quot;copyBuffer vkCmdCopyBuffer&quot;&lt;&lt;std::endl; // 缓冲区的内容使用vkCmdCopyBuffer命令传输。 // 源和目标缓冲区以及要复制的区域数组作为参数。copyRegion由源缓冲区偏移量、目标缓冲区偏移量和大小组成 vkCmdCopyBuffer(commandBuffer, srcBuffer, dstBuffer, 1, &amp;copyRegion); endSingleTimeCommands(commandBuffer);&#125; 如果我们仍然使用缓冲区，那么我们现在可以编写一个函数来记录并执行vkCmdCopyBufferToImage，但是这个命令要求首先将Image置于正确的布局中。 创建一个新函数来处理布局转换： 123456789101112131415161718192021222324252627282930313233343536373839void transitionImageLayout(VkImage image, VkFormat format, VkImageLayout oldLayout, VkImageLayout newLayout) &#123; VkCommandBuffer commandBuffer = beginSingleTimeCommands(); // 使用图像内存屏障,用于同步资源访问 VkImageMemoryBarrier barrier = &#123;&#125;; barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER; // 指定布局转换。如果不关心图像的现有内容，可以将VK_IMAGE_LAYOUT_UNDEFINED用作oldLayout barrier.oldLayout = oldLayout; barrier.newLayout = newLayout; // 如果使用屏障来传递队列族的所有权，那么这两个字段应该是队列族的索引 // 如果不这样做，则必须将它们设置为VK_QUEUE_FAMILY_IGNORED barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED; barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED; // image和subresourceRange指定受影响的图像以及图像的特定部分 barrier.image = image; barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; // 我们的图像不是数组，也没有mipmapping级别，因此只指定了一个级别和层 barrier.subresourceRange.baseMipLevel = 0; barrier.subresourceRange.levelCount = 1; barrier.subresourceRange.baseArrayLayer = 0; barrier.subresourceRange.layerCount = 1; // 屏障主要用于同步目的，因此必须指定哪些涉及资源的操作类型必须在屏障之前发生，哪些涉及资源的操作必须在屏障上等待 barrier.srcAccessMask = 0; // TODO barrier.dstAccessMask = 0; // TODO // 在管道上执行barrier指令, 所有类型的管道屏障都使用相同的函数提交 vkCmdPipelineBarrier(commandBuffer, 0 /* TODO */, 0 /* TODO */, 0, 0, nullptr, 0, nullptr, 1, &amp;barrier ); endSingleTimeCommands(commandBuffer);&#125; 执行布局转换的最常见方法之一是使用图像内存屏障。像这样的管道屏障通常用于同步对资源的访问，例如确保在从缓冲区读取之前完成对缓冲区的写入，但是当使用VK_SHARING_MODE_EXCLUSIVE时，它也可以用于转换映像布局和传输队列族所有权。对于缓冲区，有一个等效的缓冲存储器屏障来实现这一点。 1.4.1 VkImageMemoryBarrier图像存储器屏障仅适用于涉及特定图像子资源范围的存储器访问。也就是说，从图像存储器屏障形成的存储器依赖被限定为通过指定的图像子资源范围进行访问。图像内存屏障还可用于定义指定图像子资源范围的图像布局转换或队列族所有权转移。 123456789101112typedef struct VkImageMemoryBarrier &#123; VkStructureType sType; const void* pNext; VkAccessFlags srcAccessMask; VkAccessFlags dstAccessMask; VkImageLayout oldLayout; VkImageLayout newLayout; uint32_t srcQueueFamilyIndex; uint32_t dstQueueFamilyIndex; VkImage image; VkImageSubresourceRange subresourceRange;&#125; VkImageMemoryBarrier; sType就是这种结构的类型, VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER pNext为NULL或指向特定于扩展的结构的指针 srccessmask是指定源访问掩码的VkAccessFlagBits的位掩码, 指定在哪个管道阶段发生操作，这些操作应该在屏障之前发生 dstAccessMask是指定目标访问掩码的VkAccessFlagBits位掩码, 指定操作将在其中等待屏障的管道阶段 oldLayout是图像布局转换中的旧布局 newLayout是图像布局转换中的新布局 srcQueueFamilyIndex是队列系列所有权转移的源队列系列 dstQueueFamilyIndex是队列系列所有权转移的目标队列系列 image是受此屏障影响的图像 subresourceRange描述图像中受此屏障影响的图像子资源范围 1.4.2 vkCmdPipelineBarriervkCmdPipelineBarrier是一个同步命令，它在提交到同一队列的命令之间或同一子类中的命令之间插入依赖关系。 1234567891011void vkCmdPipelineBarrier( VkCommandBuffer commandBuffer, VkPipelineStageFlags srcStageMask, VkPipelineStageFlags dstStageMask, VkDependencyFlags dependencyFlags, uint32_t memoryBarrierCount, const VkMemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const VkBufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const VkImageMemoryBarrier* pImageMemoryBarriers); commandBuffer是将命令记录到的命令缓冲区 srcStageMask是一个指定源级掩码的VkPipelineStageFlagBits的位掩码 dstStageMask是指定目标阶段掩码的VkPipelineStageFlagBits的位掩码 dependencyFlags是VkdePendencyFlags的位掩码，指定如何形成执行和内存依赖关系 memoryBarrierCount是pMemoryBarriers数组的长度 pMemoryBarriers是指向VKMemorySbarrier结构数组的指针 bufferMemoryBarrierCount是pBufferMemoryBarriers数组的长度 pBufferMemoryBarriers是指向VkBufferMemoryBarrier结构数组的指针 imageMemoryBarrierCount是pImageMemoryBarriers数组的长度 pImageMemoryBarriers是指向VkimAgemoryBarrier结构数组的指针 当vkCmdPipelineBarrier提交到队列时，它定义了在它之前提交的命令和在它之后提交的命令之间的内存依赖关系。 如果vkCmdPipelineBarrier是在渲染过程实例外部录制的，则第一个同步作用域将包括按提交顺序较早出现的所有命令。如果vkCmdPipelineBarrier记录在渲染过程实例中，则第一个同步作用域仅包括在同一子过程中以提交顺序较早出现的命令。在这两种情况下，第一个同步作用域仅限于由srcStageMask指定的源阶段掩码确定的管道阶段上的操作。 如果vkCmdPipelineBarrier是在渲染过程实例外部录制的，则第二个同步作用域将包括以后按提交顺序执行的所有命令。如果vkCmdPipelineBarrier记录在渲染过程实例中，则第二个同步作用域仅包括稍后在同一子过程中按提交顺序出现的命令。在任何一种情况下，第二同步作用域都限于由dstStageMask指定的目的级掩码确定的管道级上的操作。 第一个访问范围被限制为在由srcStageMask指定的源阶段掩码确定的管道阶段中进行访问。其中，第一访问作用域仅包括由pMemoryBarriers、pBufferMemoryBarriers和pImageMemoryBarriers数组的元素定义的第一访问作用域，每个元素定义一组内存屏障。如果未指定内存屏障，则第一个访问作用域不包括任何访问。 第二访问范围被限制为在由dstStageMask指定的目标阶段掩码确定的管道阶段中的访问。其中，第二访问作用域仅包括由pMemoryBarriers、pBufferMemoryBarriers和pImageMemoryBarriers数组的元素定义的第二访问作用域，它们各自定义了一组内存屏障。如果未指定内存屏障，则第二访问作用域不包括任何访问。 1.5 拷贝缓存数据至Image就像缓冲区复制一样，需要指定缓冲区的哪个部分将被复制到图像的哪个部分： 12345678910111213141516171819202122232425262728void copyBufferToImage(VkBuffer buffer, VkImage image, uint32_t width, uint32_t height) &#123; VkCommandBuffer commandBuffer = beginSingleTimeCommands(); // 使用VkBufferImageCopy指定缓冲区复制行为 VkBufferImageCopy region = &#123;&#125;; // 指定缓冲区中像素值开始的字节偏移量 region.bufferOffset = 0; // 指定像素在内存中的布局方式, 指定0表示像素紧密打包 region.bufferRowLength = 0; region.bufferImageHeight = 0; // 指示要将像素复制到图像的哪个部分 region.imageSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; region.imageSubresource.mipLevel = 0; region.imageSubresource.baseArrayLayer = 0; region.imageSubresource.layerCount = 1; region.imageOffset = &#123;0, 0, 0&#125;; region.imageExtent = &#123;width, height, 1&#125;; // 使用vkCmdCopyBufferToImage函数将缓冲区到图像的复制操作排队 // 第四个参数指示图像当前使用的布局 vkCmdCopyBufferToImage(commandBuffer, buffer, image, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &amp;region); endSingleTimeCommands(commandBuffer);&#125; 1.5.1 VkBufferImageCopy12345678typedef struct VkBufferImageCopy &#123; VkDeviceSize bufferOffset; uint32_t bufferRowLength; uint32_t bufferImageHeight; VkImageSubresourceLayers imageSubresource; VkOffset3D imageOffset; VkExtent3D imageExtent;&#125; VkBufferImageCopy; bufferOffset是从复制图像数据的缓冲区对象的起始处开始的以字节为单位的偏移量 bufferRowLength和bufferImageHeight以texel为单位指定缓冲存储器中较大的二维或三维图像的子区域，并控制寻址计算。如果这些值中的任何一个为零，则根据imageExtent，缓冲存储器的这一方面被认为是紧密压缩的 imageSubresource是一个VkImageSubresourceLayers，用于指定用于源或目标图像数据的图像的特定图像子资源 imageOffset选择源或目标图像数据子区域的初始x、y、z偏移（以texel为单位） imageExtent是要在宽度、高度和深度上复制的图像的大小（以texel为单位） 当复制到或从深度或模具方面时，缓冲区内存中的数据使用的布局是深度或模具数据的(大部分)紧密封装的表示形式。具体地说: 复制到或从任何深度&#x2F;模板格式的模板方面的数据都用每个texel的VK_FORMAT_S8_UINT值紧密打包 复制到或从VK_FORMAT_D16_UNORM或VK_FORMAT_D16_UNORM_S8_UINT格式的深度方面的数据使用每个texel的VK_FORMAT_D16_UNORM值紧密打包 复制到或从VK_FORMAT_D32_SFLOAT或VK_FORMAT_D32_SFLOAT_S8_UINT格式的深度方面的数据使用每个texel的一个VK_FORMAT_D32_SFLOAT值紧密打包 复制到或从VK_FORMAT_X8_D24_UNORM_PACK32或VK_FORMAT_D24_UNORM_S8_UINT格式的深度方面的数据被打包为每个texel一个32位单词，每个单词的lsb中有D24值，8个msb中有未定义的值 由于图像副本的深度或模板方面缓冲区在某些实现上可能需要格式转换，因此不支持图形的队列不支持格式转换。当复制到深度方面时，并且没有启用VK_EXT_depth_range_unrestricted扩展名，缓冲区内存中的数据必须在[0,1]范围内，否则结果值是未定义的。复制从imageSubresource的图像图层baseArrayLayer成员开始一层一层地进行。layerCount层从源图像或目标图像复制。 1.5.2 vkCmdCopyBufferToImage在缓冲区和图像之间复制数据, 从buffer对象复制数据到image对象, 调用vkCmdCopyBufferToImage: 1234567void vkCmdCopyBufferToImage( VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkBufferImageCopy* pRegions); commandBuffer是命令将被记录到的命令缓冲区 srcBuffer是源缓冲区 dstImage是目标图像 dstImageLayout是复制的目标图像子资源的布局 regionCount是要复制的区域数 pRegions是一个指向VkBufferImageCopy结构数组的指针，该结构数组指定要复制的区域 区域中的每个区域从源缓冲区的指定区域复制到目标图像的指定区域。 如果dstImage的格式是一个多平面的图像格式)，必须使用VkBufferImageCopy结构的pRegions成员单独指定作为拷贝目标的每个平面的区域。在本例中，imageSubresource的aspectMask必须为VK_IMAGE_ASPECT_PLANE_0_BIT、VK_IMAGE_ASPECT_PLANE_1_BIT或VK_IMAGE_ASPECT_PLANE_2_BIT。对于vkCmdCopyBufferToImage来说，多平面图像的每个平面都被视为具有由相应子资源的aspectMask标识的平面的多平面格式的兼容平面格式中列出的格式。这既适用于VkFormat，也适用于复制中使用的坐标，它对应于平面中的texel，而不是这些texel如何映射到整个图像中的坐标。 1.6 准备纹理图像回到createTextureImage函数。我们在那里做的最后一件事是创建纹理图像。下一步是将暂存缓冲区复制到纹理图像。这包括两个步骤: 转换纹理图像到VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL 执行缓冲区到图像复制操作 123456789101112131415// 该图像是使用VK_IMAGE_LAYOUT_UNDEFINED布局创建的，因此在转换textureImage时应将oldLayout指定为VK_IMAGE_LAYOUT_UNDEFINED// 在执行复制操作之前，不关心图像内容，所以可以这样做transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_LAYOUT_UNDEFINED, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL);// 拷贝stagingBuffer中缓存的图像数据至Image（GPU可见内存）copyBufferToImage(stagingBuffer, textureImage, static_cast&lt;uint32_t&gt;(texWidth), static_cast&lt;uint32_t&gt;(texHeight));// 为了能够从着色器中的纹理图像开始采样，我们需要最后一个过渡来准备着色器访问(用于同步对资源的访问)：transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL); 1.7 转换屏障的含义 VkAccessFlags现在在启用验证层的情况下运行应用程序，那么将看到transitionImageLayout中的访问掩码和管道阶段无效。 我们需要根据过渡中的布局来设置它们，拷贝前后的两种转换都需要设置： VK_IMAGE_LAYOUT_UNDEFINED-&gt;VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL: 不需要等待任何内容的传输写入 VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL-&gt; VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL: shader reads应该等待Transfer writes，特别是shader在片段着色器中读取，因为这就是我们要使用纹理的地方 12345678910111213141516171819202122232425262728293031VkPipelineStageFlags sourceStage;VkPipelineStageFlags destinationStage;if (oldLayout == VK_IMAGE_LAYOUT_UNDEFINED &amp;&amp; newLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL) &#123; barrier.srcAccessMask = 0; // Image或缓冲区在清除或复制操作中的写访问 barrier.dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT; // 指定队列最初接收到任何命令的管道阶段 sourceStage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT; // 指定所有复制命令和清除命令管道阶段 destinationStage = VK_PIPELINE_STAGE_TRANSFER_BIT;&#125; else if (oldLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL &amp;&amp; newLayout == VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL) &#123; // Image或缓冲区在清除或复制操作中的写访问 barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT; // 指定对存储缓冲区、物理存储缓冲区、统一texel缓冲区、存储texel缓冲区、采样图像或存储图像的读访问 barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT; // 指定所有复制命令和清除命令管道阶段 sourceStage = VK_PIPELINE_STAGE_TRANSFER_BIT; // 指定片段着色器阶段 destinationStage = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;&#125; else &#123; throw std::invalid_argument(&quot;unsupported layout transition!&quot;);&#125;vkCmdPipelineBarrier(commandBuffer, sourceStage, destinationStage, 0, 0, nullptr, 0, nullptr, 1, &amp;barrier); 传输写入必须在管道传输阶段进行。因为写操作不需要等待任何东西，所以您可以为预barrier操作指定一个空的访问掩码和尽可能早的管道阶段VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT。需要注意的是，VK_PIPELINE_STAGE_TRANSFER_BIT并不是图形和计算管道中的一个真正的阶段。它更多的是一个发生转移的伪阶段。 图像将在相同的管道阶段被写入，然后被片段着色器读取，这就是为什么我们在片段着色器管道阶段指定着色器读取访问。需要注意的一点是，命令缓冲区提交在开始时会导致隐式的VK_ACCESS_HOST_WRITE_BIT同步。由于transitionImageLayout函数只使用一个命令来执行一个命令缓冲区，所以如果在布局转换中需要VK_ACCESS_HOST_WRITE_BIT依赖项，您可以使用这个隐式同步并将srcAccessMask设置为0。 实际上，有一种特殊的图像布局类型可以支持所有操作–VK_IMAGE_LAYOUT_GENERAL。当然，它的问题在于，它不一定能为任何操作提供最佳性能。在某些特殊情况下，例如使用图像作为输入和输出，或者在离开预初始化的布局后读取图像。到目前为止，所有提交命令的帮助程序功能都已设置为通过等待队列变为空闲状态而同步执行。对于实际应用，建议将这些操作组合在单个命令缓冲区中，并异步执行它们以提高吞吐量，尤其是createTextureImage函数中的过渡和复制。通过创建一个helper函数将命令记录到其中的setupCommandBuffer并尝试添加一个flushSetupCommands来执行到目前为止已记录的命令，来尝试进行此操作。最好在纹理贴图工作后执行此操作，以检查纹理资源是否仍正确设置。 1.7.1 VkAccessFlagBitsVulkan中的内存可以通过shader调用和管道中的一些固定函数来访问。访问类型是所使用的描述符类型的函数，或者固定函数阶段如何访问内存。每个访问类型对应于VkAccessFlagBits中的一个位标志。 一些同步命令以访问类型集作为参数来定义内存依赖项的访问范围。如果同步命令包含源访问掩码，则其第一个访问作用域仅包括通过该掩码中指定的访问类型进行的访问。类似地，如果同步命令包含目标访问掩码，则其第二个访问作用域仅包括通过该掩码中指定的访问类型进行的访问。 12345678910111213141516171819202122232425262728293031typedef enum VkAccessFlagBits &#123; VK_ACCESS_INDIRECT_COMMAND_READ_BIT = 0x00000001, VK_ACCESS_INDEX_READ_BIT = 0x00000002, VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT = 0x00000004, VK_ACCESS_UNIFORM_READ_BIT = 0x00000008, VK_ACCESS_INPUT_ATTACHMENT_READ_BIT = 0x00000010, VK_ACCESS_SHADER_READ_BIT = 0x00000020, VK_ACCESS_SHADER_WRITE_BIT = 0x00000040, VK_ACCESS_COLOR_ATTACHMENT_READ_BIT = 0x00000080, VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT = 0x00000100, VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT = 0x00000200, VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT = 0x00000400, VK_ACCESS_TRANSFER_READ_BIT = 0x00000800, VK_ACCESS_TRANSFER_WRITE_BIT = 0x00001000, VK_ACCESS_HOST_READ_BIT = 0x00002000, VK_ACCESS_HOST_WRITE_BIT = 0x00004000, VK_ACCESS_MEMORY_READ_BIT = 0x00008000, VK_ACCESS_MEMORY_WRITE_BIT = 0x00010000, VK_ACCESS_TRANSFORM_FEEDBACK_WRITE_BIT_EXT = 0x02000000, VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_READ_BIT_EXT = 0x04000000, VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_WRITE_BIT_EXT = 0x08000000, VK_ACCESS_CONDITIONAL_RENDERING_READ_BIT_EXT = 0x00100000, VK_ACCESS_COMMAND_PROCESS_READ_BIT_NVX = 0x00020000, VK_ACCESS_COMMAND_PROCESS_WRITE_BIT_NVX = 0x00040000, VK_ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT = 0x00080000, VK_ACCESS_SHADING_RATE_IMAGE_READ_BIT_NV = 0x00800000, VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_NV = 0x00200000, VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_NV = 0x00400000, VK_ACCESS_FRAGMENT_DENSITY_MAP_READ_BIT_EXT = 0x01000000, VK_ACCESS_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkAccessFlagBits; VK_ACCESS_INDIRECT_COMMAND_READ_BIT指定对作为间接绘图或调度命令一部分的间接命令数据的读访问 VK_ACCESS_INDEX_READ_BIT指定对索引缓冲区的读访问，作为索引绘图命令的一部分，由vkCmdBindIndexBuffer绑定 VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT指定对顶点缓冲区的读访问，作为绘图命令的一部分，由vkCmdBindVertexBuffers绑定 VK_ACCESS_UNIFORM_READ_BIT统一缓冲区读访问权限 VK_ACCESS_INPUT_ATTACHMENT_READ_BIT指定在片段着色期间渲染通道内对输入附件的读访问 VK_ACCESS_SHADER_READ_BIT指定对存储缓冲区、物理存储缓冲区、统一texel缓冲区、存储texel缓冲区、采样图像或存储图像的读访问 VK_ACCESS_SHADER_WRITE_BIT存储缓冲区、物理存储缓冲区、存储texel缓冲区或存储映像的写访问 VK_ACCESS_COLOR_ATTACHMENT_READ_BIT指定对颜色附件的读访问，例如通过混合、逻辑操作或通过某些subpass加载操作。它不包括高级混合操作 VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT指定在渲染通道期间或通过某些子通道加载和存储操作对颜色、解析或深度&#x2F;模板解析附件的写访问 VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT指定对深度&#x2F;模板附件的读访问，通过深度或模板操作，或通过某些子传递加载操作 VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT指定对深度&#x2F;模板附件的写访问，通过深度或模板操作，或者通过某些子传递加载和存储操作 VK_ACCESS_TRANSFER_READ_BIT拷贝操作中对镜像或缓冲区的读访问 VK_ACCESS_TRANSFER_WRITE_BIT映像或缓冲区在清除或复制操作中的写访问 VK_ACCESS_HOST_READ_BIT主机操作读访问。这种类型的访问不是通过资源执行的，而是直接在内存上执行的 VK_ACCESS_HOST_WRITE_BIT主机操作写访问。这种类型的访问不是通过资源执行的，而是直接在内存上执行的 VK_ACCESS_MEMORY_READ_BIT所有读访问。它在任何访问掩码中都是有效的，并被视为等同于设置所有在使用它时有效的读访问标志 VK_ACCESS_MEMORY_WRITE_BIT所有写访问。它在任何访问掩码中都是有效的，并被视为等同于设置所有在使用它时有效的写访问标志 VK_ACCESS_CONDITIONAL_RENDERING_READ_BIT_EXT指定对谓词的读访问，作为条件呈现的一部分 VK_ACCESS_TRANSFORM_FEEDBACK_WRITE_BIT_EXT指定在转换反馈激活时对转换反馈缓冲区的写访问 VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_READ_BIT_EXT指定对转换反馈计数器缓冲区的读访问，当vkCmdBeginTransformFeedbackEXT执行时读取该缓冲区 VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_WRITE_BIT_EXT指定对转换反馈计数器缓冲区的写访问，该缓冲区在vkCmdEndTransformFeedbackEXT执行时写入 VK_ACCESS_COMMAND_PROCESS_READ_BIT_NVX指定从VkBuffer输入读取vkCmdProcessCommandsNVX VK_ACCESS_COMMAND_PROCESS_WRITE_BIT_NVX指定写到vkCmdProcessCommandsNVX的目标命令缓冲区 VK_ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT类似于VK_ACCESS_COLOR_ATTACHMENT_READ_BIT，但是也包括高级的混合操作 VK_ACCESS_SHADING_RATE_IMAGE_READ_BIT_NV指定对着色率图像的读取访问，作为绘图命令的一部分，由vkcmdbindshadingraemimagenv绑定 VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_NV指定对加速结构的读访问，作为跟踪或构建命令的一部分 VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_NV指定对加速结构的写访问，作为构建命令的一部分 VK_ACCESS_FRAGMENT_DENSITY_MAP_READ_BIT_EXT动态碎片密度图操作时对碎片密度图附件的读访问 1.7.2 VkPipelineStageFlags 管道阶段操作或同步命令执行的工作由多个操作组成，这些操作作为逻辑上独立的步骤序列执行，称为管道阶段。执行的确切管道阶段取决于所使用的特定命令，以及记录命令时的当前命令缓冲区状态。绘制命令、分派命令、复制命令、清除命令和同步命令都在管道阶段的不同集合中执行。同步命令不会在已定义的管道中执行，但会执行VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT和VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT。 注意同步命令执行的操作(例如可用性和可见性操作)不是由定义的管道阶段执行的。但是，其他命令仍然可以通过VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT和VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT管道阶段与它们同步。 跨管道阶段执行操作必须遵循隐式排序保证，特别是包括管道阶段顺序。否则，与其他阶段相比，跨管道阶段的执行可能会重叠或无序执行，除非执行依赖项强制执行。 一些同步命令包括管道阶段参数，将该命令的同步范围限制在这些阶段。这允许对精确的执行依赖关系和操作命令执行的访问进行细粒度的控制。实现应该使用这些管道阶段来避免不必要的停顿或缓存刷新。 可以设置指定管道阶段通过VkPipelineStageFlags: 1234567891011121314151617181920212223242526272829typedef enum VkPipelineStageFlagBits &#123; VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT = 0x00000001, VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT = 0x00000002, VK_PIPELINE_STAGE_VERTEX_INPUT_BIT = 0x00000004, VK_PIPELINE_STAGE_VERTEX_SHADER_BIT = 0x00000008, VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT = 0x00000010, VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT = 0x00000020, VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT = 0x00000040, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT = 0x00000080, VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT = 0x00000100, VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT = 0x00000200, VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT = 0x00000400, VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT = 0x00000800, VK_PIPELINE_STAGE_TRANSFER_BIT = 0x00001000, VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT = 0x00002000, VK_PIPELINE_STAGE_HOST_BIT = 0x00004000, VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT = 0x00008000, VK_PIPELINE_STAGE_ALL_COMMANDS_BIT = 0x00010000, VK_PIPELINE_STAGE_TRANSFORM_FEEDBACK_BIT_EXT = 0x01000000, VK_PIPELINE_STAGE_CONDITIONAL_RENDERING_BIT_EXT = 0x00040000, VK_PIPELINE_STAGE_COMMAND_PROCESS_BIT_NVX = 0x00020000, VK_PIPELINE_STAGE_SHADING_RATE_IMAGE_BIT_NV = 0x00400000, VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_NV = 0x00200000, VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_NV = 0x02000000, VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV = 0x00080000, VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV = 0x00100000, VK_PIPELINE_STAGE_FRAGMENT_DENSITY_PROCESS_BIT_EXT = 0x00800000, VK_PIPELINE_STAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkPipelineStageFlagBits; VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT指定队列最初接收到任何命令的管道阶段 VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT指定使用Draw&#x2F;DispatchIndirect数据结构的管道阶段。这个阶段还包括读取vkCmdProcessCommandsNVX写的命令 VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV指定任务着色器阶段 VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV指定网格着色器阶段 VK_PIPELINE_STAGE_VERTEX_INPUT_BIT指定消耗顶点和索引缓冲区的流水线阶段 VK_PIPELINE_STAGE_VERTEX_SHADER_BIT指定顶点着色器阶段 VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT指定镶嵌控制着色器阶段 VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT指定镶嵌评估着色器阶段 VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT指定几何着色器阶段 VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT指定片段着色器阶段 VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT指定执行早期片段测试（片段着色之前的深度和模板测试）的管道阶段。此阶段还包括针对具有深度&#x2F;模板格式的帧缓冲区附件的子传递加载操作 VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT指定执行后期片段测试（片段着色后的深度和模板测试）的管道阶段。此阶段还包括用于具有深度&#x2F;模板格式的帧缓冲区附件的子传递存储操作 VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT指定混合后管道的阶段，从管道输出最终颜色值。此阶段还包括子通道加载和存储操作以及具有颜色或深度&#x2F;模板格式的帧缓冲区附件的多样本解析操作 VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT指定执行计算着色器 VK_PIPELINE_STAGE_TRANSFER_BIT指定以下命令： 所有复制命令，包括vkCmdCopyQueryPoolResults，vkCmdBlitImage，vkCmdResolveImage 所有清除命令，但vkCmdClearAttachments除外 VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT指定管道中由所有命令生成的操作完成执行的最后阶段 VK_PIPELINE_STAGE_HOST_BIT指定一个伪阶段，指示在主机上执行设备存储器的读&#x2F;写操作。记录在命令缓冲区中的任何命令都不会调用此阶段 VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_NV指定光线跟踪着色器阶段的执行 VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_NV指定vkCmdBuildAccelerationStructureNV，vkCmdCopyAccelerationStructureNV和vkCmdWriteAccelerationStructuresPropertiesNV的执行 VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT指定所有图形管线阶段的执行，并且等效于： VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV VK_PIPELINE_STAGE_VERTEX_INPUT_BIT VK_PIPELINE_STAGE_VERTEX_SHADER_BIT VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT VK_PIPELINE_STAGE_CONDITIONAL_RENDERING_BIT_EXT VK_PIPELINE_STAGE_TRANSFORM_FEEDBACK_BIT_EXT VK_PIPELINE_STAGE_SHADING_RATE_IMAGE_BIT_NV VK_PIPELINE_STAGE_FRAGMENT_DENSITY_PROCESS_BIT_EXT VK_PIPELINE_STAGE_ALL_COMMANDS_BIT等效于与其一起使用的队列上支持的所有其他管道阶段标志的逻辑或 VK_PIPELINE_STAGE_CONDITIONAL_RENDERING_BIT_EXT指定使用条件渲染谓词的管道阶段 VK_PIPELINE_STAGE_TRANSFORM_FEEDBACK_BIT_EXT指定将顶点属性输出值写入转换反馈缓冲区的管线阶段 VK_PIPELINE_STAGE_COMMAND_PROCESS_BIT_NVX指定了处理通过vkCmdProcessCommandsNVX在设备端生成命令的管道阶段 VK_PIPELINE_STAGE_SHADING_RATE_IMAGE_BIT_NV指定管道的阶段，在该阶段中读取阴影率图像，以确定栅格化图元各部分的阴影率 VK_PIPELINE_STAGE_FRAGMENT_DENSITY_PROCESS_BIT_EXT指定读取片段密度图以生成片段区域的管线阶段 1.8 清理创建纹理贴图后，不能忘记在必要的时候将内存释放出来： 123456789101112131415161718void createTextureImage() &#123; ... // 通过清除过渡缓冲区及其末尾的内存来完成createTextureImage函数： transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_UNORM, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL); vkDestroyBuffer(device, stagingBuffer, nullptr); vkFreeMemory(device, stagingBufferMemory, nullptr);&#125;void cleanup() &#123; cleanupSwapChain(); vkDestroyImage(device, textureImage, nullptr); vkFreeMemory(device, textureImageMemory, nullptr); ...&#125; 1.9 总结到目前为止，我们从设备物理存储上读取了图片内容，将其转成临时缓存后又将其存储在对应GPU可见的内存中以及生成对应VkImage纹理贴图对象，接下来需要将其显示在屏幕上还需要把这个对象放入图形管道中。 在回顾下本章中的读取图像的步骤: 首先利用stb-image库读取图片，将其内容存储在临时缓存区VkBuffer中，注意需要开辟GPU可见内存 通过VkImageCreateInfo结构指明图像格式并通过vkCreateImage创建VkImage对象 用VkBuffer图像文件中的像素填充创建的VkImage图像对象 填充图像对象需要使用VkImageMemoryBarrier 使用vkCmdPipelineBarrier使得图像填充Barrier生效 通过vkCmdCopyBufferToImage完成图像像素从VkBuffer到VkImage的拷贝(填充) 再通过VkImageMemoryBarrier指定图像是能够从着色器中的纹理图像开始采样 创建图像视图和图像采样器(后续下一章开始处理) 添加一个组合的图像采样器描述符来从纹理中采样颜色 上面步骤中，4和5是下一章的内容。 1.10 Windows上的CMakefileLists.txt写法windows平台上编译当前项目，可以使用cmake, CMakefileLists.txt文件如下(注意先安装Vulkan sdk)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556cmake_minimum_required (VERSION 3.7) #最低要求的CMake版本project(MyVulkan) # 项目名称set(VERSION 0.0.1)set(CMAKE_BUILD_TYPE &quot;Debug&quot;)set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++17 -g -Wall -Wno-unused-variable -pthread&quot;)message(STATUS &quot;This is &quot; $&#123;PROJECT_NAME&#125; &quot; version &quot; $&#123;VERSION&#125;)message(STATUS &quot;This is for windows platform&quot;)message(&quot;Build Type:&quot; $&#123;CMAKE_BUILD_TYPE&#125; $&#123;CMAKE_CXX_FLAGS&#125;)# Use FindVulkan module added with CMAKE 3.7if (NOT CMAKE_VERSION VERSION_LESS 3.7.0) message(STATUS &quot;Using module to find Vulkan&quot;) find_package(Vulkan)endif()find_library(Vulkan_LIBRARY NAMES vulkan-1 vulkan PATHS $&#123;CMAKE_SOURCE_DIR&#125;/libs/vulkan)IF (Vulkan_LIBRARY) set(Vulkan_FOUND ON) MESSAGE(&quot;Using bundled Vulkan library version&quot;)ENDIF()message(STATUS &quot;Using Vulkan lib: &quot; $&#123;Vulkan_LIBRARY&#125;)# CMAKE_SOURCE_DIR 代表工程根目录CMakeLists.txt文件所在目录set(ROOT_DIR $&#123;CMAKE_SOURCE_DIR&#125;)### GLFW3set(GLFW_LIB_DIR $&#123;ROOT_DIR&#125;/lib/glfw3)set(GLFW_LIBS $&#123;GLFW_LIB_DIR&#125;/glfw3dll.lib)### GLMset(GLM_INCLUDE_DIRS $&#123;ROOT_DIR&#125;/include/glm)### stb-imageset(STB_IMAGE_DIRS $&#123;ROOT_DIR&#125;/include/stb-image)message(STATUS &quot;Lib path: &quot;)message(STATUS &quot; GLFW3: &quot; $&#123;GLFW_LIBS&#125;)message(STATUS &quot; GLM : &quot; $&#123;GLM_INCLUDE_DIRS&#125;)message(STATUS &quot; STB_IMAGE: &quot; $&#123;STB_IMAGE_DIRS&#125;)# 定义头文件搜索路径include_directories($&#123;ROOT_DIR&#125;/inlcude $&#123;GLM_INCLUDE_DIRS&#125;)#aux_source_directory(./ SOURCE_DIR)aux_source_directory($&#123;ROOT_DIR&#125;/inlcude SOURCE_DIR)aux_source_directory($&#123;ROOT_DIR&#125;/src SOURCE_DIR)# Targetadd_executable(MyVulkan $&#123;SOURCE_DIR&#125;)####Vulkanfind_package(Vulkan REQUIRED)# GLFW3 is dynamic linktarget_link_libraries($&#123;PROJECT_NAME&#125; Vulkan::Vulkan $&#123;GLFW_LIBS&#125;) 项目文件目录:","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(13)-描述符布局及缓存","slug":"Vulkan入门-13-描述符布局及缓存","date":"2022-02-26T19:34:54.000Z","updated":"2022-02-26T19:43:22.440Z","comments":true,"path":"2022/02/27/Vulkan入门-13-描述符布局及缓存/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-13-%E6%8F%8F%E8%BF%B0%E7%AC%A6%E5%B8%83%E5%B1%80%E5%8F%8A%E7%BC%93%E5%AD%98/","excerpt":"简述我们现在可以为每个顶点传递任意属性到顶点着色器，但是全局变量呢？我们将从本章开始讨论三维图形，这需要一个模型视图投影矩阵。我们可以将其作为顶点数据包含，但这是对内存的浪费，而且每当变换发生变化时，都需要我们更新顶点缓冲区。然而这种转换可能在每一帧都有。","text":"简述我们现在可以为每个顶点传递任意属性到顶点着色器，但是全局变量呢？我们将从本章开始讨论三维图形，这需要一个模型视图投影矩阵。我们可以将其作为顶点数据包含，但这是对内存的浪费，而且每当变换发生变化时，都需要我们更新顶点缓冲区。然而这种转换可能在每一帧都有。 在Vulkan中解决这个问题的正确方法是使用资源描述符（resource descriptor）。描述符是着色器自由访问缓冲区和图像等资源的一种方式。我们将设置一个包含变换矩阵的缓冲区，并让顶点着色器通过描述符访问它们。描述符的使用包括三个部分： 在管道创建期间指定描述符布局 从描述符池分配描述符集 渲染期间绑定描述符集 描述符是表示着色器资源的不透明数据结构，比如缓冲区、缓冲区视图、图像视图、采样器或组合图像采样器。描述符被组织成描述符集，这些描述符集在命令记录期间被绑定，以便在后续的绘制命令中使用。每个描述符集中内容的安排由描述符集布局决定，该布局决定了可以在其中存储哪些描述符。管道可使用的描述符集布局序列在管道布局中指定。每个管道对象最多可以使用maxBoundDescriptorSets(参见限制)描述符集。 描述符布局指定管道要访问的资源类型，就像渲染过程指定要访问的附件类型一样。描述符集指定将绑定到描述符的实际缓冲区或图像资源，就像帧缓冲区指定要绑定到渲染过程附件的实际图像视图一样。然后为绘图命令绑定描述符集，就像顶点缓冲区和帧缓冲区一样。 着色器通过装饰有描述符集和绑定数的变量访问资源，这些变量将它们连接到描述符集中的描述符。着色器接口到绑定描述符集的映射在着色器资源接口部分描述。着色器也可以通过64位地址使用物理存储缓冲区访问，而不需要通过描述符来访问缓冲区。 描述符有很多种类型，这里使用统一缓冲区对象(UBO)。如下所示: 12345struct UniformBufferObject &#123; glm::mat4 model; glm::mat4 view; glm::mat4 proj;&#125;; 我们可以使用GLM中的数据类型精确匹配着色器中的定义。矩阵中的数据与着色器期望的方式是二进制兼容的，因此我们可以稍后将UniformBufferObject的memcpy转换为VkBuffer。 需要更改顶点着色器: 123456789101112131415161718#version 450#extension GL_ARB_separate_shader_objects : enablelayout(binding = 0) uniform UniformBufferObject &#123; mat4 model; mat4 view; mat4 proj;&#125; ubo;layout(location = 0) in vec2 inPosition;layout(location = 1) in vec3 inColor;layout(location = 0) out vec3 fragColor;void main() &#123; gl_Position = ubo.proj * ubo.view * ubo.model * vec4(inPosition, 0.0, 1.0); fragColor = inColor;&#125; 绑定指令类似于属性的位置指令。 我们将在描述符布局中引用此绑定。 更改了带有gl_Position的行，以使用转换来计算剪辑坐标中的最终位置。 与2D三角形不同，剪辑坐标的最后一个分量可能不是1，这在转换为屏幕上的最终归一化设备坐标时将导致除法。 这在透视投影中用作透视划分，对于使较近的对象看起来比较远的对象看起来更大，这是必不可少的。 一. 描述符集布局我们需要提供着色器中用于管道创建的每个描述符绑定的详细信息，就像我们必须为每个顶点属性及其位置索引所做的那样。我们将设置一个新函数来定义所有这些信息，称为createDescriptorSetLayout。在创建管道之前应该调用: 12345678910111213141516171819void initVulkan() &#123; ... createDescriptorSetLayout(); createGraphicsPipeline(); ...&#125;void createDescriptorSetLayout() &#123; VkDescriptorSetLayoutBinding uboLayoutBinding = &#123;&#125;; // 指定在着色器中使用的绑定 uboLayoutBinding.binding = 0; // 描述符的类型 uboLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; uboLayoutBinding.descriptorCount = 1; // 指定描述符将在顶点着色器阶段被引用 uboLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT; // pImmutableSamplers仅与图像采样描述符有关 uboLayoutBinding.pImmutableSamplers = nullptr;&#125; 每个绑定都需要通过VkDescriptorSetLayoutBinding结构来描述。前两个字段指定在着色器中使用的绑定和描述符的类型，该描述符是一个统一的缓冲区对象。着色器变量可能表示一个统一缓冲区对象的数组，而描述符计数指定该数组中值的数量。 例如，这可用于为骨骼动画指定骨骼中每个骨骼的变换。 我们的MVP转换位于单个统一缓冲区对象中，因此我们使用的描述符数为1。 1.1 VkDescriptorSetLayoutBinding1234567typedef struct VkDescriptorSetLayoutBinding &#123; uint32_t binding; VkDescriptorType descriptorType; uint32_t descriptorCount; VkShaderStageFlags stageFlags; const VkSampler* pImmutableSamplers;&#125; VkDescriptorSetLayoutBinding; binding是此条目的绑定号，并且与着色器阶段中具有相同绑定号的资源相对应。 descriptorType是VkDescriptorType，它指定用于此绑定的资源描述符的类型。 descriptorCount是绑定中包含的描述符数量，在着色器中以数组形式访问，除非描述符类型为VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT，在这种情况下，描述符计数是嵌入式统一块的字节大小。如果描述符计数为零，则此绑定条目被保留，并且不得使用设置的布局在任何管道内通过任何绑定从任何阶段访问资源。 stageFlags成员是VkShaderStageFlagBits的位掩码，用于指定哪些管道着色器阶段可以访问此绑定的资源。 VK_SHADER_STAGE_ALL是一种简写形式，用于指定所有定义的着色器阶段，包括扩展定义的任何其他阶段，都可以访问该资源。如果stageFlags中未包含着色器阶段，则不得使用设置的布局在任何管道中通过此绑定从该阶段访问资源。除了限于片段着色器的输入附件之外，对于阶段的哪些组合可以使用描述符绑定没有任何限制，特别是图形阶段和计算阶段都可以使用绑定。 pImmutableSamplers影响采样器的初始化。如果描述符类型指定VK_DESCRIPTOR_TYPE_SAMPLER或VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER类型描述符，则可以使用pImmutableSamplers初始化一组不可变的采样器。不可变的采样器永久绑定到设置的布局中，不得更改。不允许使用不可变采样器更新VK_DESCRIPTOR_TYPE_SAMPLER描述符，并且使用不可变采样器更新VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER描述符不会修改采样器（将更新图像视图，但会忽略采样器更新）。如果pImmutableSamplers不为NULL，则它指向一个采样器句柄数组，该数组将被复制到set布局中并用于相应的绑定。仅采样器句柄被复制；在最终使用集合布局以及使用它创建的任何描述符池和集合之前，不得破坏采样器对象。如果pImmutableSamplers为NULL，则采样器插槽是动态的，必须使用此布局将采样器句柄绑定到描述符集中。如果描述符类型不是这些描述符类型之一，则将忽略pImmutableSamplers。 1.1.1 VkDescriptorType其中描述符的类型VkDescriptorType有如下取值: 12345678910111213141516typedef enum VkDescriptorType &#123; VK_DESCRIPTOR_TYPE_SAMPLER = 0, VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER = 1, VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE = 2, VK_DESCRIPTOR_TYPE_STORAGE_IMAGE = 3, VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER = 4, VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER = 5, VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER = 6, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER = 7, VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC = 8, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC = 9, VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT = 10, VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT = 1000138000, VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_NV = 1000165000, VK_DESCRIPTOR_TYPE_MAX_ENUM = 0x7FFFFFFF&#125; VkDescriptorType; VK_DESCRIPTOR_TYPE_SAMPLER: 指定采样器描述符 VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER: 指定组合图像采样器描述符 VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE: 指定采样图像描述符 VK_DESCRIPTOR_TYPE_STORAGE_IMAGE: 指定存储映像描述符 VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER: 指定统一纹理像素缓冲区描述符 VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER: 指定存储纹理元素缓冲区描述符 VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER: 统一缓冲区描述符 VK_DESCRIPTOR_TYPE_STORAGE_BUFFER: 指定存储缓冲区描述符 VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC: 指定动态统一缓冲区描述符 VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC: 指定动态存储缓冲区描述符 VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT: 指定输入附件描述符 VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT: 指定内联统一块 1.1.2 VkShaderStageFlags需要指定一个或多个着色器阶段的命令和结构使用位对应于阶段的位掩码来指定。可以设置为指定着色器阶段的位有： 12345678910111213141516171819typedef enum VkShaderStageFlagBits &#123; VK_SHADER_STAGE_VERTEX_BIT = 0x00000001, VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT = 0x00000002, VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT = 0x00000004, VK_SHADER_STAGE_GEOMETRY_BIT = 0x00000008, VK_SHADER_STAGE_FRAGMENT_BIT = 0x00000010, VK_SHADER_STAGE_COMPUTE_BIT = 0x00000020, VK_SHADER_STAGE_ALL_GRAPHICS = 0x0000001F, VK_SHADER_STAGE_ALL = 0x7FFFFFFF, VK_SHADER_STAGE_RAYGEN_BIT_NV = 0x00000100, VK_SHADER_STAGE_ANY_HIT_BIT_NV = 0x00000200, VK_SHADER_STAGE_CLOSEST_HIT_BIT_NV = 0x00000400, VK_SHADER_STAGE_MISS_BIT_NV = 0x00000800, VK_SHADER_STAGE_INTERSECTION_BIT_NV = 0x00001000, VK_SHADER_STAGE_CALLABLE_BIT_NV = 0x00002000, VK_SHADER_STAGE_TASK_BIT_NV = 0x00000040, VK_SHADER_STAGE_MESH_BIT_NV = 0x00000080, VK_SHADER_STAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkShaderStageFlagBits; VK_SHADER_STAGE_VERTEX_BIT: 顶点阶段 VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT: 细分控制阶段 VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT: 细分评估阶段 VK_SHADER_STAGE_GEOMETRY_BIT: 几何图形阶段 VK_SHADER_STAGE_FRAGMENT_BIT: 片段阶段 VK_SHADER_STAGE_COMPUTE_BIT: 计算阶段 VK_SHADER_STAGE_ALL_GRAPHICS: 用作速记的位的组合，用于指定上面定义的所有图形阶段（计算阶段除外） VK_SHADER_STAGE_ALL: 用作简写的位的组合，用于指定设备支持的所有着色器阶段，包括扩展引入的所有其他阶段 VK_SHADER_STAGE_TASK_BIT_NV: 任务阶段 VK_SHADER_STAGE_MESH_BIT_NV: 网格阶段 VK_SHADER_STAGE_RAYGEN_BIT_NV: 射线生成阶段 VK_SHADER_STAGE_ANY_HIT_BIT_NV: 任何命中阶段 VK_SHADER_STAGE_CLOSEST_HIT_BIT_NV: 最接近的命中阶段 VK_SHADER_STAGE_MISS_BIT_NV: 未命中阶段 VK_SHADER_STAGE_INTERSECTION_BIT_NV: 相交阶段 VK_SHADER_STAGE_CALLABLE_BIT_NV: 可调用阶段 1.2 创建VkDescriptorSetLayout所有描述符绑定都合并到一个vkDescriptorSetLayout对象中： 123456789101112131415161718192021222324VkDescriptorSetLayout descriptorSetLayout;void createDescriptorSetLayout() &#123; VkDescriptorSetLayoutBinding uboLayoutBinding = &#123;&#125;; // 指定在着色器中使用的绑定 uboLayoutBinding.binding = 0; // 描述符的类型 uboLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; uboLayoutBinding.descriptorCount = 1; // 指定描述符将在顶点着色器阶段被引用 uboLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT; // pImmutableSamplers仅与图像采样描述符有关 uboLayoutBinding.pImmutableSamplers = nullptr; VkDescriptorSetLayoutCreateInfo layoutInfo = &#123;&#125;; layoutInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO; layoutInfo.bindingCount = 1; layoutInfo.pBindings = &amp;uboLayoutBinding; // 创建描述符集布局 if (vkCreateDescriptorSetLayout(device, &amp;layoutInfo, nullptr, &amp;descriptorSetLayout) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create descriptor set layout!&quot;); &#125;&#125; 1.2.1 VkDescriptorSetLayoutCreateInfo1234567typedef struct VkDescriptorSetLayoutCreateInfo &#123; VkStructureType sType; const void* pNext; VkDescriptorSetLayoutCreateFlags flags; uint32_t bindingCount; const VkDescriptorSetLayoutBinding* pBindings;&#125; VkDescriptorSetLayoutCreateInfo; sType就是这种结构的类型, VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO pNext为NULL或指向特定于扩展的结构的指针 flags是VkDescriptorSetLayoutCreateFlagBits的位掩码，用于指定描述符集布局创建的选项 bindingCount是pBindings中的元素数 pBindings是指向VkDescriptorSetLayoutBinding结构数组的指针 123456typedef enum VkDescriptorSetLayoutCreateFlagBits &#123; VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT = 0x00000002, VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT_KHR = 0x00000001, VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT_EXT = VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT, VK_DESCRIPTOR_SET_LAYOUT_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkDescriptorSetLayoutCreateFlagBits; VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT: 指定不得使用此布局分配描述符集，而是由vkCmdPushDescriptorSetKHR推送描述符 VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT_KHR: 指定描述符集使用此布局必须从创建一个描述符池分配VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT位集。描述符集布局创建这部分设置有备用限制描述符的最大数量每级和per-pipeline布局。non-UpdateAfterBind限制仅计数在没有此标志的情况下创建的集合中的描述符。UpdateAfterBind限制计算所有描述符，但是限制可能高于非UpdateAfterBind限制。 1.2.2 vkCreateDescriptorSetLayout描述符集布局对象由零个或多个描述符绑定的数组定义。每个单独的描述符绑定由描述符类型、绑定中描述符数量的计数（数组大小）、可以访问绑定的一组着色器阶段以及（如果使用不可变采样器）采样器描述符数组指定。 创建描述符集布局可以使用函数: vkCreateDescriptorSetLayout 12345VkResult vkCreateDescriptorSetLayout( VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorSetLayout* pSetLayout); device: 创建描述符集布局的逻辑设备 pCreateInfo: 指向VkDescriptorSetLayoutCreateInfo结构的指针，它指定了描述符集布局对象的状态 pAllocator: 控制主机内存分配 pSetLayout: 指向VkDescriptorSetLayout句柄的指针，在这个句柄中返回结果描述符集布局对象 当然通过vkCreate*创建的对象或资源，一般需要显示销毁: 12345void cleanup() &#123; cleanupSwapChain(); vkDestroyDescriptorSetLayout(device, descriptorSetLayout, nullptr); ...&#125; 1.3 管道指定描述符集布局我们需要在管道创建期间指定描述符集布局，以告诉Vulkan着色器将使用哪些描述符。描述符集布局在管道布局对象中指定。修改VkPipelineLayoutCreateInfo以引用布局对象： 1234VkPipelineLayoutCreateInfo pipelineLayoutInfo = &#123;&#125;;pipelineLayoutInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO;pipelineLayoutInfo.setLayoutCount = 1;pipelineLayoutInfo.pSetLayouts = &amp;descriptorSetLayout; 这里留个悬念，为什么可以指定多个描述符集布局。 1.4 统一缓存我们将指定包含着色器的UBO数据的缓冲区，但是我们需要首先创建这个缓冲区。我们将在每一帧将新数据复制到统一缓冲区，因此使用暂存缓冲区实际上没有任何意义。在这种情况下，它只会增加额外的开销，而且可能会降低性能。 我们应该有多个缓冲区，因为多个帧可能在同一时间绘制，我们不想更新缓冲区，准备下一帧，而前一帧仍在读取它！我们可以为每个帧或每个交换链图像提供统一的缓冲区。然而，由于我们需要从每个交换链映像所拥有的命令缓冲区引用统一缓冲区，因此最好也为每个交换链映像创建一个统一缓冲区。 123456789101112131415161718192021222324252627VkBuffer indexBuffer;VkDeviceMemory indexBufferMemory;std::vector&lt;VkBuffer&gt; uniformBuffers;std::vector&lt;VkDeviceMemory&gt; uniformBuffersMemory;void initVulkan() &#123; ... createVertexBuffer(); createIndexBuffer(); createUniformBuffers(); ...&#125;void createUniformBuffers() &#123; VkDeviceSize bufferSize = sizeof(UniformBufferObject); uniformBuffers.resize(swapChainImages.size()); uniformBuffersMemory.resize(swapChainImages.size()); for (size_t i = 0; i &lt; swapChainImages.size(); i++) &#123; createBuffer(bufferSize, VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, uniformBuffers[i], uniformBuffersMemory[i], VK_SHARING_MODE_EXCLUSIVE); &#125;&#125; 我们将编写一个单独的函数，在每一帧用一个新的转换来更新统一缓冲区，所以这里没有vkMapMemory。 统一数据将被用于所有的draw调用，所以包含它的缓冲区只有在我们停止渲染时才会被销毁。因为它也取决于交换链图像的数量，这可能会在重新创建后改变，所以在cleanupSwapChain中清理它: 1234567891011121314void cleanupSwapChain() &#123; ... for (size_t i = 0; i &lt; uniformBuffers.size(); i++) &#123; vkDestroyBuffer(device, uniformBuffers[i], nullptr); vkFreeMemory(device, uniformBuffersMemory[i], nullptr); &#125;&#125;void recreateSwapChain() &#123; ... createFramebuffers(); createUniformBuffers(); createCommandBuffers();&#125; 1.5 更新统一缓存数据在绘制更新交换链帧的时候更新统一缓存数据： 123456789101112void drawFrame() &#123; ... updateUniformBuffer(imageIndex); VkSubmitInfo submitInfo = &#123;&#125;; submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO; ...&#125;void updateUniformBuffer(uint32_t currentImage) &#123;&#125; updateUniformBuffer函数将在每帧生成一个新的变换，以使几何体旋转。 1234567891011121314151617181920212223242526272829303132333435// 确保glm::rotate之类的函数使用弧度作为参数是必要的，以避免任何可能的混淆#define GLM_FORCE_RADIANS#include &lt;glm/glm.hpp&gt;#include &lt;glm/gtc/matrix_transform.hpp&gt;// chrono标准库标头公开了执行精确计时的功能#include &lt;chrono&gt;void updateUniformBuffer(uint32_t currentImage) &#123; static auto startTime = std::chrono::high_resolution_clock::now(); auto currentTime = std::chrono::high_resolution_clock::now(); // 计算时长 float time = std::chrono::duration&lt;float, std::chrono::seconds::period&gt;(currentTime - startTime).count(); UniformBufferObject ubo = &#123;&#125;; // 在统一缓冲区对象中定义模型，视图和投影转换。 使用时间变量，模型旋转将是围绕Z轴的简单旋转 // 意思是每秒旋转90度 ubo.model = glm::rotate(glm::mat4(1.0f), time * glm::radians(90.0f), glm::vec3(0.0f, 0.0f, 1.0f)); // 设置视图角度，从上方以45度角查看几何图形。 glm :: lookAt函数将眼睛位置，中心位置和上轴作为参数。 ubo.view = glm::lookAt(glm::vec3(2.0f, 2.0f, 2.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 0.0f, 1.0f)); // 使用具有45度垂直视场的透视投影。 // 其他参数是长宽比，近视平面和远视平面。 重要的是使用当前交换链范围来计算纵横比，以考虑调整大小后窗口的新宽度和高度。 ubo.proj = glm::perspective(glm::radians(45.0f), swapChainExtent.width / (float) swapChainExtent.height, 0.1f, 10.0f); // GLM最初是为OpenGL(左手坐标系)设计的，将其中坐标的Y坐标反转。 最简单的补偿方法是在投影矩阵中翻转Y轴缩放比例上的符号。 // 如果不这样做，那么图像将被倒置呈现。 ubo.proj[1][1] *= -1; // 将统一缓冲区对象中的数据复制到当前的统一缓冲区中。 与使用顶点缓冲区的方式完全相同，只是不需要暂存缓冲区（因为每帧都要更新）： void* data; vkMapMemory(device, uniformBuffersMemory[currentImage], 0, sizeof(ubo), 0, &amp;data); memcpy(data, &amp;ubo, sizeof(ubo)); vkUnmapMemory(device, uniformBuffersMemory[currentImage]);&#125; 当然此时编译运行程序是不成功的，因为我们仅仅是更新数据，但是没有将描述符集绑定到图形管道中。 二. 描述符前面我们创建了描述符集布局，描述了可以绑定的描述符的类型，现在我们给统一缓冲区的每个缓冲创建一个描述符集，然后将其绑定到统一缓冲区描述符中。 2.1 描述符池描述符集无法直接创建，它们必须从命令缓冲区之类的池中分配。描述符集又称为描述符池。 我们将编写一个新函数createDescriptorPool进行设置 12345678910111213141516171819202122232425void initVulkan() &#123; ... createUniformBuffers(); createDescriptorPool(); ...&#125;void createDescriptorPool() &#123; VkDescriptorPoolSize poolSize = &#123;&#125;; // 我们创建的是统一缓冲的描述符 poolSize.type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; poolSize.descriptorCount = static_cast&lt;uint32_t&gt;(swapChainImages.size()); VkDescriptorPoolCreateInfo poolInfo = &#123;&#125;; poolInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO; poolInfo.poolSizeCount = 1; poolInfo.pPoolSizes = &amp;poolSize; // 除了可用的单个描述符的最大数量外，还需要指定可以分配的最大描述符集数量：与交换链图像数量一致 poolInfo.maxSets = static_cast&lt;uint32_t&gt;(swapChainImages.size()); // 创建描述符池 if (vkCreateDescriptorPool(device, &amp;poolInfo, nullptr, &amp;descriptorPool) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create descriptor pool!&quot;); &#125;&#125; 首先需要使用VkDescriptorPoolSize结构来描述我们的描述符集将包含哪些描述符类型以及其中有多少个描述符类型。 2.1.1 VkDescriptorPoolSize1234typedef struct VkDescriptorPoolSize &#123; VkDescriptorType type; uint32_t descriptorCount;&#125; VkDescriptorPoolSize; type是描述符的类型 descriptorCount是要分配的该类型的描述符数。如果类型是VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT，则descriptorCount是要为此类型的描述符分配的字节数 2.1.2 VkDescriptorPoolCreateInfo12345678typedef struct VkDescriptorPoolCreateInfo &#123; VkStructureType sType; const void* pNext; VkDescriptorPoolCreateFlags flags; uint32_t maxSets; uint32_t poolSizeCount; const VkDescriptorPoolSize* pPoolSizes;&#125; VkDescriptorPoolCreateInfo; sType是此结构的类型, VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO pNext是NULL或指向扩展特定结构的指针 flags是VkDescriptorPoolCreateFlagBits的位掩码，用于指定池中某些受支持的操作 maxSets是可以从池中分配的描述符集的最大数量 poolSizeCount是pPoolSizes中的元素数 pPoolSizes是一个指向VkDescriptorPoolSize结构数组的指针，每个结构都包含一个描述符类型和要在池中分配的该类型的描述符数量 2.1.3 vkCreateDescriptorPool描述符池维护着一个描述符池，从中分配描述符集。 描述符池是外部同步的，这意味着应用程序不得同时从多个线程中的同一池中分配和&#x2F;或释放描述符集。 12345VkResult vkCreateDescriptorPool( VkDevice device, const VkDescriptorPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorPool* pDescriptorPool); device: 创建描述符池的逻辑设备 pCreateInfo: 指向VkDescriptorPoolCreateInfo结构的指针，该结构指定描述符池对象的状态 pAllocator: 内存分配 pDescriptorPool: 指向VkDescriptorPool句柄的指针，在该句柄中返回生成的描述符池对象 别忘了手动清理描述符池： 1234567891011void cleanupSwapChain() &#123; ... vkDestroyDescriptorPool(device, descriptorPool, nullptr);&#125;void recreateSwapChain() &#123; ... createUniformBuffers(); createDescriptorPool(); createCommandBuffers();&#125; 2.2 描述符集有了描述符池就可以分配描述符集了。为此添加createDescriptorSets函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859VkDescriptorPool descriptorPool;std::vector&lt;VkDescriptorSet&gt; descriptorSets;void initVulkan() &#123; ... createDescriptorPool(); createDescriptorSets(); ...&#125;void recreateSwapChain() &#123; ... createDescriptorPool(); createDescriptorSets(); ...&#125;void createDescriptorSets() &#123; std::vector&lt;VkDescriptorSetLayout&gt; layouts(swapChainImages.size(), descriptorSetLayout); VkDescriptorSetAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO; allocInfo.descriptorPool = descriptorPool; allocInfo.descriptorSetCount = static_cast&lt;uint32_t&gt;(swapChainImages.size()); allocInfo.pSetLayouts = layouts.data(); // 重置大小 descriptorSets.resize(swapChainImages.size()); // 内存分配描述符集 if (vkAllocateDescriptorSets(device, &amp;allocInfo, descriptorSets.data()) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate descriptor sets!&quot;); &#125; // 配置描述符 for (size_t i = 0; i &lt; descriptorSets.size(); i++) &#123; // 引用缓冲区的描述符（例如我们的统一缓冲区描述符）使用VkDescriptorBufferInfo结构进行配置 // 指定缓冲区以及其中包含描述符数据的区域。 VkDescriptorBufferInfo bufferInfo = &#123;&#125;; // 绑定缓冲区 bufferInfo.buffer = uniformBuffers[i]; bufferInfo.offset = 0; bufferInfo.range = sizeof(UniformBufferObject); VkWriteDescriptorSet descriptorWrite = &#123;&#125;; descriptorWrite.sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET; descriptorWrite.dstSet = descriptorSets[i]; descriptorWrite.dstBinding = 0; descriptorWrite.dstArrayElement = 0; descriptorWrite.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER; descriptorWrite.descriptorCount = 1; descriptorWrite.pBufferInfo = &amp;bufferInfo; descriptorWrite.pImageInfo = nullptr; // Optional descriptorWrite.pTexelBufferView = nullptr; // Optional // 应用描述符集更新 vkUpdateDescriptorSets(device, 1, &amp;descriptorWrite, 0, nullptr); &#125;&#125; 描述符集分配用VkDescriptorSetAllocateInfo结构描述。需要指定要从中分配的描述符池、要分配的描述符集的数量以及基于它们的描述符布局。 2.2.1 VkDescriptorSetAllocateInfo1234567typedef struct VkDescriptorSetAllocateInfo &#123; VkStructureType sType; const void* pNext; VkDescriptorPool descriptorPool; uint32_t descriptorSetCount; const VkDescriptorSetLayout* pSetLayouts;&#125; VkDescriptorSetAllocateInfo; sType是此结构的类型 pNext是NULL或指向扩展特定结构的指针 descriptorPool是从中分配集合的池 descriptorSetCount确定要从池中分配的描述符集的数量 pSetLayouts是一个指向描述符集布局数组的指针，每个成员指定如何分配相应的描述符集 2.2.2 vkAllocateDescriptorSets1234VkResult vkAllocateDescriptorSets( VkDevice device, const VkDescriptorSetAllocateInfo* pAllocateInfo, VkDescriptorSet* pDescriptorSets); device: 拥有描述符池的逻辑设备 pAllocateInfo: 指向VkDescriptorSetAllocateInfo结构的指针，该结构描述分配参数 pDescriptorSets: 指向VkDescriptorSet句柄数组的指针，在该数组中返回生成的描述符集对象 无需手动清理描述符集，因为在销毁描述符池时，会自动释放描述符集。 对vkAllocateDescriptorSets的调用将分配描述符集，每个描述符集具有一个统一的缓冲区描述符。 2.2.3 VkDescriptorBufferInfo12345typedef struct VkDescriptorBufferInfo &#123; VkBuffer buffer; VkDeviceSize offset; VkDeviceSize range;&#125; VkDescriptorBufferInfo; buffer是缓冲区资源 offset是从缓冲区开始的偏移量（以字节为单位）。 通过此描述符访问缓冲存储器将使用相对于此起始偏移量的寻址 range是用于此描述符更新的大小（以字节为单位），或者是VK_WHOLE_SIZE以使用从偏移量到缓冲区末尾的范围 2.2.4 VkWriteDescriptorSet123456789101112typedef struct VkWriteDescriptorSet &#123; VkStructureType sType; const void* pNext; VkDescriptorSet dstSet; uint32_t dstBinding; uint32_t dstArrayElement; uint32_t descriptorCount; VkDescriptorType descriptorType; const VkDescriptorImageInfo* pImageInfo; const VkDescriptorBufferInfo* pBufferInfo; const VkBufferView* pTexelBufferView;&#125; VkWriteDescriptorSet; sType是此结构的类型, VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET pNext是NULL或指向扩展特定结构的指针 dstSet是要更新的目标描述符集 dstBinding是该集合内的描述符绑定 dstArrayElement是该数组中的起始元素。如果由dstSet和dstBinding标识的描述符绑定的描述符类型为VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT，则dstArrayElement指定绑定内的起始字节偏移量 descriptorCount是要更新的描述符的数量（pImageInfo，pBufferInfo或pTexelBufferView中的元素数量，或者与pNext链中的VkWriteDescriptorSetInlineUniformBlockEXT结构的dataSize成员匹配的值，或者与pNext中的VkWriteDescriptorSetAccelerationStructureNV结构的AccelerationStructureCount匹配的值。链 ）。如果由dstSet和dstBinding标识的描述符绑定的描述符类型为VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT，则描述符计数指定要更新的字节数 descriptorType是VkDescriptorType，用于指定pImageInfo，pBufferInfo或pTexelBufferView中每个描述符的类型，如下所述。它必须与在dstBinding中为dstSet的VkDescriptorSetLayoutBinding中指定的类型相同。描述符的类型还控制描述符从哪个数组获取 pImageInfo是指向VkDescriptorImageInfo结构数组的指针 pBufferInfo是指向VkDescriptorBufferInfo结构数组的指针 pTexelBufferView是指向VkBufferView句柄数组的指针 2.2.5 vkUpdateDescriptorSets内存分配后，描述符集可以使用写和复制操作的组合进行更新。 要更新描述符集，调用：vkUpdateDescriptorSets 123456void vkUpdateDescriptorSets( VkDevice device, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites, uint32_t descriptorCopyCount, const VkCopyDescriptorSet* pDescriptorCopies); device是更新描述符集的逻辑设备 descriptorWriteCount是pDescriptorWrites数组中元素的数量 pDescriptorWrites是指向VkWriteDescriptorSet结构数组的指针，该结构描述了要写入的描述符集 descriptorCopyCount是pDescriptorCopies数组中元素的数量 pDescriptorCopies是指向VkCopyDescriptorSet结构数组的指针，该结构描述了要在其间复制的描述符集 2.3 使用描述符集现在，我们需要更新createCommandBuffers函数，以将每个交换链图像的正确描述符集实际绑定到具有cmdBindDescriptorSets的着色器中的描述符。 需要在vkCmdDrawIndexed调用之前完成： 12vkCmdBindDescriptorSets(commandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, pipelineLayout, 0, 1, &amp;descriptorSets[i], 0, nullptr);vkCmdDrawIndexed(commandBuffers[i], static_cast&lt;uint32_t&gt;(indices.size()), 1, 0, 0, 0); 与顶点和索引缓冲区不同，描述符集不是图形管线所独有的。因此，我们需要指定是否要将描述符集绑定到图形或计算管道–vkCmdBindDescriptorSets。 现在运行程序，是看不到任何内容的。问题在于，由于我们在投影矩阵中进行了Y翻转，因此现在以顺时针顺序而不是逆时针顺序绘制了顶点。这将导致背面剔除，并阻止绘制任何几何图形。 在createGraphicsPipeline函数中VkPipelineRasterizationStateCreateInfo中修改frontFace来更正此问题： 12rasterizer.cullMode = VK_CULL_MODE_BACK_BIT;rasterizer.frontFace = VK_FRONT_FACE_COUNTER_CLOCKWISE; frontFace是VkFrontFace结构体内的类型: 12345typedef enum VkFrontFace &#123; VK_FRONT_FACE_COUNTER_CLOCKWISE = 0, VK_FRONT_FACE_CLOCKWISE = 1, VK_FRONT_FACE_MAX_ENUM = 0x7FFFFFFF&#125; VkFrontFace; VK_FRONT_FACE_COUNTER_CLOCKWISE 指定具有正面积的三角形被认为是朝前的 VK_FRONT_FACE_CLOCKWISE 指定具有负面积的三角形被认为是朝前的 如何计算面积的正负，后续研究。现在运行程序可以看到我们的图像在沿着逆时针旋转~ 2.3.1 vkCmdBindDescriptorSets绑定描述符集调用 vkCmdBindDescriptorSets:一个参数是描述符所基于的布局。接下来的三个参数指定第一个描述符集的索引，要绑定的集的数量以及要绑定的集的数组。我们待会儿再讲这个。最后两个参数指定用于动态描述符的偏移量数组。 123456789void vkCmdBindDescriptorSets( VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t firstSet, uint32_t descriptorSetCount, const VkDescriptorSet* pDescriptorSets, uint32_t dynamicOffsetCount, const uint32_t* pDynamicOffsets); commandBuffer是描述符集将绑定到的命令缓冲区 pipelineBindPoint是一个VkPipelineBindPoint，它指示描述符是由图形管线还是由计算管线使用。 每个图形和计算都有一组单独的绑定点，因此绑定一个不会干扰另一个 layout是一个VkPipelineLayout对象，用于对绑定进行编程 firstSet是要绑定的第一个描述符集的集号 descriptorSetCount是pDescriptorSets数组中元素的数量 pDescriptorSets是指向VkDescriptorSet对象的句柄数组的指针，该对象描述了要写入的描述符集 dynamicOffsetCount是pDynamicOffsets数组中的动态偏移量 pDynamicOffsets是指向指定动态偏移量的uint32_t值数组的指针 vkCmdBindDescriptorSets导致编号为[firstSet..firstSet + descriptorSetCount-1]的集合使用存储在pDescriptorSets [0..descriptorSetCount-1]中的绑定用于后续渲染命令（根据pipelineBindPoint计算或图形）。以前通过这些集合应用的任何绑定都不再有效。 绑定后，描述符集会影响命令缓冲区中后续图形或计算命令的渲染，直到将不同的集绑定到相同的集编号，或者直到该集受到干扰（如管线布局兼容性中所述）为止。 在记录绘制或分派命令以使用该管道执行时，必须为管道中任何着色器访问的所有设定编号绑定一个兼容的描述符集。但是，如果管道中的所有着色器都不静态使用具有特定集合号的任何绑定，则即使该管道编号包括该集合号的非平凡描述符集合布局，也不需要为该集合号绑定任何描述符集。 如果要绑定的任何集合包括动态统一缓冲区或存储缓冲区，则pDynamicOffsets会为每个集合中每个动态描述符类型绑定中的每个数组元素包含一个元素。从pDynamicOffsets中获取值的顺序是：集合N的所有条目都在集合N + 1之前；在一个集合中，条目按描述符集合布局中的绑定号排序；在绑定数组中，元素是有序的。 dynamicOffsetCount必须等于要绑定的集合中动态描述符的总数。 用于动态统一和存储缓冲区绑定的有效偏移量是从pDynamicOffsets获取的相对偏移量与缓冲区的基地址加描述符集中的基本偏移量之和。动态统一和存储缓冲区绑定的范围是描述符集中指定的缓冲区范围。 每个pDescriptorSet都必须与layout指定的管道布局兼容。用于编程绑定的布局还必须与后续图形或计算命令中使用的管线兼容，如“管线布局兼容性”部分中所定义。 调用vkCmdBindDescriptorSets绑定的描述符集内容可能在以下时间使用： 对于使用VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT位置1创建的描述符绑定，在将命令缓冲区提交到队列时，在着色器执行结果绘制和调度时或在两者之间的任何时间，内容都可能被消耗。 在命令的主机执行期间，或在着色器执行结果绘制和派发期间，或之间的任何时间。 因此，在描述符集合绑定的内容可能被消耗的第一个时间点和该命令在队列上完成执行之间，不得更改（由更新命令覆盖或释放）描述符集绑定的内容。 在执行vkCmdBindDescriptorSets时，pDynamicOffsets的内容将立即消耗。一旦所有待定用途都已完成，就可以更新和重用描述符集。 三. 总结描述符的使用包括三个部分： 在管道创建期间指定描述符布局 从描述符池分配描述符集 渲染期间绑定描述符集 所谓描述符，就是用来描述着色器资源的不透明数据结构，比如缓冲区、缓冲区视图、图像视图、采样器或组合图像采样器。 接下来，我们尝试一些更让人激动的东西–贴图。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(12)-暂存缓冲和索引缓冲","slug":"Vulkan入门-12-暂存缓冲和索引缓冲","date":"2022-02-26T19:34:41.000Z","updated":"2022-02-26T19:42:33.608Z","comments":true,"path":"2022/02/27/Vulkan入门-12-暂存缓冲和索引缓冲/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-12-%E6%9A%82%E5%AD%98%E7%BC%93%E5%86%B2%E5%92%8C%E7%B4%A2%E5%BC%95%E7%BC%93%E5%86%B2/","excerpt":"简述虽然现在我们创建的顶点缓冲区工作正常，但是从CPU访问它的内存类型可能不是图形显卡本身读取的最佳内存类型，最理想的内存具有VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT位标志，并且通常不可由专用图形显卡上的CPU访问。而且我们上一篇最后实现的随鼠标移动的功能也没有考虑同步，简单一点，考虑读写分离。 现在创建两个顶点缓冲区：CPU可访问内存中的一个暂存缓冲区用于从顶点数组上传数据，最终顶点缓冲区位于设备本地内存中。然后我们将使用一个缓冲区复制命令将数据从暂存缓冲区移动到实际的顶点缓冲区。简单来说就是暂存缓冲区用于cpu写入，顶点缓冲区用于GPU读取数据。","text":"简述虽然现在我们创建的顶点缓冲区工作正常，但是从CPU访问它的内存类型可能不是图形显卡本身读取的最佳内存类型，最理想的内存具有VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT位标志，并且通常不可由专用图形显卡上的CPU访问。而且我们上一篇最后实现的随鼠标移动的功能也没有考虑同步，简单一点，考虑读写分离。 现在创建两个顶点缓冲区：CPU可访问内存中的一个暂存缓冲区用于从顶点数组上传数据，最终顶点缓冲区位于设备本地内存中。然后我们将使用一个缓冲区复制命令将数据从暂存缓冲区移动到实际的顶点缓冲区。简单来说就是暂存缓冲区用于cpu写入，顶点缓冲区用于GPU读取数据。 参考资料 Vulkan coordinate system http://vulkano.rs/guide/vertex-input 一. 传输队列buffer copy命令需要支持传输操作的队列族，使用VK_QUEUE_TRANSFER_BIT表示。不过任何具有VK_QUEUE_GRAPHICS_BIT或VK_QUEUE_COMPUTE_BIT功能的队列家族都已经隐式支持VK_QUEUE_TRANSFER_BIT操作。在这些情况下，不需要实现在queueFlags中显式地列出它。 但可以尝试使用专门用于传输操作的不同队列族， 可以如下操作: 修改QueueFamilyIndices和findQueueFamilies来显式地查找具有VK_QUEUE_TRANSFER位的队列族，而不是VK_QUEUE_GRAPHICS_BIT位 修改createLogicalDevice以请求传输队列的句柄 为传输队列系列上提交的命令缓冲区创建第二个命令池 修改资源的共享模式为VK_SHARING_MODE_CONCURRENT，并指定图形和传输队列族 提交传输命令，如vkCmdCopyBuffer到传输队列，而不是图形队列 二. 暂存缓冲区因为我们要创建多个VkBuffer，所以最好把共有的部分抽出，以避免代码累赘: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 传入必要参数void createBuffer(VkDeviceSize size, VkBufferUsageFlags usage, VkMemoryPropertyFlags properties, VkBuffer&amp; buffer, VkDeviceMemory&amp; bufferMemory, VkSharingMode mode) &#123; VkBufferCreateInfo bufferInfo = &#123;&#125;; bufferInfo.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO; bufferInfo.size = size; bufferInfo.usage = usage; bufferInfo.sharingMode = mode; if (vkCreateBuffer(device, &amp;bufferInfo, nullptr, &amp;buffer) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create vertex buffer!&quot;); &#125; VkMemoryRequirements memRequirements; vkGetBufferMemoryRequirements(device, buffer, &amp;memRequirements); VkMemoryAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO; allocInfo.allocationSize = memRequirements.size; allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, properties); if (vkAllocateMemory(device, &amp;allocInfo, nullptr, &amp;bufferMemory) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate vertex buffer memory!&quot;); &#125; vkBindBufferMemory(device, buffer, bufferMemory, 0);&#125;void createVertexBuffer() &#123; VkDeviceSize bufferSize = sizeof(vertices[0]) * vertices.size(); VkBuffer stagingBuffer; VkDeviceMemory stagingBufferMemory; createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, // 资源只能由单个队列族独占 stagingBufferMemory, VK_SHARING_MODE_EXCLUSIVE); void* data; vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &amp;data); memcpy(data, vertices.data(), (size_t) bufferSize); vkUnmapMemory(device, stagingBufferMemory); // 注意这里的MEMORY_PROPERTY是VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT！ createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, vertexBuffer, // 资源只能由单个队列族独占 vertexBufferMemory, VK_SHARING_MODE_EXCLUSIVE);&#125; 因为我们需要使用传输队列，所以注意stagingBuffer的usage是用的VK_BUFFER_USAGE_TRANSFER_SRC_BIT，而vertexBuffer现在用的是VK_BUFFER_USAGE_TRANSFER_DST_BIT！ vertexBuffer现在从设备本地的内存类型分配，这意味着我们不能使用vkMapMemory。但是，我们可以将数据从stagingBuffer复制到vertexBuffer。我们必须通过指定stagingBuffer的传输源标志和vertexBuffer的传输目标标志以及顶点缓冲区使用标志来表明我们打算这样做。 2.1 VkBufferUsageFlagBits12345678910111213141516171819typedef enum VkBufferUsageFlagBits &#123; VK_BUFFER_USAGE_TRANSFER_SRC_BIT = 0x00000001, VK_BUFFER_USAGE_TRANSFER_DST_BIT = 0x00000002, VK_BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT = 0x00000004, VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT = 0x00000008, VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT = 0x00000010, VK_BUFFER_USAGE_STORAGE_BUFFER_BIT = 0x00000020, VK_BUFFER_USAGE_INDEX_BUFFER_BIT = 0x00000040, VK_BUFFER_USAGE_VERTEX_BUFFER_BIT = 0x00000080, VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT = 0x00000100, VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT = 0x00020000, VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_BUFFER_BIT_EXT = 0x00000800, VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_COUNTER_BUFFER_BIT_EXT = 0x00001000, VK_BUFFER_USAGE_CONDITIONAL_RENDERING_BIT_EXT = 0x00000200, VK_BUFFER_USAGE_RAY_TRACING_BIT_NV = 0x00000400, VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_EXT = VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT, VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_KHR = VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT, VK_BUFFER_USAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkBufferUsageFlagBits; VkBufferUsageFlagBits设置的位可以指定缓冲区的使用行为： VK_BUFFER_USAGE_TRANSFER_SRC_BIT指定缓冲区可以用作传输命令的源(请参阅VK_PIPELINE_STAGE_TRANSFER_BIT的定义)。 VK_BUFFER_USAGE_TRANSFER_DST_BIT指定缓冲区可以用作传输命令的目的地。 VK_BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT缓冲区可用于创建一个VkBufferView，该视图适合占用VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER类型的VkDescriptorSet槽位。 VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT指定该缓冲区可以用来创建一个VkBufferView，该视图适合于占用VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER类型的VkDescriptorSet槽位。 VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT缓冲区可以用于VkDescriptorBufferInfo中，该缓冲区适合于占用VkDescriptorSet类型的VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC槽位。 VK_BUFFER_USAGE_STORAGE_BUFFER_BIT指定该缓冲区可用于VkDescriptorBufferInfo中，该缓冲区适合于占用VkDescriptorSet类型的VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC槽位。 VK_BUFFER_USAGE_INDEX_BUFFER_BIT指定该缓冲区适合作为buffer参数传递给vkCmdBindIndexBuffer。 VK_BUFFER_USAGE_VERTEX_BUFFER_BIT指定缓冲区适合作为pBuffers数组的元素传递给vkCmdBindVertexBuffers。 VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT缓冲区适合作为buffer参数传递给vkCmdDrawIndirect、vkCmdDrawIndexedIndirect、vkCmdDrawMeshTasksIndirectNV、vkCmdDrawMeshTasksIndirectCountNV或vkCmdDispatchIndirect。它也适合作为VkIndirectCommandsTokenNVX的缓冲区成员，或VkCmdProcessCommandsInfoNVX的sequencesCountBuffer或sequencesIndexBuffer成员传递 VK_BUFFER_USAGE_CONDITIONAL_RENDERING_BIT_EXT指定缓冲区适合作为buffer参数传递给vkCmdBeginConditionalRenderingEXT。 VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_BUFFER_BIT_EXT指定该缓冲区适合使用for binding作为vkCmdBindTransformFeedbackBuffersEXT的转换反馈缓冲区。 VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_COUNTER_BUFFER_BIT_EXT指定该缓冲区适合与vkCmdBeginTransformFeedbackEXT和vkCmdEndTransformFeedbackEXT一起用作计数器缓冲区。 VK_BUFFER_USAGE_RAY_TRACING_BIT_NV指定缓冲区适用于vkCmdTraceRaysNV和vkCmdBuildAccelerationStructureNV。 VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT指定缓冲区可以通过vkGetBufferDeviceAddress来检索缓冲区设备地址，并使用该地址从着色器访问缓冲区的内存。 2.2 VkMemoryPropertyFlags1234567891011typedef enum VkMemoryPropertyFlagBits &#123; VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT = 0x00000001, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT = 0x00000002, VK_MEMORY_PROPERTY_HOST_COHERENT_BIT = 0x00000004, VK_MEMORY_PROPERTY_HOST_CACHED_BIT = 0x00000008, VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT = 0x00000010, VK_MEMORY_PROPERTY_PROTECTED_BIT = 0x00000020, VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD = 0x00000040, VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD = 0x00000080, VK_MEMORY_PROPERTY_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkMemoryPropertyFlagBits; VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT: 指定使用这种类型分配的内存对于设备访问是最有效的。当且仅当内存类型属于设置了VK_MEMORY_HEAP_DEVICE_LOCAL_BIT的堆时，才会设置此属性。 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT: 指定使用这种类型分配的内存可以通过vkMapMemory映射给主机访问。 VK_MEMORY_PROPERTY_HOST_COHERENT_BIT: 指定主机缓存管理命令vkFlushMappedMemoryRanges和vkInvalidateMappedMemoryRanges分别用于刷新主机对设备的写操作，或者使设备的写操作对主机可见。 VK_MEMORY_PROPERTY_HOST_CACHED_BIT: 指定用这种类型分配的内存缓存在主机上。主机内存对非缓存内存的访问比对缓存内存的访问慢，但是非缓存内存总是与主机一致的。 VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT: 指定内存类型仅允许设备访问内存。内存类型不能同时设置VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT和VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT。另外，对象的后备内存可以由在惰性分配内存中指定的lazy实现提供。 VK_MEMORY_PROPERTY_PROTECTED_BIT: 指定内存类型仅允许设备访问内存，并允许受保护的队列操作访问内存。内存类型不能设置VK_MEMORY_PROPERTY_PROTECTED_BIT和任何VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT、VK_MEMORY_PROPERTY_HOST_COHERENT_BIT或VK_MEMORY_PROPERTY_HOST_CACHED_BIT。 VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD: 指定对这种内存类型分配的设备访问将自动变为可用和可见的。 VK_MEMORY_PROPERTY_DEVICE_UNCACHHED_BIT_AMD: 指定用这种类型分配的内存不会缓存到设备上。非缓存设备内存总是设备一致的。 2.3 缓冲区拷贝函数内存传输操作使用命令缓冲区执行，就像绘制命令一样。因此，首先分配一个临时的命令缓冲区。您可能希望为这些短期缓冲区创建一个单独的命令池，因为实现可能能够应用内存分配优化。在这种情况下，您应该在生成命令池期间使用VK_COMMAND_POOL_CREATE_TRANSIENT_BIT标志。 123456789101112131415161718192021222324252627282930313233343536void copyBuffer(VkBuffer srcBuffer, VkBuffer dstBuffer, VkDeviceSize size) &#123; VkCommandBufferAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO; allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY; allocInfo.commandPool = commandPool; allocInfo.commandBufferCount = 1; VkCommandBuffer commandBuffer; vkAllocateCommandBuffers(device, &amp;allocInfo, &amp;commandBuffer); // 开始记录指令 VkCommandBufferBeginInfo beginInfo = &#123;&#125;; beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO; // 只使用一次命令缓冲区，并等待函数返回，直到复制操作完成执行 // 所以使用VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT标志 beginInfo.flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT; vkBeginCommandBuffer(commandBuffer, &amp;beginInfo); // 缓冲拷贝指令 VkBufferCopy copyRegion = &#123;&#125;; copyRegion.srcOffset = 0; // Optional copyRegion.dstOffset = 0; // Optional copyRegion.size = size; // 缓冲区的内容使用vkCmdCopyBuffer命令传输。 // 源和目标缓冲区以及要复制的区域数组作为参数。copyRegion由源缓冲区偏移量、目标缓冲区偏移量和大小组成 vkCmdCopyBuffer(commandBuffer, srcBuffer, dstBuffer, 1, &amp;copyRegion); vkEndCommandBuffer(commandBuffer); VkSubmitInfo submitInfo = &#123;&#125;; submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO; submitInfo.commandBufferCount = 1; submitInfo.pCommandBuffers = &amp;commandBuffer; vkQueueSubmit(graphicsQueue, 1, &amp;submitInfo, VK_NULL_HANDLE); vkQueueWaitIdle(graphicsQueue); vkFreeCommandBuffers(device, commandPool, 1, &amp;commandBuffer);&#125; 拷贝缓冲指令的一般流程是: vkAllocateCommandBuffers 创建指令缓冲，分配内存 vkBeginCommandBuffer 开始指令记录 vkCmdCopyBuffer 执行具体指令 vkEndCommandBuffer 结束指令记录 vkQueueSubmit 将指令提交到管道 vkQueueWaitIdle 等待管道执行指令,也可以通过fence机制 vkFreeCommandBuffers 释放指令缓冲区 2.2.1 vkCmdCopyBuffer 拷贝缓冲区在缓冲区对象之间复制数据，调用:vkCmdCopyBuffer 123456void vkCmdCopyBuffer( VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkBuffer dstBuffer, uint32_t regionCount, const VkBufferCopy* pRegions); commandBuffer是命令将被记录到的命令缓冲区。 srcBuffer是源缓冲区。 dstBuffer是目标缓冲区。 regionCount是要复制的区域数。 pRegions是一个指向VkBufferCopy结构体数组的指针，该数组指定了要复制的区域。 2.3 缓冲区拷贝12345678910111213141516171819202122232425262728void createVertexBuffer() &#123; VkDeviceSize bufferSize = sizeof(vertices[0]) * vertices.size(); VkBuffer stagingBuffer; VkDeviceMemory stagingBufferMemory; createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, // 资源只能由单个队列族独占 stagingBufferMemory, VK_SHARING_MODE_EXCLUSIVE); void* data; vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &amp;data); memcpy(data, vertices.data(), (size_t) bufferSize); vkUnmapMemory(device, stagingBufferMemory); // 注意这里的MEMORY_PROPERTY是VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT！ createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, vertexBuffer, // 资源只能由单个队列族独占 vertexBufferMemory, VK_SHARING_MODE_EXCLUSIVE); // 将暂存缓冲区的数据内容拷贝到顶点缓冲区 copyBuffer(stagingBuffer, vertexBuffer, bufferSize); // 销毁暂存缓冲区，释放内存 vkDestroyBuffer(device, stagingBuffer, nullptr); vkFreeMemory(device, stagingBufferMemory, nullptr);&#125; 在这里思考一下，为什么要使用一个暂存缓冲区替换原来的直接使用memcpy呢，而且使用暂存缓冲还额外多了一个创建缓冲区的操作？ 因为图形管道使用顶点数据缓冲区时，如果需要更改顶点数据内容，还需要等待memcpy,如果使用暂存缓冲区，可以将更改顶点数据内容的操作放在另一个线程执行，等到写完之后，再使用vkCmdCopyBuffer指令拷贝内存数据，这样图形管道最多等待这个指令拷贝的时间。当然这一点现在看不出来优势，等我们的顶点数据多而且绘制内容复杂的时候就可以体现出来了。 让我们更近一步，考虑到每次拷贝都需要执行vkAllocateCommandBuffers分配内存，不如一开始就请求一块合适的内存区域，毕竟这个函数开销还是很大的。通过使用我们在许多函数中看到的偏移参数，在许多不同的对象之间分割单个分配或回收。可以自己实现也可以使用GPUOpen倡议提供的VulkanMemoryAllocator库。 三. 索引缓冲区在真实世界的应用程序中渲染的3D网格经常会在多个三角形之间共享顶点。比如画一个矩形: 绘制一个矩形需要两个三角形(基本绘制单元只有点、线和三角形，所以矩形是两个三角形之和)，这意味着需要有6个顶点的顶点缓冲区。问题是两个顶点的部分数据重复，会产生50%的冗余。在更复杂的网格中，只会变得更糟，因为顶点会在平均3个三角形中重复使用。解决这个问题的方法是使用索引缓冲区。 索引缓冲区本质上是一个指向顶点缓冲区的指针数组。它允许重新排序顶点数据，并为多个顶点重用现有数据。上面的插图演示了一个顶点缓冲区包含四个不同的顶点，其索引缓冲区会是什么样子的。前三个索引定义了右上角的三角形，后三个索引定义了左下角三角形的顶点(顺时钟)。 3.1 创建索引缓冲区接下来将修改顶点数据并添加索引数据来绘制一个矩形，像上图中一样。修改顶点数据以表示四个角: 123456const std::vector&lt;Vertex&gt; vertices = &#123; &#123;&#123;-0.5f, -0.5f&#125;, &#123;1.0f, 0.0f, 0.0f&#125;&#125;, &#123;&#123;0.5f, -0.5f&#125;, &#123;0.0f, 1.0f, 0.0f&#125;&#125;, &#123;&#123;0.5f, 0.5f&#125;, &#123;0.0f, 0.0f, 1.0f&#125;&#125;, &#123;&#123;-0.5f, 0.5f&#125;, &#123;1.0f, 1.0f, 1.0f&#125;&#125;&#125;; 左上角是红色的，右上方是绿色的，右下角是蓝色的，左下角是白色的。现在添加一个新的数组索引来表示索引缓冲区的内容，匹配图中的索引来绘制右上三角形和左下三角形。 123const std::vector&lt;uint16_t&gt; indices = &#123; 0, 1, 2, 2, 3, 0&#125;; 可以使用uint16_t或uint32_t作为索引缓冲区，这取决于顶点中条目的数量。我们可以坚持uint16_t现在，因为我们使用少于65535唯一顶点。 就像顶点数据一样，索引需要上传到VkBuffer中，GPU才能访问它们。定义两个新的类成员来保存索引缓冲区的资源: 123456789101112131415161718192021222324252627282930313233343536VkBuffer indexBuffer;VkDeviceMemory indexBufferMemory;void initVulkan() &#123; ... createVertexBuffer(); createIndexBuffer(); ...&#125;void createIndexBuffer() &#123; VkDeviceSize bufferSize = sizeof(indices[0]) * indices.size(); VkBuffer stagingBuffer; VkDeviceMemory stagingBufferMemory; createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT, stagingBuffer, // 资源只能由单个队列族独占 stagingBufferMemory, VK_SHARING_MODE_EXCLUSIVE); void* data; vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &amp;data); memcpy(data, indices.data(), (size_t) bufferSize); vkUnmapMemory(device, stagingBufferMemory); createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_INDEX_BUFFER_BIT, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, indexBuffer, // 资源只能由单个队列族独占 indexBufferMemory, VK_SHARING_MODE_EXCLUSIVE); // 将暂存缓冲区的数据内容拷贝到顶点缓冲区 copyBuffer(stagingBuffer, indexBuffer, bufferSize); // 销毁暂存缓冲区，释放内存 vkDestroyBuffer(device, stagingBuffer, nullptr); vkFreeMemory(device, stagingBufferMemory, nullptr);&#125; 可以看到 createIndexBuffer 几乎和 createVertexBuffer 一样，只有bufferSize和VkBufferUsageFlags不同而已，毕竟都是只是缓冲区。 索引缓冲同样也需要显示销毁： 12345678void cleanup() &#123; cleanupSwapChain(); vkDestroyBuffer(device, indexBuffer, nullptr); vkFreeMemory(device, indexBufferMemory, nullptr); vkDestroyBuffer(device, vertexBuffer, nullptr); vkFreeMemory(device, vertexBufferMemory, nullptr); ...&#125; 3.2 使用顶点缓冲使用索引缓冲区绘制涉及createCommandBuffers的两个更改。我们首先需要绑定索引缓冲区，就像我们对顶点缓冲区所做的那样。但是索引缓冲区只能有一个。而且，不可能对每个顶点属性使用不同的索引，所以即使只有一个属性发生变化，仍然需要完全复制顶点数据。 索引缓冲区与vkCmdBindIndexBuffer绑定，vkCmdBindIndexBuffer包含索引缓冲区、其中的字节偏移量和索引数据类型作为参数。如前所述，可能的类型是VK_INDEX_TYPE_UINT16和VK_INDEX_TYPE_UINT32。 仅仅绑定索引缓冲区还不能改变任何东西，我们还需要更改绘图命令来告诉Vulkan使用索引缓冲区。移除vkCmdDraw，并用vkCmdDrawIndexed替换: 123456789VkBuffer vertexBuffers[] = &#123;vertexBuffer&#125;;VkDeviceSize offsets[] = &#123;0&#125;;vkCmdBindVertexBuffers(commandBuffers[i], 0, 1, vertexBuffers, offsets);// VK_INDEX_TYPE_UINT16 是因为我们索引用的就是uint16_tvkCmdBindIndexBuffer(commandBuffers[i], indexBuffer, 0, VK_INDEX_TYPE_UINT16);// 使用vkCmdDrawIndexed替换vkCmdDraw// vkCmdDraw(commandBuffers[i], static_cast&lt;uint32_t&gt;(vertices.size()), 1, 0, 0);vkCmdDrawIndexed(commandBuffers[i], static_cast&lt;uint32_t&gt;(indices.size()), 1, 0, 0, 0);vkCmdEndRenderPass(commandBuffers[i]); 对vkCmdDrawIndexed函数的调用非常类似于vkCmdDraw。前两个参数指定索引的数量和实例的数量。我们没有使用实例，所以只指定一个实例。索引的数量表示将被传递到顶点缓冲区的顶点的数量。下一个参数指定到索引缓冲区的偏移量，使用值1将导致显卡从第二个索引开始读取。倒数第二个参数指定要添加到索引缓冲区中的索引的偏移量。最后一个参数指定了实例化的偏移量。 四. 绘制命令概述绘制命令大致分为两类:非索引绘图命令和索引绘图命令。 4.1 非索引绘图命令非索引绘图命令为顶点着色器提供一个连续的vertexIndex。顺序索引是由设备自动生成的，这些命令有: vkCmdDraw vkCmdDrawIndirect vkCmdDrawIndirectCount vkCmdDrawIndirectCountKHR vkCmdDrawIndirectCountAMD 4.1.1 vkCmdDrawvkCmdDraw可以记录一个非索引的绘制，其原型如下: 123456void vkCmdDraw( VkCommandBuffer commandBuffer, uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance); commandBuffer是命令记录到的命令缓冲区 vertexCount是要绘制的顶点数 instanceCount是要绘制的实例数量 firstVertex是绘制的第一个顶点的索引 firstInstance是绘制的第一个实例的实例ID 执行该命令时，将使用当前基本体拓扑和顶点计数连续顶点索引（第一个顶点索引值等于第一个顶点）组装基本体。原语绘制实例数量为instanceCount，instanceIndex从firstInstance开始，每个实例依次递增。组装原语的执行要绑定到图形管道。 4.1.2 vkCmdDrawIndirectvkCmdDrawIndirect用于记录非索引的间接绘制，其原型如下: 123456void vkCmdDrawIndirect( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride); commandBuffer是记录命令的命令缓冲区 buffer是包含绘图参数的缓冲区 offset是参数开始的缓冲区中的字节偏移量 drawCount是要执行的绘制数，可以为零 stride是连续绘图参数集之间的字节步幅 vkCmdDrawIndirect的行为与vkCmdDraw类似，不同的是参数是在执行过程中由设备从缓冲区读取的。drawCount绘制由命令执行，参数从缓冲区的偏移量开始，每次绘制时按步长字节递增。每次绘制的参数都编码在一个VkDrawIndirectCommand结构数组中。如果drawCount小于或等于1，则忽略stride。 4.1.3 vkCmdDrawIndirectCount、vkCmdDrawIndirectCountKHR、vkCmdDrawIndirectCountAMD记录来自缓冲区的draw调用计数的非索引绘制调用,可以使用vkCmdDrawIndirectCount，vkCmdDrawIndirectCountKHR或者vkCmdDrawIndirectCountAMD, 这三个指令几乎等效： 1234567891011121314151617181920212223242526void vkCmdDrawIndirectCount( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);void vkCmdDrawIndirectCountKHR( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);void vkCmdDrawIndirectCountAMD( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride); commandBuffer是记录命令的命令缓冲区 buffer是包含绘图参数的缓冲区 offset是参数开始的缓冲区中的字节偏移量 countBuffer是包含绘图计数的缓冲区 countBufferOffset是开始绘制计数的字节偏移到countBuffer中 maxDrawCount指定将执行的最大绘制数。实际执行的绘制调用数是countBuffer和maxDrawCount中指定的最小计数 stride是连续绘图参数集之间的字节步幅 vkCmdDrawIndirectCount的行为与vkCmdDrawIndirectCount类似，只是在执行期间设备从缓冲区读取绘制计数。该命令将从位于countBufferOffset的countBuffer中读取一个无符号32位整数，并将其用作绘图计数。 4.2 索引绘图命令索引图形命令从索引缓冲区读取索引值，并使用此命令计算顶点着色器的vertexIndex值。这些命令有： vkCmdDrawIndexed vkCmdDrawIndexedIndirect vkCmdDrawIndexedIndirectCount vkCmdDrawIndexedIndirectCountKHR vkCmdDrawIndexedIndirectCountAMD 4.2.1 vkCmdDrawIndexedvkCmdDrawIndexed可以记录一个索引的绘制，其原型如下: 1234567void vkCmdDrawIndexed( VkCommandBuffer commandBuffer, uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, int32_t vertexOffset, uint32_t firstInstance); commandBuffer是命令记录到的命令缓冲区 indexCount是要绘制的顶点数 instanceCount是要绘制的实例数 firstIndex是索引缓冲区中的基索引 vertexOffset是在索引到顶点缓冲区之前添加到顶点索引的值 firstInstance是要绘制的第一个实例的实例ID 在执行该命令时，使用当前基元拓扑和indexCount顶点组装基元，这些顶点的索引是从索引缓冲区检索的。索引缓冲区被视为一个紧凑封装的大小无符号整数数组，该整数由vkCmdBindIndexBuffer::indexType形参定义，该形参与该缓冲区绑定。 第一个顶点索引位于绑定索引缓冲区中的firstIndex * indexSize + offset的偏移量，其中offset是由vkCmdBindIndexBuffer指定的偏移量，indexSize是由indexType指定的类型的字节大小。从索引缓冲区中连续的位置检索后续的索引值。索引首先与原始的重启值比较，然后0扩展到32位(如果indexType是VK_INDEX_TYPE_UINT8_EXT或VK_INDEX_TYPE_UINT16)，并添加vertexOffset，然后再作为vertexIndex值提供。 这些原语是用从firstInstance开始的instanceIndex绘制instanceCount次数，并按顺序增加每个实例。组装的原语执行应绑定图形管道。 4.2.2 vkCmdDrawIndexedIndirectvkCmdDrawIndexedIndirect用于记录索引的间接绘制，其原型如下: 123456void vkCmdDrawIndexedIndirect( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride); commandBuffer是记录命令的命令缓冲区 buffer是包含绘图参数的缓冲区 offset是参数开始的缓冲区中的字节偏移量 drawCount是要执行的绘制数，可以为零 stride是连续绘图参数集之间的字节步幅 vkCmdDrawIndexedIndirect的行为与vkcmddrawindex类似，不同的是参数是在执行过程中由设备从缓冲区中读取的。drawCount绘制由命令执行，参数从缓冲区的偏移量开始，每次绘制时按步长字节递增。每次绘制的参数都编码在vkdrawindexdindirectcommand结构的数组中。如果drawCount小于或等于1，则忽略stride。 4.2.3 vkCmdDrawIndexedIndirectCount、vkCmdDrawIndexedIndirectKHR、vkCmdDrawIndexedIndirectAMD同样的，记录来自缓冲区的draw调用计数的索引绘制调用,可以使用, 这三个指令几乎等效： 1234567891011121314151617181920212223242526void vkCmdDrawIndexedIndirectCount( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);void vkCmdDrawIndexedIndirectCountKHR( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride);void vkCmdDrawIndexedIndirectCountAMD( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride); commandBuffer是记录命令的命令缓冲区 buffer是包含绘图参数的缓冲区 offset是参数开始的缓冲区中的字节偏移量 countBuffer是包含绘制计数的缓冲区 countBufferOffset是进入countBuffer的字节偏移量，在这里开始绘制计数 maxDrawCount指定将执行的最大绘制数。实际执行的draw调用数是countBuffer和maxDrawCount中指定的最小计数 stride是连续绘图参数集之间的字节步幅 vkCmdDrawIndexedIndirectCount的行为与vkCmdDrawIndexedIndirect类似，只是在执行期间设备从缓冲区读取绘制计数。该命令将从位于countBufferOffset的countBuffer中读取一个无符号32位整数，并将其用作绘图计数。 五. 小结在上一篇文章中，我们使用顶点描述符VkVertexInputBindingDescription和VkVertexInputAttributeDescription替换了硬编码顶点，并且使用VkBuffer存储了顶点数据，好处是可随时更改顶点信息。在本文中，我们又使用了暂存缓冲优化了顶点缓冲每次都需要memcpy的弊端，还介绍了顶点索引，使得我们的程序可以画出更多的图形。 使用暂存缓冲是因为图形管道使用顶点数据缓冲区时，如果需要更改顶点数据内容，还需要等待memcpy,如果使用暂存缓冲区，可以将更改顶点数据内容的操作放在另一个线程执行，等到写完之后，再使用vkCmdCopyBuffer指令拷贝内存数据，这样图形管道最多等待这个指令拷贝的时间。当顶点数据多而且绘制内容复杂的时候就可以体现出来了。 而使用顶点索引缓冲是和顶点缓冲几乎一样的流程，只是VkBuffer创建时的VkBufferUsageFlags和size(对应的数据不同嘛)不同。 不过这里还是很好奇，顶点索引和顶点的关系，比如如果我们顶点坐标不变，顶点索引改成： 1234// 顶点索引std::vector&lt;uint16_t&gt; indices = &#123; 0, 1, 2, 2, 3, 1&#125;; 对应的图形就变成了: 但是当顶点索引改成: 1234// 顶点索引std::vector&lt;uint16_t&gt; indices = &#123; 0, 1, 2, 2, 3, 4&#125;; 对应的图形就变成了: 这个顶点索引和最终图像的生成到底是什么个关系呢，参考:https://zhuanlan.zhihu.com/p/97496535 Vulkan中的坐标系使用的右手坐标系，相比OpenGL是用的左手坐标系： 其中原点(0,0,0)在屏幕中央, 所以当我们想画一个三棱锥可以使用如下顶点及索引: 1234567891011// 顶点数据std::vector&lt;Vertex&gt; vertices = &#123; &#123;&#123;-0.25f, -0.01f&#125;, &#123;1.0f, 0.0f, 0.0f&#125;&#125;, &#123;&#123;0.01f, -0.5f&#125;, &#123;0.0f, 1.0f, 0.0f&#125;&#125;, &#123;&#123;0.25f, 0.01f&#125;, &#123;0.0f, 0.0f, 1.0f&#125;&#125;, &#123;&#123;-0.01f, 0.15f&#125;, &#123;1.0f, 1.0f, 1.0f&#125;&#125;&#125;;// 顶点索引std::vector&lt;uint16_t&gt; indices = &#123; 0,1,2,2,3,0,0,1,3,1,2,3&#125;; 接下来，让我们再接再厉，学习使用资源描述符来加载3D图形。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(11)-顶点输入描述及顶点缓冲的创建","slug":"Vulkan入门-11-顶点输入描述及顶点缓冲的创建","date":"2022-02-26T19:34:26.000Z","updated":"2022-02-26T19:41:34.967Z","comments":true,"path":"2022/02/27/Vulkan入门-11-顶点输入描述及顶点缓冲的创建/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-11-%E9%A1%B6%E7%82%B9%E8%BE%93%E5%85%A5%E6%8F%8F%E8%BF%B0%E5%8F%8A%E9%A1%B6%E7%82%B9%E7%BC%93%E5%86%B2%E7%9A%84%E5%88%9B%E5%BB%BA/","excerpt":"简述接下来，我们将用内存中的顶点缓冲区替换顶点着色器中的硬编码顶点数据。我们将从创建CPU可见缓冲区的最简单方法开始，并使用memcpy将顶点数据直接复制到其中，然后我们将看到如何使用分段缓冲区将顶点数据复制到高性能内存。","text":"简述接下来，我们将用内存中的顶点缓冲区替换顶点着色器中的硬编码顶点数据。我们将从创建CPU可见缓冲区的最简单方法开始，并使用memcpy将顶点数据直接复制到其中，然后我们将看到如何使用分段缓冲区将顶点数据复制到高性能内存。 首先修改顶点着色器不再包含顶点数据在着色器代码本身， 顶点着色器使用in关键字从顶点缓冲区获取输入。 12345678910111213#version 450#extension GL_ARB_separate_shader_objects : enablelayout(location = 0) in vec2 inPosition;layout(location = 1) in vec3 inColor;// 输出为fragColorlayout(location = 0) out vec3 fragColor;void main() &#123; gl_Position = vec4(inPosition, 0.0, 1.0); fragColor = inColor;&#125; inPosition和inColor变量是顶点属性。 它们是在顶点缓冲区中为每个顶点指定的属性，就像我们使用两个数组为每个顶点手动指定位置和颜色一样。 更改后记得重新编译顶点着色器！ 像fragColor一样，layout（location &#x3D; x）批注为输入分配索引，我们之后可以使用索引来引用它们。 重要的是要知道某些类型（例如dvec3 64位向量）使用多个插槽。 这意味着之后的索引必须至少高2倍（这里没搞懂, 需要学习一下GLSL的语法:https://www.khronos.org/opengl/wiki/Layout_Qualifier_(GLSL)）： 12layout(location = 0) in dvec3 inPosition;layout(location = 2) in vec3 inColor; 一. 顶点数据将顶点数据从着色器代码移动到程序代码中的数组中。需要引入GLM库，它为我们提供了与线性代数相关的类型，如向量和矩阵, 有与着色器语言中使用的向量类型完全匹配的c++类型。我们将使用这些类型来指定位置和颜色向量。 123456789101112#include &lt;glm/glm.hpp&gt;struct Vertex &#123; glm::vec2 pos; glm::vec3 color;&#125;;const std::vector&lt;Vertex&gt; vertices = &#123; &#123;&#123;0.0f, -0.5f&#125;, &#123;1.0f, 0.0f, 0.0f&#125;&#125;, &#123;&#123;0.5f, 0.5f&#125;, &#123;0.0f, 1.0f, 0.0f&#125;&#125;, &#123;&#123;-0.5f, 0.5f&#125;, &#123;0.0f, 0.0f, 1.0f&#125;&#125;&#125;; 创建一个名为Vertex的新结构，内有两个属性，我们将在其内部的顶点着色器中使用. 使用顶点结构来指定顶点数据的数组。我们使用和之前完全相同的位置和颜色值，但现在它们被组合到一个顶点数组中, 这就是所谓的交错顶点(interleaving vertex)属性。 接下来是告诉Vulkan，一旦数据格式被上传到GPU内存，如何将其传递到顶点着色器。而传达这个信息需要有两种类型的结构: VkVertexInputBindingDescription和VkVertexInputAttributeDescription. 1.1 绑定描述第一个结构是VkVertexInputBindingDescription，我们将向顶点结构添加一个成员函数，用正确的数据填充它。 123456789struct Vertex &#123; glm::vec2 pos; glm::vec3 color; static VkVertexInputBindingDescription getBindingDescription() &#123; VkVertexInputBindingDescription bindingDescription = &#123;&#125;; return bindingDescription; &#125;&#125;; 1.1.1 VkVertexInputBindingDescription12345typedef struct VkVertexInputBindingDescription &#123; uint32_t binding; uint32_t stride; VkVertexInputRate inputRate;&#125; VkVertexInputBindingDescription; binding: 该结构描述的绑定号 stride : 是缓冲区中两个连续元素之间的距离(以字节为单位) inputRate: 是一个VkVertexInputRate值，指定顶点属性寻址是顶点索引还是实例索引的函数 VK_VERTEX_INPUT_RATE_VERTEX: 指定顶点属性寻址是顶点索引的函数，即移动到每个顶点后的下一个数据项 VK_VERTEX_INPUT_RATE_INSTANCE: 指定顶点属性寻址是实例索引的函数，即移到每个实例之后的下一个数据项 顶点绑定描述在所有顶点中从内存加载数据的速率。它指定数据条目之间的字节数，以及是在每个顶点之后还是在每个实例之后移动到下一个数据条目。 1.1.2 绑定所有的顶点数据都打包在一个数组中，所以我们只需要一个绑定: 12345678910static VkVertexInputBindingDescription getBindingDescription() &#123; VkVertexInputBindingDescription bindingDescription = &#123;&#125;; VkVertexInputBindingDescription bindingDescription = &#123;&#125;; bindingDescription.binding = 0; bindingDescription.stride = sizeof(Vertex); bindingDescription.inputRate = VK_VERTEX_INPUT_RATE_VERTEX; return bindingDescription;&#125; 1.2 属性描述第二个描述如何处理顶点输入的结构是VkVertexInputAttributeDescription。我们将添加另一个辅助函数到顶点来填充这些结构体。 1234567891011121314151617#include &lt;array&gt;struct Vertex &#123; glm::vec2 pos; glm::vec3 color; static VkVertexInputBindingDescription getBindingDescription() &#123; VkVertexInputBindingDescription bindingDescription = &#123;&#125;; return bindingDescription; &#125; static std::array&lt;VkVertexInputAttributeDescription, 2&gt; getAttributeDescriptions() &#123; std::array&lt;VkVertexInputAttributeDescription, 2&gt; attributeDescriptions = &#123;&#125;; return attributeDescriptions; &#125;&#125;; 正如函数原型所表明的，有两个VkVertexInputAttributeDescription,分别代表位置和颜色。 属性描述结构描述如何从源自绑定描述的顶点数据块中提取顶点属性。 1.2.1 VkVertexInputAttributeDescription123456typedef struct VkVertexInputAttributeDescription &#123; uint32_t location; uint32_t binding; VkFormat format; uint32_t offset;&#125; VkVertexInputAttributeDescription; location: 属性的着色器绑定位置号 binding: 该属性获取其数据的绑定号 format: 指顶点属性数据的大小和类型, 应使用颜色通道数量与着色器数据类型中的组件数量相匹配的格式 float: VK_FORMAT_R32_SFLOAT vec2: VK_FORMAT_R32G32_SFLOAT vec3: VK_FORMAT_R32G32B32_SFLOAT vec4: VK_FORMAT_R32G32B32A32_SFLOAT offset: 该属性相对于顶点输入绑定中元素开始的字节偏移量 1.2.2 绑定12345678910111213141516static std::array&lt;VkVertexInputAttributeDescription, 2&gt; getAttributeDescriptions() &#123; std::array&lt;VkVertexInputAttributeDescription, 2&gt; attributeDescriptions = &#123;&#125;; // position attributeDescriptions[0].binding = 0; attributeDescriptions[0].location = 0; attributeDescriptions[0].format = VK_FORMAT_R32G32_SFLOAT; attributeDescriptions[0].offset = offsetof(Vertex, pos); // color attributeDescriptions[1].binding = 0; attributeDescriptions[1].location = 1; attributeDescriptions[1].format = VK_FORMAT_R32G32B32_SFLOAT; attributeDescriptions[1].offset = offsetof(Vertex, color); return attributeDescriptions;&#125; 这里offsetof函数是用来获取偏移量的。 1.3 管道输入顶点现在需要通过引用createGraphicsPipeline中的结构来设置图形管道以接受这种格式的顶点数据。找到vertexInputInfo结构体并修改它以引用以下两种描述: 1234567auto bindingDescription = Vertex::getBindingDescription();auto attributeDescriptions = Vertex::getAttributeDescriptions();vertexInputInfo.vertexBindingDescriptionCount = 1;vertexInputInfo.vertexAttributeDescriptionCount = static_cast&lt;uint32_t&gt;(attributeDescriptions.size());vertexInputInfo.pVertexBindingDescriptions = &amp;bindingDescription;vertexInputInfo.pVertexAttributeDescriptions = attributeDescriptions.data(); 管道现在已经准备好接受顶点容器格式的顶点数据，并将其传递给顶点着色器。 如果在启用验证层的情况下运行程序，将报出没有顶点缓冲区绑定到绑定。下一步是创建一个顶点缓冲区，并将顶点数据移动到其中，以便GPU能够访问它。 二. 顶点缓冲区Vulkan中的缓冲区是用于存储任意数据的内存区域，这些数据可以被显卡读取，通过描述符集或特定命令将它们绑定到图形或计算管道，或者直接将它们指定为特定命令的参数。它们可以用来存储顶点数据，但也可以用于许多其他目的，以后中探讨。 与我们目前处理的Vulkan对象不同，缓冲区不会自动为自己分配内存， Vulkan API让程序员控制了几乎所有的事情，内存管理就是其中之一。 2.1 创建缓冲区创建一个新的函数createVertexBuffer，并在createCommandBuffers之前从initVulkan调用它： 123456789101112void initVulkan() &#123; ... createCommandPool(); // 有可能使用指令，所以需要在指令池创建之后创建 createVertexBuffer(); createCommandBuffers(); createSyncObjects();&#125;void createVertexBuffer() &#123;&#125; 创建顶点缓冲区需要填充VkBufferCreateInfo结构。 2.1.1 VkBufferCreateInfo12345678910typedef struct VkBufferCreateInfo &#123; VkStructureType sType; const void* pNext; VkBufferCreateFlags flags; VkDeviceSize size; VkBufferUsageFlags usage; VkSharingMode sharingMode; uint32_t queueFamilyIndexCount; const uint32_t* pQueueFamilyIndices;&#125; VkBufferCreateInfo; sType: 结构体类型, VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO pNext: 为空或指向特定于扩展的结构的指针 flags: VkBufferCreateFlagBits的位掩码，指定缓冲区的附加参数, 用于配置稀疏缓冲区内存 size: 是要创建的缓冲区的大小(以字节为单位) usage: VkBufferUsageFlagBits的位掩码，指定缓冲区允许的用法 sharingMode: VkSharingMode值，指定当多个队列族访问缓冲区时，缓冲区的共享模式 VK_SHARING_MODE_EXCLUSIVE: 指定对对象的任何范围或图像子资源的访问一次只能由单个队列族独占 VK_SHARING_MODE_CONCURRENT: 指定支持对来自多个队列族的对象的任何范围或映像子资源的并发访问 queueFamilyIndexCount: 是pQueueFamilyIndices数组中的数量 pQueueFamilyIndices: 将访问这个缓冲区的队列族列表(如果shareingmode不是VK_SHARING_MODE_CONCURRENT则忽略) 2.1.2 vkCreateBuffer12345VkResult vkCreateBuffer( VkDevice device, const VkBufferCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkBuffer* pBuffer); device: 创建缓冲区对象的逻辑设备 pCreateInfo: 指向VkBufferCreateInfo结构的指针，该结构包含影响缓冲区创建的参数 pAllocator: 控制主机内存分配 pBuffer: 指向VkBuffer句柄的指针，在该句柄中返回结果缓冲区对象 VkBuffer缓冲区表示用于各种目的的数据的线性数组，通过描述符集或特定命令将它们绑定到图形或计算管道，或者直接将它们指定为特定命令的参数。 缓冲区由VkBuffer句柄表示： 2.1.3 createVertexBuffer12345678910111213VkBuffer vertexBuffer;void createVertexBuffer() &#123; VkBufferCreateInfo bufferInfo = &#123;&#125;; bufferInfo.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO; bufferInfo.size = sizeof(vertices[0]) * vertices.size(); bufferInfo.usage = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT; bufferInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE; if (vkCreateBuffer(device, &amp;bufferInfo, nullptr, &amp;vertexBuffer) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create vertex buffer!&quot;); &#125;&#125; 创建后不需要时应该手动销毁: 123456void cleanup() &#123; cleanupSwapChain(); vkDestroyBuffer(device, vertexBuffer, nullptr); ...&#125; 2.2 给顶点缓冲区分配内存缓冲区已创建，但实际上尚未分配任何内存。为缓冲区分配内存的第一步是使用vkGetBufferMemoryRequirements函数查询其内存需求. 12VkMemoryRequirements memRequirements;vkGetBufferMemoryRequirements(device, vertexBuffer, &amp;memRequirements); 2.2.1 vkGetBufferMemoryRequirements1234void vkGetBufferMemoryRequirements( VkDevice device, VkBuffer buffer, VkMemoryRequirements* pMemoryRequirements); device: 创建缓冲区对象的逻辑设备 buffer: 待请求所需内存大小的缓冲区 pMemoryRequirements: 指向VkMemoryRequirements结构的指针，在该结构中返回缓冲区对象的内存需求 2.2.2 VkMemoryRequirements12345typedef struct VkMemoryRequirements &#123; VkDeviceSize size; VkDeviceSize alignment; uint32_t memoryTypeBits;&#125; VkMemoryRequirements; size: 资源所需的内存分配的大小（以字节为单位） alignment: 资源所需的分配内偏移量的对齐（以字节为单位）,即缓冲区在分配的内存区域中开始的偏移量 memoryTypeBits: 适合缓冲区的内存类型的位字段 2.2.3 findMemoryType图形显卡可以提供不同类型的内存进行分配。每种类型的内存在允许的操作和性能特性方面都有所不同。 我们需要结合缓冲区的需求和我们自己的应用程序需求来找到合适的内存类型。为此，我们创建一个新函数findMemoryType: 1234567891011121314uint32_t findMemoryType(uint32_t typeFilter, VkMemoryPropertyFlags properties) &#123; // 首先获取物理显卡支持的内存类型 VkPhysicalDeviceMemoryProperties memProperties; vkGetPhysicalDeviceMemoryProperties(physicalDevice, &amp;memProperties); for (uint32_t i = 0; i &lt; memProperties.memoryTypeCount; i++) &#123; if (typeFilter &amp; (1 &lt;&lt; i) &amp;&amp; // 可能有多个属性 (memProperties.memoryTypes[i].propertyFlags &amp; properties) == properties) &#123; return i; &#125; &#125; throw std::runtime_error(&quot;failed to find suitable memory type!&quot;);&#125; typeFilter参数用于指定适合的内存类型的位字段。 2.2.3.1 VkPhysicalDeviceMemoryProperties123456typedef struct VkPhysicalDeviceMemoryProperties &#123; uint32_t memoryTypeCount; VkMemoryType memoryTypes[VK_MAX_MEMORY_TYPES]; uint32_t memoryHeapCount; VkMemoryHeap memoryHeaps[VK_MAX_MEMORY_HEAPS];&#125; VkPhysicalDeviceMemoryProperties; memoryTypeCount: memoryTypes数组中的有效元素数。 memoryTypes: VK_MAX_MEMORY_TYPES_Vk MemoryType结构数组，描述可用于访问从memoryHeaps指定的堆中分配的内存的内存类型。 memoryHeapCount: memoryHeaps数组中的有效元素数。 memoryHeaps: VK_MAX_MEMORY_HEAPS VkMemoryHeap结构的数组，描述可以从中分配内存的内存堆。 VkPhysicalDeviceMemoryProperties结构描述了许多内存堆以及一些内存类型，这些内存类型可用于访问这些堆中分配的内存。每个堆描述特定大小的内存资源，每个内存类型描述一组内存属性（例如，主机缓存与未缓存），这些属性可以与给定内存堆一起使用。使用特定内存类型的分配将消耗该内存类型的堆索引指示的堆中的资源。多个内存类型可以共享每个堆，堆和内存类型提供了一种机制，以宣告物理内存资源的精确大小，同时允许将内存与各种不同的属性一起使用。 2.2.4 分配内存通过findMemoryType, 现在可以获取正确的内存类型，接下来就是给VkBuffer分配内存了。 不同类型的内存具有不同的属性。一些类型的内存可以被CPU访问，一些不可以。一些类型可以在GPU和CPU间保持数据一致性、一些类型可以被CPU缓存使用等等。可以通过查询物理设备获取这些信息。我们可以根据需要使用不同的内存类型，比如对于暂存资源，我们需要使用可以被CPU访问的内存类型。对于用于渲染的图像、顶点数据，我们通常为其分配GPU内存。 内存分配现在只需指定大小和类型就可以了，这两种类型都来自于顶点缓冲区的内存需求和所需的属性。创建一个类成员来将句柄存储到内存中，并用vkallocatemory分配它。 2.2.4.1 VkMemoryAllocateInfo123456typedef struct VkMemoryAllocateInfo &#123; VkStructureType sType; const void* pNext; VkDeviceSize allocationSize; uint32_t memoryTypeIndex;&#125; VkMemoryAllocateInfo; sType: 结构体类型, VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO pNext: 为空或指向特定于扩展的结构的指针 allocationSize: 内存分配大小，以字节为单位 memoryTypeIndex: 内存类型的索引，VkPhysicalDeviceMemoryProperties结构的memoryTypes数组中的数据 2.2.4.2 内存分配123456789101112void createVertexBuffer() &#123; ... VkMemoryAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO; allocInfo.allocationSize = memRequirements.size; allocInfo.memoryTypeIndex = findMemoryType(memRequirements.memoryTypeBits, VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT); if (vkAllocateMemory(device, &amp;allocInfo, nullptr, &amp;vertexBufferMemory) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate vertex buffer memory!&quot;); &#125;&#125; 内存对象对设备内存中的数据进行操作可以使用vkAllocateMemory函数: 12345VkResult vkAllocateMemory( VkDevice device, const VkMemoryAllocateInfo* pAllocateInfo, const VkAllocationCallbacks* pAllocator, VkDeviceMemory* pMemory); device: 是拥有内存的逻辑设备 pAllocateInfo: 指向描述分配参数的VkMemoryAllocateInfo结构的指针。成功返回的分配必须使用请求的参数 - 实现不允许替换。 pAllocator: 控制内存分配 pMemory: 指向VkDeviceMemory句柄的指针，在该句柄中返回有关已分配内存的信息 vkallocatemory返回的分配保证满足实现的任何对齐要求。例如，如果一个实现需要128字节的图像对齐和64字节的缓冲区对齐，那么通过这个机制返回的设备内存将是128字节对齐的。这确保了应用程序可以在同一内存对象中正确地子分配不同类型的对象（具有可能不同的对齐要求）。 2.2.4.3 内存与缓冲区关联如果内存分配成功，那么可以使用vkBindBufferMemory将此内存与缓冲区关联： 1vkBindBufferMemory(device, vertexBuffer, vertexBufferMemory, 0); 要将内存附加到缓冲区对象可以调用vkBindBufferMemory函数： 12345VkResult vkBindBufferMemory( VkDevice device, VkBuffer buffer, VkDeviceMemory memory, VkDeviceSize memoryOffset); device: 是拥有内存的逻辑设备 buffer: 要附加到内存的缓冲区 memory: 描述要附加的设备内存的VkDeviceMemory对象 memoryOffset: 要绑定到缓冲区的内存区域的起始偏移量。因为这个内存被专门分配给这个顶点缓冲区，所以偏移量是0。如果偏移量不为零，则要求它可以被整除内存memRequirements.alignment. 一旦缓冲区不再使用，绑定到缓冲区对象的内存可能会被释放，因此让我们在缓冲区被销毁后释放它： 123456789// 在 vulkan 中推荐在创建的资源不需要后主动释放void cleanup() &#123; // 清理交换链关联资源 cleanupSwapChain(); // 清理顶点缓冲区 vkDestroyBuffer(device, vertexBuffer, nullptr); vkFreeMemory(device, vertexBufferMemory, nullptr); ...&#125; 2.3 填充顶点缓冲区现在是时候将顶点数据复制到缓冲区了。可以通过使用vkMapMemory将缓冲内存映射到CPU可访问内存来实现: 1234567VkResult vkMapMemory( VkDevice device, VkDeviceMemory memory, VkDeviceSize offset, VkDeviceSize size, VkMemoryMapFlags flags, void** ppData); device: 拥有内存的逻辑设备 memory: 要映射的VkDeviceMemory对象 offset: 从内存对象开始的以零为基础的字节偏移量 size: 映射的内存范围的大小，或者是要从偏移量映射到分配末尾的VK_WHOLE_SIZE大小 flags: 保留供将来使用 ppData: 指向void*变量的指针，指向映射内存的指针的输出。在该变量中返回指向映射范围开头的主机可访问指针。此指针减去偏移量必须至少与VkPhysicalDeviceLimits:：minMemoryMapAlignment对齐 此函数允许我们访问由偏移量和大小定义的指定内存资源区域: 1234567void* data;// 将缓冲内存映射到CPU可访问内存vkMapMemory(device, vertexBufferMemory, 0, bufferInfo.size, 0, &amp;data);// 将顶点数据拷贝到映射内存中memcpy(data, vertices.data(), (size_t) bufferInfo.size);// 使用vkUnmapMemory再次取消映射vkUnmapMemory(device, vertexBufferMemory); 填充顶点数据到缓冲区内存的方式就是先映射然后拷贝，最后解映射。 但是驱动程序可能不会立即将数据复制到缓冲区内存中，例如因为缓存(Cache)机制。有两种方法可以解决这个问题： 缓存的内存类型使用主机相关的内存堆，用VK_MEMORY_PROPERTY_HOST_COHERENT_BIT表示 在写入映射内存后调用vkFlushMappedMemoryRanges以及在从映射内存读取之前调用vkInvalidateMappedMemoryRanges 对于CPU可以访问的内存类型，可以使用vkMapMemory&#x2F;vkUnmapMemory函数对其进行映射。这一映射是持久化的，只要进行了正确的同步，可以在GPU使用这一内存区域时访问它。 vkMapMemory函数返回的指针可以被保存使用，只要进行了正确的同步，甚至可以在GPU使用这一内存区域时对其进行写入操作，同步规则可以保证CPU不会写入数据到GPU正在使用的那部分内存。 这里我们采用第一个方式实现，确保映射内存始终与分配内存的内容匹配。 刷新内存范围或使用一致的内存堆意味着驱动程序将知道我们对缓冲区的写入，但这并不意味着它们在GPU上实际上是可见的。将数据传输到GPU是一个在后台发生的操作，规范简单地告诉我们，它保证在下一次调用vkQueueSubmit时完成。 2.4 绑定顶点缓冲区现在我们有了顶点缓冲区，也分配了内存并填充了顶点数据，就剩下在渲染操作期间绑定顶点缓冲区。 通过扩展createCommandBuffers函数来实现: 12345678vkCmdBindPipeline(commandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, graphicsPipeline);VkBuffer vertexBuffers[] = &#123;vertexBuffer&#125;;VkDeviceSize offsets[] = &#123;0&#125;;vkCmdBindVertexBuffers(commandBuffers[i], 0, 1, vertexBuffers, offsets);vkCmdDraw(commandBuffers[i], static_cast&lt;uint32_t&gt;(vertices.size()), 1, 0, 0);vkCmdEndRenderPass(commandBuffers[i]); 将顶点缓冲区绑定到命令缓冲区，以便在后续绘制命令中使用，需要使用vkCmdBindVertexBuffers: 123456void vkCmdBindVertexBuffers( VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets); commandBuffer: 记录命令的命令缓冲区。 firstBinding: 第一个顶点输入绑定的索引，其状态由命令更新。 bindingCount: 状态由命令更新的顶点输入绑定数 pBuffers: 指向缓冲区句柄数组的指针。 pOffsets: 指向缓冲区偏移量数组的指针。 从pBuffers和poffset的元素i获取的值替换了顶点输入绑定firstBinding+i的当前状态，即[0，bindingCount]中的i。顶点输入绑定将更新为从缓冲区pBuffers[i]开始的由pOffsets[i]指示的偏移处开始。所有使用这些绑定的顶点输入属性都将在后续绘制命令的地址计算中使用这些更新的地址。 三. 根据鼠标移动变化颜色现在我们完成了从硬编码的顶点输入转为程序内的顶点数据输入， 更改vertices就可以看到颜色有变化，比如: 123456// 顶点数据const std::vector&lt;Vertex&gt; vertices = &#123; &#123;&#123;0.0f, -0.5f&#125;, &#123;1.0f, 1.0f, 1.0f&#125;&#125;, &#123;&#123;0.5f, 0.5f&#125;, &#123;1.0f, 1.0f, 0.0f&#125;&#125;, &#123;&#123;-0.5f, 0.5f&#125;, &#123;0.0f, 0.0f, 1.0f&#125;&#125;&#125;; 对应的图形就是: 现在我们动手做根据鼠标移动动态变化颜色: 1234567891011121314151617181920212223242526272829303132333435void initWindow() &#123; ... // 处理事件 initGlfwInput();&#125;void initGlfwInput() &#123; // 注册鼠标位置监听 glfwSetCursorPosCallback(window, cursor_position_callback);&#125;static void cursor_position_callback(GLFWwindow* window, double xpos, double ypos) &#123; auto app = reinterpret_cast&lt;HelloTriangleApplication*&gt;(glfwGetWindowUserPointer(window)); if (app-&gt;widthOfWindow != 0 &amp;&amp; app-&gt;heightOfWindow != 0) &#123; float xP = xpos/app-&gt;widthOfWindow; float yP = ypos/app-&gt;heightOfWindow; float x = xP * 2 - 1; float y = yP * 2 - 1; app-&gt;vertices = &#123; &#123;&#123;x, y&#125;, &#123;xP, xP, xP&#125;&#125;, &#123;&#123;0.5f, 0.5f&#125;, &#123;yP, yP, yP&#125;&#125;, &#123;&#123;-0.5f, 0.5f&#125;, &#123;0.0f, 0.0f, 1.0f&#125;&#125; &#125;; // 顶点数据变化后，重新拷贝至内存中 app-&gt;reMemcpyVertexBuffer(sizeof(app-&gt;vertices[0]) * app-&gt;vertices.size()); &#125;&#125;void reMemcpyVertexBuffer(VkDeviceSize size) &#123; void* data; vkMapMemory(device, vertexBufferMemory, 0, size, 0, &amp;data); memcpy(data, vertices.data(), (size_t) size); vkUnmapMemory(device, vertexBufferMemory);&#125; 最后的结果: 哈哈，有那么回事了，第一个顶点会跟随鼠标移动而移动，并且三角形也会变幻颜色, 不过这里只是简单的处理，甚至没有考虑同步问题。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(10)-重建交换链","slug":"Vulkan入门-10-重建交换链","date":"2022-02-26T19:34:10.000Z","updated":"2022-02-26T19:40:23.936Z","comments":true,"path":"2022/02/27/Vulkan入门-10-重建交换链/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-10-%E9%87%8D%E5%BB%BA%E4%BA%A4%E6%8D%A2%E9%93%BE/","excerpt":"简述在上一篇里，我们已经成功绘制了一个颜色渐变的三角形，并将其显示在窗口上了。但是窗口Surface可能会发生变化，从而使交换链不再与之兼容，比如是窗口大小的变化。所以我们必须捕获这些事件并重新创建交换链。","text":"简述在上一篇里，我们已经成功绘制了一个颜色渐变的三角形，并将其显示在窗口上了。但是窗口Surface可能会发生变化，从而使交换链不再与之兼容，比如是窗口大小的变化。所以我们必须捕获这些事件并重新创建交换链。 一. 重建交换链创建一个新的recreateSwapChain函数，该函数调用createSwapChain和所有依赖于交换链或窗口大小的对象的创建函数: 1234567891011121314151617void cleanupSwapChain() &#123;&#125;void recreateSwapChain() &#123; // 等待队列中所有操作完成 vkDeviceWaitIdle(device); // 先清理后创建 cleanupSwapChain(); createSwapChain(); createImageViews(); createRenderPass(); createGraphicsPipeline(); createFramebuffers(); createCommandBuffers();&#125; 首先调用vkDeviceWaitIdle，确保不触及可能仍在使用的资源。显然，我们必须做的第一件事是重新创建交换链本身。 需要重新创建图像视图，因为它们直接基于交换链图像。渲染通道需要重新创建，因为它取决于交换链图像的格式。交换链的图像格式很少在窗口调整等操作期间发生改变，但它仍然应该被处理。视口和剪刀矩形大小是在图形管道创建时指定的，因此管道也需要重新构建。可以通过使用动态状态的视图和剪刀矩形来避免这种情况。最后，帧缓冲区和命令缓冲区也直接依赖于交换链图像。 为了确保这些对象的旧版本在重新创建它们之前得到清理，我们应该将一些清理代码移到一个单独的函数中，我们可以从recreateSwapChain函数调用这个函数cleanupSwapChain。 1.1 cleanupSwapChain将所有和交换链相关的资源从cleanup函数中移到此函数内： 12345678910111213141516171819202122232425262728void cleanupSwapChain() &#123; // 释放所有的帧缓冲区 for (auto framebuffer : swapChainFramebuffers) &#123; vkDestroyFramebuffer(device, framebuffer, nullptr); &#125; // 释放指令缓冲区 // 可以从头重新创建命令池，但相当浪费。所以选择使用vkFreeCommandBuffers函数清理现有的命令缓冲区。 // 这样可以重用现有的池来分配新的命令缓冲区。 vkFreeCommandBuffers(device, commandPool, static_cast&lt;uint32_t&gt;(commandBuffers.size()), commandBuffers.data()); // 销毁图形管道 vkDestroyPipeline(device, graphicsPipeline, nullptr); // 释放管道布局 vkDestroyPipelineLayout(device, pipelineLayout, nullptr); // 释放渲染通道 vkDestroyRenderPass(device, renderPass, nullptr); // 释放交换链对应的图像视图 for (auto imageView : swapChainImageViews) &#123; vkDestroyImageView(device, imageView, nullptr); &#125; // 释放交换链 vkDestroySwapchainKHR(device, swapChain, nullptr);&#125;void cleanup() &#123; cleanupSwapChain(); ...&#125; 可以从头重新创建命令池，但相当浪费。所以选择使用vkFreeCommandBuffers函数清理现有的命令缓冲区, 这样可以重用现有的池来分配新的命令缓冲区。 1.2 获取窗口最新大小为了正确地处理窗口的大小，我们还需要查询framebuffer的当前大小，以确保交换链图像具有(新的)正确的大小。为了做到这一点，改变chooseSwapExtent函数来考虑实际的大小: 12345678910111213141516// 选择交换链分辨率VkExtent2D chooseSwapExtent(const VkSurfaceCapabilitiesKHR&amp; capabilities) &#123; if (capabilities.currentExtent.width != std::numeric_limits&lt;uint32_t&gt;::max()) &#123; return capabilities.currentExtent; &#125; else &#123; int width, height; glfwGetFramebufferSize(window, &amp;width, &amp;height); VkExtent2D actualExtent = &#123; static_cast&lt;uint32_t&gt;(width), static_cast&lt;uint32_t&gt;(height)&#125;; actualExtent.width = std::max(capabilities.minImageExtent.width, std::min(capabilities.maxImageExtent.width, actualExtent.width)); actualExtent.height = std::max(capabilities.minImageExtent.height, std::min(capabilities.maxImageExtent.height, actualExtent.height)); return actualExtent; &#125;&#125; 通过glfwGetFramebufferSize函数来获取当前窗口大小。 这就是重建交换链所需要的全部!然而，这种方法的缺点是:需要在创建新的交换链之前停止所有的呈现。当从旧的交换链在图像上绘制命令时，可以创建一个新的交换链。需要将之前的交换链传递给VkSwapchainCreateInfoKHR结构中的oldswarechain字段，并在使用完旧的交换链后立即销毁它。 1.3 次优或过时的交换链现在，我们只需要确定何时需要重新创建交换链，并调用新的recreateSwapChain函数。幸运的是，Vulkan通常会告诉我们交换链在显示过程中不再足够。vkAcquireNextImageKHR和vkQueuePresentKHR函数可以返回以下特殊值来表示这一点: VK_ERROR_OUT_OF_DATE_KHR: 交换链已经变得与表面不兼容，不能再用于渲染。通常发生在窗口大小调整之后。 VK_SUBOPTIMAL_KHR:交换链仍然可以成功地呈现到表面，但是表面的属性不再完全匹配。 12345678910VkResult result = vkAcquireNextImageKHR(device, swapChain, std::numeric_limits&lt;uint64_t&gt;::max(), imageAvailableSemaphores[currentFrame], VK_NULL_HANDLE, &amp;imageIndex);if (result == VK_ERROR_OUT_OF_DATE_KHR) &#123; recreateSwapChain(); // 已经获得了一个映像。VK_SUCCESS和VK_SUBOPTIMAL_KHR都被认为是“成功”返回码, 也可以去掉return return;&#125; else if (result != VK_SUCCESS &amp;&amp; result != VK_SUBOPTIMAL_KHR) &#123; throw std::runtime_error(&quot;failed to acquire swap chain image!&quot;);&#125; 如果交换链在试图获取映像时已经过期，那么就不可能再向其呈现。因此，应该立即重新创建交换链，并在下一个drawFrame调用中再次尝试。然而，如果在这中止绘图，那么栅栏将永远不会通过vkqueuessubmit提交，当我们稍后尝试等待它时，它将处于一个意想不到的状态。我们可以重建fence作为交换链重建的一部分，但是移动vkResetFences调用更容易: 12345vkResetFences(device, 1, &amp;inFlightFences[currentFrame]);// VkQueue是Vulkan中应用程序向GPU提交命令的唯一途径if (vkQueueSubmit(graphicsQueue, 1, &amp;submitInfo, inFlightFences[currentFrame]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to submit draw command buffer!&quot;);&#125; 把fence放在vkQueueSubmit之前，而不是在vkWaitForFences后立刻调用。这是什么原理呢？ 1.3.1 fencefence是一种同步原语，可用于将依赖项从队列插入到主机。fence有两种状态——有信号的和没有信号的, fence可以作为队列提交命令执行的一部分发出信号。 使用vkResetFences可以将fence置为unsignal状态。主机可以通过vkWaitForFences命令来等待fence，并且可以通过vkGetFenceStatus来查询当前的状态。 如果vkWaitForFences被调用时条件被满足，那么vkWaitForFences会立即返回。如果在vkWaitForFences被调用的时候条件没有被满足，那么vkWaitForFences将会阻塞并等待到超时纳秒，直到条件被满足。这里的条件就是fence状态是不是signal状态。vkQueueSubmit会将fence置为signal状态，那么vkWaitForFences就会通过。 所以，当vkWaitForFences之后立刻调用vkResetFences，那么当vkAcquireNextImageKHR发生异常导致返回时，下次在进入drawFrame调用vkWaitForFences就永远处于等待状态了。 1.3.2 vkQueuePresentKHR如果交换链不是最优的，也可以继续呈现，因为我们已经获得了一个映像。VK_SUCCESS和VK_SUBOPTIMAL_KHR都被认为是“成功”返回码。 123456result = vkQueuePresentKHR(presentQueue, &amp;presentInfo);if (result == VK_ERROR_OUT_OF_DATE_KHR || result == VK_SUBOPTIMAL_KHR) &#123; recreateSwapChain();&#125; else if (result != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to present swap chain image!&quot;);&#125; vkQueuePresentKHR函数返回具有相同含义的相同值。 在这种情况下，如果交换链不是次优的，为获得最好的结果，最好重新创建交换链。 1.4 主动处理窗口变化尽管许多驱动程序和平台在调整窗口大小后会自动触发VK_ERROR_OUT_OF_DATE_KHR，但不能保证一定会发生这种情况。所以最好通过监听窗口变化来主动重建交换链。 添加一个新的成员变量，该变量指示已调整大小： 12345678910bool framebufferResized = false;void drawFrame() &#123; ... result = vkQueuePresentKHR(presentQueue, &amp;presentInfo); if (result == VK_ERROR_OUT_OF_DATE_KHR || result == VK_SUBOPTIMAL_KHR || framebufferResized) &#123; framebufferResized = false; recreateSwapChain(); ...&#125; 1.4.1 监听窗口变化要实际检测窗口大小调整，可以使用GLFW框架中的glfwSetFramebufferSizeCallback函数来设置回调： 123456789101112131415void initWindow() &#123; glfwInit(); glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API); window = glfwCreateWindow(WIDTH, HEIGHT, &quot;Vulkan&quot;, nullptr, nullptr); glfwSetWindowUserPointer(window, this); glfwSetFramebufferSizeCallback(window, framebufferResizeCallback);&#125;static void framebufferResizeCallback(GLFWwindow* window, int width, int height) &#123; auto app = reinterpret_cast&lt;HelloTriangleApplication*&gt;(glfwGetWindowUserPointer(window)); app-&gt;framebufferResized = true;&#125; 因为glfw回调只能通过静态函数实现，所以通过glfwSetWindowUserPointer保存当前实例指针。 1.5 窗口最小化还有一种特殊状态是，当最小化窗口时，拿到的窗口大小是0, 这样创建出来的帧缓冲区大小也应该是0，根本不需要渲染。所以这里做一个简单的等待处理: 12345678910void recreateSwapChain() &#123; int width = 0, height = 0; while (width == 0 || height == 0) &#123; glfwGetFramebufferSize(window, &amp;width, &amp;height); glfwWaitEvents(); &#125; vkDeviceWaitIdle(device); ...&#125; 突然有点好奇这个绘制的刷新率，通过在drawFrame里嵌入函数computeRefreshRate来计算刷新率: 123456789101112131415161718void computeRefreshRate() &#123; static float fps = 0; static int64_t count = 0; static int64_t lastCount = 0; static auto lastTimestamp = std::chrono::high_resolution_clock::now(); static auto now = std::chrono::high_resolution_clock::now(); count++; now = std::chrono::high_resolution_clock::now(); float duration = std::chrono::duration_cast&lt;std::chrono::duration&lt;float&gt;&gt;(now-lastTimestamp).count(); if (duration &gt;= 1) &#123; lastTimestamp = now; fps = (count - lastCount)/duration; lastCount = count; std::cout&lt;&lt;&quot;computeRefreshRate: fps=&quot;&lt;&lt;fps&lt;&lt;&quot;, count=&quot;&lt;&lt;count&lt;&lt;std::endl; &#125;&#125; 算出来高达4k，看起来这个fence也并没有同步gpu显示，只是不停的提交。 那么如果我们想吧这个实时刷新率显示在我们程序的左上角，该怎么做呢?","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(9)-渲染和显示","slug":"Vulkan入门-9-渲染和显示","date":"2022-02-26T19:33:58.000Z","updated":"2022-02-26T19:39:31.582Z","comments":true,"path":"2022/02/27/Vulkan入门-9-渲染和显示/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-9-%E6%B8%B2%E6%9F%93%E5%92%8C%E6%98%BE%E7%A4%BA/","excerpt":"简述在这一章里，所有的事情都要集中起来。我们将编写drawFrame函数，该函数将在主循环中被调用，以将三角形置于屏幕上。创建函数并从mainLoop调用它. 123456789void mainLoop() &#123; while (!glfwWindowShouldClose(window)) &#123; glfwPollEvents(); drawFrame(); &#125;&#125;...void drawFrame() &#123;&#125;","text":"简述在这一章里，所有的事情都要集中起来。我们将编写drawFrame函数，该函数将在主循环中被调用，以将三角形置于屏幕上。创建函数并从mainLoop调用它. 123456789void mainLoop() &#123; while (!glfwWindowShouldClose(window)) &#123; glfwPollEvents(); drawFrame(); &#125;&#125;...void drawFrame() &#123;&#125; 一. 同步drawFrame函数将执行以下操作: 从交换链获取一个映像 在framebuffer中以该图像作为附件执行命令缓冲 将图像返回到交换链以便显示 这些事件都是使用单个函数调用设置的，但它们是异步执行的。函数调用将在操作实际完成之前返回，并且执行的顺序也未定义。因为每个操作都依赖于前一个完成，所以需要同步机制。 有两种同步交换链事件的方法:栅栏和信号量。 它们都是可以用于协调操作的对象，方法是让一个操作信号和另一个操作等待栅栏或信号量从无信号状态变为有信号状态。 不同的是，你可以通过vkWaitForFences来访问fences的状态，而信号量却不能。 fence主要用于通过呈现操作同步应用程序本身，而信号量用于在命令队列内或跨命令队列同步操作。我们想要同步draw命令和表示的队列操作，这使得信号量最适合。 1.1 信号量同步信号量是一种同步原语，可以用来在提交给队列的批之间插入依赖关系。信号量有两种状态——有信号的和无信号的。一个信号量的状态可以在一批命令执行完成后发出信号。批处理可以在开始执行前等待信号量变成有信号的，也可以在批处理开始执行前等待信号量变成无信号的。 与Vulkan中的大多数对象一样，信号量是内部数据的接口，通常对应用程序是不透明的。这个内部数据被称为信号量的有效负载。但是，为了能够与当前设备之外的代理进行通信，必须能够将有效负载导出为一种普遍理解的格式，然后再从该格式导入。信号量的内部数据可以包括对任何资源的引用，以及与在该信号量对象上执行的信号或非信号操作相关的待定工作。 下面提供了向信号量导入和导出内部数据的机制。这些机制间接地使应用程序能够跨进程和API边界在两个或多个信号量和其他同步原语之间共享信号量状态。 信号量由VkSemaphore句柄表示:VK_DEFINE_NON_DISPATCHABLE_HANDLE(VkSemaphore) 12345VkResult vkCreateSemaphore( VkDevice device, const VkSemaphoreCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSemaphore* pSemaphore); device: 创建信号量的逻辑设备 pCreateInfo: 指向VkSemaphoreCreateInfo结构体实例的指针，该结构体包含了如何创建信号量的信息 pAllocator: 控制内存分配 pSemaphore: 指向返回结果信号量对象的句柄。 创建时，信号量处于无信号状态。 12345typedef struct VkSemaphoreCreateInfo &#123; VkStructureType sType; const void* pNext; VkSemaphoreCreateFlags flags;&#125; VkSemaphoreCreateInfo; sType: 此结构的类型，VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO pNext: 为空或指向特定于扩展的结构的指针 flags: 当前API下无可用flag, 未来版本的Vulkan API或扩展可能会像对其他结构一样为flag和pNext参数添加功能 1.2 创建信号量 vkCreateSemaphore需要一个信号量来表示图像已经获得并准备好呈现，还需要另一个信号量来表示渲染已经完成并可以进行呈现。创建两个类成员来存储这些信号量对象: 12VkSemaphore imageAvailableSemaphore;VkSemaphore renderFinishedSemaphore; 创建信号量需要填写VkSemaphoreCreateInfo，但是在当前版本的API中，除了sType之外实际上没有任何必需的字段: 1234567891011121314void initVulkan() &#123; ... createSemaphores();&#125;void createSemaphores() &#123; VkSemaphoreCreateInfo semaphoreInfo = &#123;&#125;; semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO; if (vkCreateSemaphore(device, &amp;semaphoreInfo, nullptr, &amp;imageAvailableSemaphore) != VK_SUCCESS || vkCreateSemaphore(device, &amp;semaphoreInfo, nullptr, &amp;renderFinishedSemaphore) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create semaphores!&quot;); &#125;&#125; 同理，信号量应该在程序结束时清除，当所有的命令都已经完成，不再需要更多的同步: 12345void cleanup() &#123; vkDestroySemaphore(device, renderFinishedSemaphore, nullptr); vkDestroySemaphore(device, imageAvailableSemaphore, nullptr); ...&#125; 二. 从交换链获取图像如前所述，在drawFrame函数中需要做的第一件事是从交换链中获取图像。回想一下，交换链是一个扩展特性，所以我们必须使用一个具有vk*KHR命名约定的函数: 123456void drawFrame() &#123; uint32_t imageIndex; vkAcquireNextImageKHR(device, swapChain, std::numeric_limits&lt;uint64_t&gt;::max(), imageAvailableSemaphore, VK_NULL_HANDLE, &amp;imageIndex);&#125; 获取一个可用的可呈现图像使用，并检索该图像的索引，调用: vkAcquireNextImageKHR: 1234567VkResult vkAcquireNextImageKHR( VkDevice device, VkSwapchainKHR swapchain, uint64_t timeout, VkSemaphore semaphore, VkFence fence, uint32_t* pImageIndex); device: 提供逻辑设备句柄 swapChain: 交换链对象的句柄, 从这个交换链中获取图像 timeout: 指定如果没有可用的映像，函数将等待多长时间(以纳秒为单位)。 semaphore: 是VK_NULL_HANDLE或者一个信号量 fence: VK_NULL_HANDLE或fence to signal。 pImageIndex: 一个指向uint32_t的指针, 用于输出可用的交换链映像的索引, 索引指的是swapChainImages数组中的VkImage。我们将使用这个索引来选择正确的命令缓冲区。 当成功时，vkAcquireNextImageKHR从swapchain获得一个应用程序可以使用的图像，并将pImageIndex设置为该图像在swapchain中的索引。表示引擎在获取图像时可能还没有完成对图像的读取，因此应用程序必须使用信号量和&#x2F;或栅栏来确保图像布局和内容在表示引擎读取完成之前不会被修改。如果semaphore不是VK_NULL_HANDLE，应用程序可能会认为，一旦vkAcquireNextImageKHR返回，semaphore引用的信号量信号操作已经提交执行。图像获取的顺序取决于实现，并且可能与图像呈现的顺序不同。 如果timeout为0，则vkAcquireNextImageKHR不会等待，并且会成功获取镜像，或者失败并返回VK_NOT_READY，如果没有可用的镜像。如果指定的超时时间在获取镜像之前过期，vkAcquireNextImageKHR将返回VK_TIMEOUT。如果timeout是UINT64_MAX，超时时间被认为是无限的，vkAcquireNextImageKHR将阻塞直到一个图像被获取或一个错误发生。 如果应用程序当前获取的(但尚未呈现的)图像数量小于或等于swapchain中的图像数量与vksurfacecabiltieskhr::minImageCount值之间的差值，则最终会获得一个图像。如果当前获取的图像数量大于此值，则不应该调用vkAcquireNextImageKHR;如果是，timeout不能是UINT64_MAX。 如果一个图像成功获得，vkAcquireNextImageKHR必须要么返回VK_SUCCESS，要么返回VK_SUBOPTIMAL_KHR，如果交换链不再完全匹配表面属性，但仍然可以用于表示。 三. 提交指令缓冲区队列提交和同步是通过VkSubmitInfo结构中的参数配置的。 1234567891011typedef struct VkSubmitInfo &#123; VkStructureType sType; const void* pNext; uint32_t waitSemaphoreCount; const VkSemaphore* pWaitSemaphores; const VkPipelineStageFlags* pWaitDstStageMask; uint32_t commandBufferCount; const VkCommandBuffer* pCommandBuffers; uint32_t signalSemaphoreCount; const VkSemaphore* pSignalSemaphores;&#125; VkSubmitInfo; sType: 此结构的类型，VK_STRUCTURE_TYPE_SUBMIT_INFO pNext: 为空或指向特定于扩展的结构的指针 waitSemaphoreCount: 执行批处理的命令缓冲区之前需要等待的信号量的数量 pWaitSemaphores: 指向VkSemaphore句柄数组的指针，在这个批处理的命令缓冲区开始执行之前，要等待该句柄。如果提供了等待的信号量，则定义一个信号量等待操作。 pWaitDstStageMask: 指向每个对应的信号量等待将发生的管道阶段数组的指针 commandBufferCount: 批处理中要执行的命令缓冲区的数量 pCommandBuffers: 指向要在批处理中执行的VkCommandBuffer句柄数组的指针 signalSemaphoreCount: 在pCommandBuffers中指定的命令完成执行后要发出信号的信号量的数量 pSignalSemaphores: 指向VkSemaphore句柄数组的指针，当这个批处理的命令缓冲区完成执行时，VkSemaphore句柄数组将发出信号。如果提供了要发送信号的信号量，它们定义了一个信号量信号操作。 命令缓冲区在pCommandBuffers中出现的顺序用于确定提交顺序，因此所有的隐式排序都保证遵守它。除了这些隐式排序保证和任何显式同步原语之外，这些命令缓冲区可能会重叠或以其他方式乱序执行。 12345678910111213141516171819202122232425// 前三个参数指定在执行开始之前等待哪些信号量，以及在管道的哪个阶段等待。VkSubmitInfo submitInfo = &#123;&#125;;submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;VkSemaphore waitSemaphores[] = &#123;imageAvailableSemaphore&#125;;// 我们希望等待向图像写入颜色，直到它可用为止，因此我们指定了向颜色附件写入的图形管道阶段。VkPipelineStageFlags waitStages[] = &#123;VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT&#125;;submitInfo.waitSemaphoreCount = 1;submitInfo.pWaitSemaphores = waitSemaphores;// 理论上已经可以开始执行顶点着色器，而还没有可用图像。// waitStages数组中的每一项都对应于在pwaitsemaphres中具有相同索引的信号量。submitInfo.pWaitDstStageMask = waitStages;// 指定实际提交哪些命令缓冲区以执行submitInfo.commandBufferCount = 1;submitInfo.pCommandBuffers = &amp;commandBuffers[imageIndex];// 指定在命令缓冲区完成执行后要发送哪些信号量VkSemaphore signalSemaphores[] = &#123;renderFinishedSemaphore&#125;;submitInfo.signalSemaphoreCount = 1;submitInfo.pSignalSemaphores = signalSemaphores;// 使用vkqueuessubmit将命令缓冲区提交到图形队列if (vkQueueSubmit(graphicsQueue, 1, &amp;submitInfo, VK_NULL_HANDLE) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to submit draw command buffer!&quot;);&#125; 使用vkqueuessubmit将命令缓冲区提交到图形队列。当工作负载更大时，该函数接受一个VkSubmitInfo结构数组作为效率参数。最后一个参数引用一个可选的fence，该fence将在命令缓冲区完成执行时发出信号。我们使用信号量进行同步，所以我们将传递一个VK_NULL_HANDLE。 12345VkResult vkQueueSubmit( VkQueue queue, uint32_t submitCount, const VkSubmitInfo* pSubmits, VkFence fence); queue: 命令缓冲将被提交到的队列 submitCount: 提交数组pSubmits中的元素数量 pSubmits: 指向VkSubmitInfo结构数组的指针，每个结构都指定了一个命令缓冲区提交批处理 fence: 可选的fence句柄，一旦所有提交的命令缓冲区完成执行，就会发出信号。如果fence不是VK_NULL_HANDLE，则定义一个fence信号操作 提交可能是一个高开销的操作，应用程序应该尽可能少的调用vkqueuessubmit来批量处理。 四. Subpass依赖渲染通道中的子通道会自动处理图像布局的转换。这些转换由子传递依赖项控制，子传递依赖项指定子传递之间的内存和执行依赖项。 我们现在只有一个Subpass，但是在这个Subpass之前和之后的操作也被算作隐式的“Subpasses”。 有两个内置的依赖关系负责渲染通道开始和结束的转换，但前者没有在正确的时间发生。它假设转换发生在管道的开始，但是我们在那一点还没有获得图像! 有两种方法来处理这个问题： 将imageAvailableSemaphore的等待阶段更改为VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT，以确保渲染通道直到图像可用时才开始 让渲染通道等待VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT阶段。 在这里使用第二种方法，因为这是一个很好的方式来了解子传递依赖项及其工作方式。Subpass依赖在VkSubpassDependency结构中指定。 在createRenderPass函数中添加一个: 123456789101112131415VkSubpassDependency dependency = &#123;&#125;;// 指定依赖项dependency.srcSubpass = VK_SUBPASS_EXTERNAL;// 从属子传递的索引dependency.dstSubpass = 0;// 指定要等待的操作以及这些操作发生的阶段// 需要等待交换链完成对图像的读取后才能访问它。这可以通过等待颜色附件输出阶段本身来完成。dependency.dstStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;dependency.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_READ_BIT | VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;// 在这一阶段应该等待的操作是在颜色连接阶段，包括阅读和书写颜色连接。// 这些设置将防止转换发生，直到它是真正必要的(和允许的):当我们想要开始写入颜色。renderPassInfo.dependencyCount = 1;renderPassInfo.pDependencies = &amp;dependency; 特殊值VK_SUBPASS_EXTERNAL指的是在渲染传递之前或之后的隐式子传递，这取决于它是在srcSubpass还是dstSubpass中指定的。索引0指向我们的子通道，它是第一个也是唯一一个。dstSubpass必须始终高于srcSubpass，以防止依赖关系图中的循环。 五. 显示绘制框架的最后一步是将结果提交回交换链，使其最终显示在屏幕上。 在应用程序可以呈现一个图像之前，图像的布局必须转换为VK_IMAGE_LAYOUT_PRESENT_SRC_KHR布局，或者对于一个共享的可呈现图像，必须转换为VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR布局。 5.1 VkPresentInfoKHR12345678910typedef struct VkPresentInfoKHR &#123; VkStructureType sType; const void* pNext; uint32_t waitSemaphoreCount; const VkSemaphore* pWaitSemaphores; uint32_t swapchainCount; const VkSwapchainKHR* pSwapchains; const uint32_t* pImageIndices; VkResult* pResults;&#125; VkPresentInfoKHR; sType: 此结构的类型，VK_STRUCTURE_TYPE_PRESENT_INFO_KHR pNext: 为空或指向特定于扩展的结构的指针 waitsemaphore: 在发出当前请求之前等待的信号量的数量, 可能是零。 pwaitsemaphres: 空的或指向带有waitsemaphore条目的VkSemaphore对象数组的指针，它指定了在发出当前请求之前需要等待的信号量。 swapchainCount: 指令提供给交换链的数量 pSwapchains: 指向带有swapchainCount条目的VkSwapchainKHR对象数组的指针。给定的交换链不能在此列表中出现多次。 pImageIndices: 指向每个swapchain的可呈现图像数组的索引数组的指针，其中包含swapchainCount条目。这个数组中的每个条目都标识要在pSwapchains数组中的相应条目上显示的图像。 results: 指向带有swapchainCount条目的VkResult类型元素数组的指针。不需要每个swapchain结果的应用程序可以对结果使用NULL。如果非null，则results中的每个条目都将被设置为VkResult，以表示与pSwapchains中的相同索引相对应的交换链。 5.2 显示设置通过drawFrame函数末尾的VkPresentInfoKHR结构来配置显示相关设置: 123456789101112131415161718VkPresentInfoKHR presentInfo = &#123;&#125;;presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR;// 指定在表示发生之前等待哪些信号量，就像VkSubmitInfo一样presentInfo.waitSemaphoreCount = 1;presentInfo.pWaitSemaphores = signalSemaphores;// 指定要向其显示图像的交换链，以及每个交换链的图像索引。VkSwapchainKHR swapChains[] = &#123;swapChain&#125;;presentInfo.swapchainCount = 1;presentInfo.pSwapchains = swapChains;presentInfo.pImageIndices = &amp;imageIndex;// 指定一个VkResult值数组，以便在表示成功时检查每个交换链。// 只使用单个交换链，就不需要，因为可以简单地使用当前函数的返回值。presentInfo.pResults = nullptr; // Optional// vkQueuePresentKHR函数提交请求，以向交换链请求一个图像vkQueuePresentKHR(presentQueue, &amp;presentInfo); 现在编译运行一下我们的程序: ohhhh!!!!整整一千多行的代码，终于不是黑糊糊的窗口了。 当启用验证层时，程序在关闭时就会崩溃。从debugCallback打印到终端的消息告诉我们为什么: 记住，drawFrame中的所有操作都是异步的。这意味着当我们退出mainLoop中的循环时，绘图和表示操作可能仍然在进行。当这种情况发生时，清理资源就可能带来异常。 要解决这个问题，我们应该等待逻辑设备完成操作，然后退出mainLoop并销毁窗口: 1234567void mainLoop() &#123; while (!glfwWindowShouldClose(window)) &#123; glfwPollEvents(); drawFrame(); &#125;&#125;vkDeviceWaitIdle(device); 5.2.1 vkQueuePresentKHR在将所有渲染命令排队并将图像转换到正确的布局后，要将图像排队显示，调用: 123VkResult vkQueuePresentKHR( VkQueue queue, const VkPresentInfoKHR* pPresentInfo); queue是一个能够在与图像交换链相同的设备上显示到目标表面平台的队列。 pPresentInfo是一个指向VkPresentInfoKHR结构体的指针，该结构体指定了表示的参数。 应用程序不需要按照获取图像的顺序来呈现图像——应用程序可以任意地呈现当前获取的任何图像。 六. Frames in flight如果在启用了验证层的情况下运行应用程序，并且监视应用程序的内存使用情况，则可能会注意到它正在缓慢增长。 原因是应用程序正在使用drawFrame函数快速提交工作，但实际上并没有检查是否有任何工作完成。如果CPU提交工作的速度快于GPU不能跟上的工作，那么队列将缓慢地填满工作。 更糟糕的是，我们同时对多个帧重用了imageAvailableSemaphore和renderFinishedSemaphore。 解决此问题的简单方法是提交后等待工作完成，例如使用vkQueueWaitIdle： 12345void drawFrame() &#123; ... vkQueuePresentKHR(presentQueue, &amp;presentInfo); vkQueueWaitIdle(presentQueue);&#125; 但是，我们可能无法以这种方式最佳地使用GPU，因为整个图形流水线现在一次只能使用一帧。 当前帧已经经过的阶段是空闲的，可能已经用于下一帧。 现在，我们将扩展我们的应用程序，以允许在运行多个frame的同时仍限制堆积的工作量。 首先在程序顶部添加一个常量，该常量定义应同时处理多少帧, 以及每个frame应具有自己的一组信号： 123456789101112131415161718192021222324252627const int MAX_FRAMES_IN_FLIGHT = 2;std::vector&lt;VkSemaphore&gt; imageAvailableSemaphores;std::vector&lt;VkSemaphore&gt; renderFinishedSemaphores;void createSemaphores() &#123; imageAvailableSemaphores.resize(MAX_FRAMES_IN_FLIGHT); renderFinishedSemaphores.resize(MAX_FRAMES_IN_FLIGHT); VkSemaphoreCreateInfo semaphoreInfo = &#123;&#125;; semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO; for (size_t i = 0; i &lt; MAX_FRAMES_IN_FLIGHT; i++) &#123; if (vkCreateSemaphore(device, &amp;semaphoreInfo, nullptr, &amp;imageAvailableSemaphores[i]) != VK_SUCCESS || vkCreateSemaphore(device, &amp;semaphoreInfo, nullptr, &amp;renderFinishedSemaphores[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create semaphores for a frame!&quot;); &#125; &#125;&#125;void cleanup() &#123; for (size_t i = 0; i &lt; MAX_FRAMES_IN_FLIGHT; i++) &#123; vkDestroySemaphore(device, renderFinishedSemaphores[i], nullptr); vkDestroySemaphore(device, imageAvailableSemaphores[i], nullptr); &#125; ...&#125; 同理，drawFrame也需要修改: 123456789void drawFrame() &#123; vkAcquireNextImageKHR(device, swapChain, std::numeric_limits&lt;uint64_t&gt;::max(), imageAvailableSemaphores[currentFrame], VK_NULL_HANDLE, &amp;imageIndex); ... VkSemaphore waitSemaphores[] = &#123;imageAvailableSemaphores[currentFrame]&#125;; ... VkSemaphore signalSemaphores[] = &#123;renderFinishedSemaphores[currentFrame]&#125;; ...&#125; 这里的currentFrame可以通过取模来获取: currentFrame &#x3D; (currentFrame + 1)%MAX_FRAMES_IN_FLIGHT 通过使用模（％）运算符，我们确保帧索引在每个MAX_FRAMES_IN_FLIGHT排队的帧之后循环。 6.1 fence机制尽管我们现在已经设置了必需的对象以方便同时处理多个帧，但实际上并没有阻止提交超过MAX_FRAMES_IN_FLIGHT个对象。 现在只有GPU-GPU同步，没有CPU-GPU同步来跟踪工作的进行情况。 我们可能正在使用第0帧对象，而第0帧仍在显示中！ 为了执行CPU-GPU同步，Vulkan提供了第二种类型的同步原语，称为fences。 在可以发信号并等待信号的意义上，fence与信号相似，但是这次我们实际上在自己的代码中等待信号。 我们首先为每个框架创建一个fence： 1234std::vector&lt;VkSemaphore&gt; imageAvailableSemaphores;std::vector&lt;VkSemaphore&gt; renderFinishedSemaphores;std::vector&lt;VkFence&gt; inFlightFences;size_t currentFrame = 0; 因为fence也是同步机制，所以最好把同步对象的创建放在一起，吧createSemaphores改名成createSyncObjects: 123456789101112131415161718void createSyncObjects() &#123; imageAvailableSemaphores.resize(MAX_FRAMES_IN_FLIGHT); renderFinishedSemaphores.resize(MAX_FRAMES_IN_FLIGHT); inFlightFences.resize(MAX_FRAMES_IN_FLIGHT); VkSemaphoreCreateInfo semaphoreInfo = &#123;&#125;; semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO; VkFenceCreateInfo fenceInfo = &#123;&#125;; fenceInfo.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO; for (size_t i = 0; i &lt; MAX_FRAMES_IN_FLIGHT; i++) &#123; if (vkCreateSemaphore(device, &amp;semaphoreInfo, nullptr, &amp;imageAvailableSemaphores[i]) != VK_SUCCESS || vkCreateSemaphore(device, &amp;semaphoreInfo, nullptr, &amp;renderFinishedSemaphores[i]) != VK_SUCCESS || vkCreateFence(device, &amp;fenceInfo, nullptr, &amp;inFlightFences[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create synchronization objects for a frame!&quot;); &#125; &#125;&#125; 也要记得销毁fence. 123456789void cleanup() &#123; // 释放信号量和fence for (size_t i = 0; i &lt; MAX_FRAMES_IN_FLIGHT; i ++) &#123; vkDestroySemaphore(device, renderFinishedSemaphores[i], nullptr); vkDestroySemaphore(device, imageAvailableSemaphores[i], nullptr); vkDestroyFence(device, inFlightFences[i], nullptr); &#125;&#125; 现在使用fence进行同步。vkqueuessubmit调用包含一个可选参数，用于传递一个fence，当命令缓冲区执行完毕时，该fence应该被通知。我们可以用它来表示一个帧已经完成。 1234567891011void drawFrame() &#123; // 等待当前帧fence完成 vkWaitForFences(device, 1, &amp;inFlightFences[currentFrame], VK_TRUE, std::numeric_limits&lt;uint64_t&gt;::max()); vkResetFences(device, 1, &amp;inFlightFences[currentFrame]); ... // VkQueue是Vulkan中应用程序向GPU提交命令的唯一途径 if (vkQueueSubmit(graphicsQueue, 1, &amp;submitInfo, inFlightFences[currentFrame]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to submit draw command buffer!&quot;); &#125; ...&#125; vkWaitForFences函数接受一个fences数组，在返回之前等待其中任何一个或者所有的栅栏被通知。我们在这里传递的VK_TRUE表示我们希望等待所有的fence，但在单个fence的情况下，这显然无关紧要。就像vkAcquireNextImageKHR一样，这个函数也是需要一个超时。 与信号量不同，我们需要通过vkResetFences调用来手动将栅栏恢复到无信号状态。如果你现在运行这个程序，你会注意到一些奇怪的东西。应用程序似乎不再呈现任何东西。这是因为在等一个还没被提交的fence! 这里的问题是，在默认情况下，fence是在无信号状态下创建的。这意味着如果我们以前没有用过fence，vkWaitForFences将会永远等下去。为了解决这个问题，我们可以改变fence的创建，在有信号的状态下初始化它，就像我们已经完成了初始帧的渲染一样: 123VkFenceCreateInfo fenceInfo = &#123;&#125;;fenceInfo.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;fenceInfo.flags = VK_FENCE_CREATE_SIGNALED_BIT; // 初始化fence 程序现在应该可以正常工作了，内存泄漏也消失了! 我们已经实现了所有需要的同步，以确保排队的工作不超过两个帧。请注意，代码的其他部分，如最终的清理，可以依赖于更粗糙的同步，如vkDeviceWaitIdle，应该根据性能需求决定使用哪种方法。 Vulkan管道的框图 七. 总结现在我们已经写了一千多行的代码，总算把Vulkan的这一套简单的过了一遍。在继续后续学习之前，有必要先总结一下，巩固基础。 首先Vulkan是什么：Vulkan是一个低开销、跨平台的二维、三维图形与计算的应用程序接口（API）。本身是一个与平台无关的API，所以不包括用于创建显示渲染结果的窗口的工具。所以借助 GLFW （当然也可以是其他库如SDL）创建窗口。 下面是一个Vuklan应用一般流程的简述: 借助GLFW库，创建显示窗口。 创建Vulkan实例VkInstance 使用VkApplicationInfo和VkInstanceCreateInfo声明相关配置 调用 vkCreateInstance, 创建 vulkan 实例 如果是开发调试，可以启用验证层 实现调试回调函数 通过VkDebugUtilsMessengerCreateInfoEXT.pfnUserCallback绑定消息回调函数 通过CreateDebugUtilsMessengerEXT函数实例化DebugUtilsMessengerEXT 注意在不需要的时候显示销毁回调实例 PFN_vkDestroyDebugUtilsMessengerEXT 检索合适的物理设备 通过vkEnumeratePhysicalDevices获取本机物理显卡，并根据需要选择合适GPU 通过vkGetPhysicalDeviceProperties检查显卡的基本功能 查询vkGetPhysicalDeviceFeatures中可以被支持的feature 挑选需要的队列族 通过vkGetPhysicalDeviceQueueFamilyProperties获取物理显卡支持的队列，并挑选需要的队列 创建逻辑设备 VkDevice 首先将4.2.1中挑选的队列记录在VkDeviceQueueCreateInfo中，指定要创建的队列VkDeviceCreateInfo.pQueueCreateInfos 指定使用的设备功能(feature)，比如几何着色器等 通过vkCreateDevice函数创建逻辑设备，注意在不需要的时候显示销毁逻辑设备(vkDestroyDevice) 队列是与逻辑设备一起自动创建的，直接通过vkGetDeviceQueue获取该逻辑设备上指定的队列即可（当逻辑设备被销毁时，会隐式清除设备队列） 创建Surface 启用VK_KHR_surface扩展，通过glfw的glfwCreateWindowSurface创建VkSurfaceKHR 创建交换链，即渲染缓冲区, 本质上是一个等待呈现给屏幕的图像队列 检查GPU是否支持交换链，VK_KHR_SWAPCHAIN_EXTENSION_NAME 使能设备VK_KHR_swapchain扩展 获取关于swap chain更多支持细节 基本Surface功能（交换链中的最小&#x2F;最大图像数，图像的最小&#x2F;最大宽度和高度） Surface的格式（像素格式，色彩空间） 可用的呈现模式 为交换链选择合适的设置，如Surface格式（颜色深度）、呈现模式（将图像“交换”到屏幕的条件）、交换范围（交换链中图像的分辨率）等 创建swap chain对象 VkSwapchainKHR 绑定窗口Surface 设置最小图像数量 minImageCount 选择合适的图像格式 imageFormat 选择合适的图像颜色空间 imageColorSpace 选择合适的图像分辨率 imageExtent 设置图像图层 imageArrayLayers 设置图像操作方式 imageUsage 选择图像呈现模式 presentMode 是否需要裁剪功能 clipped(VK_TRUE, VK_FALSE) 设置旧交换链的引用 oldSwapchain 获取交换链图像(VkImage)对象集合 创建渲染过程，Render Passes 通过vkCreateRenderPass创建，在不需要时通过vkDestroyRenderPass销毁 创建图形管道, 在Vulkan中，必须明确所有内容，从视口大小到颜色混合功能。有如下几个固定操作： 输入汇编程序(input assembler): 从指定的缓冲区收集原始顶点数据，也可以使用索引缓冲区重复某些元素，而不必复制顶点数据本身。 顶点着色器(vertex shader): 针对每个顶点运行，并且通常应用变换以将顶点位置从模型空间转换到屏幕空间。它还沿着管道传递每顶点数据。 曲面细分着色器(tessellation shaders): 根据特定规则细分几何体以提高网格质量。通常用于使砖墙和楼梯等表面在附近时看起来不那么平坦。 几何着色器(geometry shader): 在每个基元(三角形，直线，点)上运行，并且可以丢弃它或输出比原来更多的基元。类似于曲面细分着色器，但更灵活。但没有得到太多应用，因为大多数显卡的性能都不是很好。 光栅化阶段(rasterization stage): 将基元离散化为片段。这些是它们填充在帧缓冲区上的像素元素。在屏幕之外的片段都将被丢弃，顶点着色器输出的属性将在片段之间进行插值。由于深度测试，通常在这里也丢弃其他原始片段后面的片段。 片段着色器(fragment shader): 为存活的每个片段调用片段着色器，并确定片段写入哪些帧缓冲区以及使用哪些颜色和深度值。它可以使用来自顶点着色器的插值数据来完成此操作，其中可以包括纹理坐标和法线照明等内容。 颜色混合阶段(color blending stage): 应用操作来混合映射到帧缓冲区中的相同像素的不同片段。 fragment可以简单地相互覆盖，加起来或根据透明度进行混合。 输入汇编程序、光栅化和颜色混合阶段阶段被称为固定功能阶段。这些阶段允许使用参数调整其操作，但它们的工作方式是预定义的。 顶点着色器、曲面细分着色器、几何着色器和片段着色器阶段是可编程的，这意味着可以将代码上传到图形卡，以完全应用想要的操作。 例如，实现从纹理和光照到光线跟踪器的任何内容。这些程序同时在许多GPU内核上运行，以并行处理许多对象，如顶点和片段。，可以使用片段着色器 通过vkCreateGraphicsPipelines创建图形管道，指明渲染过程 创建帧缓冲区 调整帧缓冲区容器的大小以容纳所有交换链图像视图 指定帧缓冲区需要与哪个renderPass兼容。只能对与之兼容的渲染过程使用帧缓冲区，这意味着它们使用相同数量和类型的附件。 attachmentCount和pAttachments参数指定应绑定到渲染过程pAttachment数组中相应附件描述的VkImageView对象。 帧缓冲区宽度和高度参数是交换链中获取的宽高 帧缓冲区的layers是指图像数组中的层数 在不需要时，通过vkDestroyFramebuffer销毁帧缓冲区 创建指令缓冲区，Vulkan必须在指令缓冲区对象中记录想要执行的所有操作 先创建创建指令缓冲池，Command pool 创建指令缓冲区，大小和帧缓冲一致 渲染和显示 从交换链获取一个映像 在framebuffer中以该图像作为附件执行命令缓冲，提交指令缓冲区 将图像返回到交换链以便显示 渲染显示的过程需要同步 好的，现在我们又加深了一遍印象，这其中诸多细节我们后续挖掘。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(8)-帧缓冲区和指令缓冲区","slug":"Vulkan入门-8-帧缓冲区和指令缓冲区","date":"2022-02-26T19:33:45.000Z","updated":"2022-02-26T19:39:14.149Z","comments":true,"path":"2022/02/27/Vulkan入门-8-帧缓冲区和指令缓冲区/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-8-%E5%B8%A7%E7%BC%93%E5%86%B2%E5%8C%BA%E5%92%8C%E6%8C%87%E4%BB%A4%E7%BC%93%E5%86%B2%E5%8C%BA/","excerpt":"简述Framebuffers, 帧缓冲区。之前我们在学习’Swap Chain-交换链’时提到Vulkan没有“默认帧缓冲区”的概念，取而代之的是名为 “swap chain” 即交换链，也就是渲染的缓冲区，必须在Vulkan中明确创建。 现在我们已经设置了渲染过程，以期望使用与交换链图像相同格式的单个帧缓冲区，但实际上我们还没有创建任何帧缓冲区。 通过将渲染过程创建期间指定的附件包装到VkFramebuffer对象中来绑定附件。 帧缓冲区对象引用表示附件的所有VkImageView对象。在我们的情况下，这将只是一个单一的：颜色附件。但是，我们必须用于附件的图像取决于在检索用于表示的图像时交换链返回的图像。这意味着我们必须为交换链中的所有图像创建一个帧缓冲区，并使用与绘制时检索到的图像相对应的帧缓冲区。","text":"简述Framebuffers, 帧缓冲区。之前我们在学习’Swap Chain-交换链’时提到Vulkan没有“默认帧缓冲区”的概念，取而代之的是名为 “swap chain” 即交换链，也就是渲染的缓冲区，必须在Vulkan中明确创建。 现在我们已经设置了渲染过程，以期望使用与交换链图像相同格式的单个帧缓冲区，但实际上我们还没有创建任何帧缓冲区。 通过将渲染过程创建期间指定的附件包装到VkFramebuffer对象中来绑定附件。 帧缓冲区对象引用表示附件的所有VkImageView对象。在我们的情况下，这将只是一个单一的：颜色附件。但是，我们必须用于附件的图像取决于在检索用于表示的图像时交换链返回的图像。这意味着我们必须为交换链中的所有图像创建一个帧缓冲区，并使用与绘制时检索到的图像相对应的帧缓冲区。 一. VkFramebuffer 创建帧缓冲区帧缓冲区由VkFramebuffer句柄表示： VK_DEFINE_NON_DISPATCHABLE_HANDLE(VkFramebuffer) 通过调用vkCreateFramebuffer来创建： 12345VkResult vkCreateFramebuffer( VkDevice device, const VkFramebufferCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkFramebuffer* pFramebuffer); device: 创建帧缓冲区的逻辑设备 pCreateInfo: 指向VkFramebufferCreateInfo结构，该结构描述有关帧缓冲区创建的附加信息。 pAllocator: 控制主机内存分配 pFramebuffer: 指向返回结果帧缓冲区对象的VkFramebuffer句柄。 我们创建一个VkFramebuffer的集合来保存所有帧缓冲: 1std::vector&lt;VkFramebuffer&gt; swapChainFramebuffers; 在一个新函数createFramebuffers中为该数组创建对象，该函数在创建图形管道之后立即从initVulkan调用： 123456789101112void initVulkan() &#123; createInstance(); setupDebugCallback(); createSurface(); pickPhysicalDevice(); createLogicalDevice(); createSwapChain(); createImageViews(); createRenderPass(); createGraphicsPipeline(); createFramebuffers();&#125; 在createFramebuffers最开始，调整帧缓冲区容器的大小以容纳所有交换链图像视图, 然后遍历图像视图并从它们创建帧缓冲区： 123456789101112131415161718192021void createFramebuffers() &#123; swapChainFramebuffers.resize(swapChainImageViews.size()); for (size_t i = 0; i &lt; swapChainImageViews.size(); i++) &#123; VkImageView attachments[] = &#123; swapChainImageViews[i] &#125;; VkFramebufferCreateInfo framebufferInfo = &#123;&#125;; framebufferInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO; framebufferInfo.renderPass = renderPass; framebufferInfo.attachmentCount = 1; framebufferInfo.pAttachments = attachments; framebufferInfo.width = swapChainExtent.width; framebufferInfo.height = swapChainExtent.height; framebufferInfo.layers = 1; if (vkCreateFramebuffer(device, &amp;framebufferInfo, nullptr, &amp;swapChainFramebuffers[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create framebuffer!&quot;); &#125;&#125; 如上，帧缓冲区的创建非常简单: 首先需要指定帧缓冲区需要与哪个renderPass兼容。只能对与之兼容的渲染过程使用帧缓冲区，这意味着它们使用相同数量和类型的附件。 attachmentCount和pAttachments参数指定应绑定到渲染过程pAttachment数组中相应附件描述的VkImageView对象。 宽度和高度参数是交换链中获取的宽高 layers是指图像数组中的层数。我们的交换链图像是单个图像，因此层的数量是1。 我们应该先删除帧缓冲区，然后再删除它们所基于的图像视图和渲染过程，但必须在完成渲染之后： 123456void cleanup() &#123; for (auto framebuffer : swapChainFramebuffers) &#123; vkDestroyFramebuffer(device, framebuffer, nullptr); &#125; ...&#125; 现在我们已经到达了一个里程碑–拥有了渲染所需的所有对象。接下来，我们将编写第一个实际的绘图指令。 二. Command buffers 指令缓冲区Vulkan中的指令，比如绘图操作和内存传输，不是直接使用函数调用来执行的。必须在指令缓冲区对象中记录想要执行的所有操作。这样做的好处是，所有设置绘图指令的工作都可以提前在多个线程中完成。之后，只需告诉Vulkan在主循环中执行指令。 指令缓冲区是用来记录指令的对象，这些指令可以随后提交到设备队列中执行。指令缓冲区有两级:一级指令缓冲区，它可以执行二级指令缓冲区，并提交给队列;二级指令缓冲区，它可以由一级指令缓冲区执行，但不直接提交给队列。 2.1 Command pools 指令池在创建指令缓冲区之前必须先创建指令池。指令池管理用于存储缓冲区的内存，并从它们中分配指令缓冲区。 指令池通过允许不同的线程使用不同的分配器来提高多线程性能，而不需要每次使用都进行内部同步。 由VkCommandPool对象表示： VK_DEFINE_NON_DISPATCHABLE_HANDLE(VkCommandPool) 1VkCommandPool commandPool; 创建指令池函数: 12345VkResult vkCreateCommandPool( VkDevice device, const VkCommandPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCommandPool* pCommandPool); device: 创建指令池的逻辑设备 pCreateInfo: 一个指向VkCommandPoolCreateInfo结构实例的指针，该结构指定指令池对象的状态。 pAllocator: 控制内存分配 pCommandPool: 指向一个VkCommandPool句柄，创建的池返回该句柄。 2.1.1 创建指令池我们创建一个新的函数：createCommandPool, 来执行创建指令池： 123456789101112131415161718192021222324252627282930313233343536void initVulkan() &#123; // checkAvailableExtensions(); createInstance(); // 创建DEBUG消息回调 setupDebugMessenger(); // 创建surface createSurface(); // 选择物理设备 pickPhysicalDevice(); // 创建逻辑设备 createLogicalDevice(); // 创建交换链 createSwapChain(); // 创建交换链图像的VkImageView createImageViews(); // 创建渲染通道 createRenderPass(); // 创建管道 createGraphicsPipeline(); // 创建帧缓冲区 createFramebuffers(); // 创建指令缓冲池 createCommandPool();&#125;void createCommandPool() &#123; QueueFamilyIndices queueFamilyIndices = findQueueFamilies(physicalDevice); VkCommandPoolCreateInfo poolInfo = &#123;&#125;; poolInfo.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO; poolInfo.queueFamilyIndex = queueFamilyIndices.graphicsFamily.value(); poolInfo.flags = 0; // Optional if (vkCreateCommandPool(device, &amp;poolInfo, nullptr, &amp;commandPool) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create command pool!&quot;); &#125;&#125; 指令缓冲区是通过将它们提交到设备队列(比如我们检索到的图形和展示队列)上来执行的。 每个指令池只能分配提交到单一类型队列上的指令缓冲区。我们将记录绘图的指令，这就是我们选择图形队列家族的原因。 2.1.2 VkCommandPoolCreateInfo123456typedef struct VkCommandPoolCreateInfo &#123; VkStructureType sType; const void* pNext; VkCommandPoolCreateFlags flags; uint32_t queueFamilyIndex;&#125; VkCommandPoolCreateInfo; sType: 此结构的类型，VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO pNext: 为空或指向特定于扩展的结构的指针。 flags: 是VkCommandPoolCreateFlagBits的位掩码, 指示指令池和从中分配的指令缓冲区的使用行为。 queueFamilyIndex: 指定队列族。从这个指令池分配的所有指令缓冲区必须在来自相同队列族的队列上提交。 2.1.3 VkCommandPoolCreateFlags123456typedef enum VkCommandPoolCreateFlagBits &#123; VK_COMMAND_POOL_CREATE_TRANSIENT_BIT = 0x00000001, VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT = 0x00000002, VK_COMMAND_POOL_CREATE_PROTECTED_BIT = 0x00000004, VK_COMMAND_POOL_CREATE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkCommandPoolCreateFlagBits; VK_COMMAND_POOL_CREATE_TRANSIENT_BIT:指定从池中分配的指令缓冲区将是短暂的，这意味着它们将在相对较短的时间内被重置或释放。这个标志可以被实现用来控制池内的内存分配行为。 VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT:允许从池中分配的任何指令缓冲区被单独重置到初始状态;或者通过调用vkResetCommandBuffer，或者在调用vkBeginCommandBuffer时通过隐式重置。如果在池中没有设置这个标志，那么vkResetCommandBuffer绝对不能被从池中分配的任何指令缓冲区调用。 VK_COMMAND_POOL_CREATE_PROTECTED_BIT:指定从池中分配的指令缓冲区为受保护的指令缓冲区。如果未启用受保护的内存特性，则不能设置VK_COMMAND_POOL_CREATE_PROTECTED_BIT标志位。 鉴于我们将只在程序开始时记录指令缓冲区，然后在主循环中多次执行它们，因此我们不会使用这这些标志。 2.1.4 vkDestroyCommandPool使用vkCreateCommandPool功能完成指令池的创建，指令将在整个程序中使用来绘制屏幕上的东西，所以池应该只在结束时销毁: 12345void cleanup() &#123; // 释放指令池 vkDestroyCommandPool(device, commandPool, nullptr); ...&#125; 2.2 Command buffer allocation 指令缓冲区分配现在我们可以开始分配指令缓冲区并在其中记录绘图指令。因为其中一个绘图指令涉及到绑定正确的VkFramebuffer，所以我们实际上必须再次为交换链中的每个图像记录一个指令缓冲区。 为此，创建一个VkCommandBuffer对象列表作为类成员。当它们的指令池被销毁时，指令缓冲区将被自动释放，所以我们不需要显式的清理。 1std::vector&lt;VkCommandBuffer&gt; commandBuffers; 现在开始使用createCommandBuffers函数，为每个交换链图像(VkImageView)分配和记录指令。 12345678void initVulkan() &#123; ... createCommandBuffers();&#125;void createCommandBuffers() &#123; commandBuffers.resize(swapChainFramebuffers.size());&#125; 2.2.1 vkAllocateCommandBuffers指令缓冲区是通过vkAllocateCommandBuffers函数分配的，该函数以VkCommandBufferAllocateInfo结构体作为参数，指定指令池和要分配的缓冲区数量: 1234VkResult vkAllocateCommandBuffers( VkDevice device, const VkCommandBufferAllocateInfo* pAllocateInfo, VkCommandBuffer* pCommandBuffers); device: 指令池所属的逻辑设备。 pAllocateInfo: 指向VkCommandBufferAllocateInfo结构实例的指针，该结构描述了分配的参数。 pCommandBuffers: 指向VkCommandBuffer句柄数组的指针，在该数组中返回生成的指令缓冲区对象。数组必须至少为pAllocateInfo的commandBufferCount成员指定的长度commandBufferCount。每个分配的指令缓冲区都从初始状态开始。(就是commandBuffers集的首个元素的地址) 2.2.2 VkCommandBufferAllocateInfo1234567typedef struct VkCommandBufferAllocateInfo &#123; VkStructureType sType; const void* pNext; VkCommandPool commandPool; VkCommandBufferLevel level; uint32_t commandBufferCount;&#125; VkCommandBufferAllocateInfo; sType: 结构体类型 pNext: 为空或指向特定于扩展的结构的指针 commandPool: 分配此指令缓冲区的指令池 level: VkCommandBufferLevel值，指定指令缓冲区级别 commandBufferCount: 从池中分配的指令缓冲区的数量 VkCommandBufferLevel, 指定指令缓冲区级别: 12345typedef enum VkCommandBufferLevel &#123; VK_COMMAND_BUFFER_LEVEL_PRIMARY = 0, VK_COMMAND_BUFFER_LEVEL_SECONDARY = 1, VK_COMMAND_BUFFER_LEVEL_MAX_ENUM = 0x7FFFFFFF&#125; VkCommandBufferLevel; VK_COMMAND_BUFFER_LEVEL_PRIMARY:指定主指令缓冲区，可以提交到队列执行，但不能从其他指令缓冲区调用。 VK_COMMAND_BUFFER_LEVEL_SECONDARY:指定次要指令缓冲区，不能直接提交，但可以从主指令缓冲区调用。 2.2.3 createCommandBuffers接下来就是完成指令缓冲区集的创建： 123456789101112void createCommandBuffers() &#123; commandBuffers.resize(swapChainFramebuffers.size()); VkCommandBufferAllocateInfo allocInfo = &#123;&#125;; allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO; allocInfo.commandPool = commandPool; allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY; allocInfo.commandBufferCount = (uint32_t) commandBuffers.size(); if (vkAllocateCommandBuffers(device, &amp;allocInfo, commandBuffers.data()) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate command buffers!&quot;); &#125;&#125; 在这里不使用辅助指令缓冲区功能，但是可以想象，重用来自主要指令缓冲区的常用操作是很有帮助的 2.3 启动指令缓冲区记录记录的指令包括将管道和描述符集绑定到指令缓冲区的指令、修改动态状态的指令、绘制指令(用于图形渲染)、调度指令(用于计算)、执行次要指令缓冲区的指令(仅用于主要指令缓冲区)、复制缓冲区和图像的指令，以及其他指令。 为什么需要记录指令？ 先看一下指令缓冲区的生命周期。 2.3.1 指令缓冲区的生命周期每个指令缓冲区总是处于以下状态之一: Initial(初始状态): 当一个指令缓冲区被分配时，它处于初始状态。一些指令能够将一个指令缓冲区或一组指令缓冲区从任何可执行状态、记录状态或无效状态重置回该状态。处于初始状态的指令缓冲区只能移动到记录状态或释放。 Recording(记录状态): vkBeginCommandBuffer改变指令缓冲区的状态从初始状态到记录状态。一旦指令缓冲区处于记录状态，可以使用vkCmd*指令记录到指令缓冲区。 Executable(可执行状态): vkEndCommandBuffer结束指令缓冲区的记录，并将其从记录状态移动到可执行状态。可执行指令缓冲区可以提交、重置或记录到另一个指令缓冲区。 Pending(挂起状态): 指令缓冲区的队列提交将指令缓冲区的状态从可执行状态更改为挂起状态。在挂起状态下，应用程序不能试图以任何方式修改指令缓冲区-因为设备可能正在处理记录到它的指令。一旦指令缓冲区的执行完成，指令缓冲区将返回到可执行状态，或者返回无效状态(如果它是通过VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT记录的)。应该使用一个同步指令来检测何时发生这种情况。 Invalid(无效状态):某些操作，如修改或删除记录到指令缓冲区的指令中使用的资源，将把该指令缓冲区的状态转换为无效状态。处于无效状态的指令缓冲区只能被重置或释放。 所以记录状态可以理解为记录绘制操作，然后记录完毕就转为可执行状态，等待被执行。 2.3.2 记录指令缓冲区通过调用vkBeginCommandBuffer开始记录指令缓冲区，并使用一个小的VkCommandBufferBeginInfo结构作为参数，指定关于这个特定指令缓冲区使用的一些细节。 123VkResult vkBeginCommandBuffer( VkCommandBuffer commandBuffer, const VkCommandBufferBeginInfo* pBeginInfo); commandBuffer: 待放入记录状态的指令缓冲区的句柄。 pBeginInfo: VkCommandBufferBeginInfo结构的一个实例，它定义了关于指令缓冲区如何开始记录的附加信息。 123456typedef struct VkCommandBufferBeginInfo &#123; VkStructureType sType; const void* pNext; VkCommandBufferUsageFlags flags; const VkCommandBufferInheritanceInfo* pInheritanceInfo;&#125; VkCommandBufferBeginInfo; sType: 结构体类型 pNext: 为空或指向特定于扩展的结构的指针 flags: 是VkCommandBufferUsageFlagBits的位掩码，指定命令缓冲区的使用行为。 pInheritanceInfo: 是一个指向VkCommandBufferInheritanceInfo结构的指针，如果commandBuffer是一个次要命令缓冲区，就会使用这个结构。如果这是一个主命令缓冲区，那么这个值将被忽略。 在VkCommandBufferBeginInfo::flags中设置位来指定命令缓冲区的使用行为: 123456typedef enum VkCommandBufferUsageFlagBits &#123; VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT = 0x00000001, VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT = 0x00000002, VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT = 0x00000004, VK_COMMAND_BUFFER_USAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkCommandBufferUsageFlagBits; VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT:指定命令缓冲区的每个记录将只提交一次，命令缓冲区将被重置并在每次提交之间再次记录。 VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT:指定次要命令缓冲区被认为完全位于渲染通道内。如果这是一个主命令缓冲区，那么这个位会被忽略。 VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT:指定当命令缓冲区处于挂起状态时，可以重新提交给队列，并记录到多个主要命令缓冲区中。 开始指令缓冲区记录: 12345678910for (size_t i = 0; i &lt; commandBuffers.size(); i++) &#123; VkCommandBufferBeginInfo beginInfo = &#123;&#125;; beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO; // 标记该指令缓冲区可重复追加指令 beginInfo.flags = VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT; beginInfo.pInheritanceInfo = nullptr; // Optional if (vkBeginCommandBuffer(commandBuffers[i], &amp;beginInfo) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to begin recording command buffer!&quot;); &#125;&#125; 我们使用VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT标志是因为我们可能已经在为下一帧调度绘图命令，而最后一帧还没有完成。pInheritanceInfo参数仅与辅助命令缓冲区相关。它指定从调用的主命令缓冲区继承哪个状态。 如果命令缓冲区已经被记录过一次，那么调用vkBeginCommandBuffer将隐式重置它。以后不可能向缓冲区追加命令。 2.4 启动渲染通道通过vkCmdBeginRenderPass开始绘制。渲染通道是使用VkRenderPassBeginInfo结构中的一些参数来配置的。 1234void vkCmdBeginRenderPass( VkCommandBuffer commandBuffer, const VkRenderPassBeginInfo* pRenderPassBegin, VkSubpassContents contents); commandBuffer: 指令缓冲区 VkRenderPassBeginInfo: 是一个指向VkRenderPassBeginInfo结构的指针，提供的渲染通道的详细信息 contents: 是一个VkSubpassContents值，控制渲染通道内的绘图命令将如何提供,可以有两个值: VK_SUBPASS_CONTENTS_INLINE:render pass命令将被嵌入到主命令缓冲区中，而不会执行次要命令缓冲区。 VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS:render pass命令将从次要命令缓冲区执行。 在开始渲染通道实例之后，命令缓冲区准备好记录该渲染通道的第一个子通道的命令。 2.4.1 VkRenderPassBeginInfo123456789typedef struct VkRenderPassBeginInfo &#123; VkStructureType sType; const void* pNext; VkRenderPass renderPass; VkFramebuffer framebuffer; VkRect2D renderArea; uint32_t clearValueCount; const VkClearValue* pClearValues;&#125; VkRenderPassBeginInfo; sType: 结构体类型 pNext: 为空或指向特定于扩展的结构的指针 renderPass: 渲染通道 framebuffer: 指令缓冲区 renderArea: 渲染通道实例影响的渲染区域 clearValueCount: pClearValues中的元素数量 pClearValues: 是一个VkClearValue结构的数组，它包含每个附件的清除值，如果附件使用的loadOp值是VK_ATTACHMENT_LOAD_OP_CLEAR，或者附件具有深度&#x2F;模板格式并使用的stencilLoadOp值是VK_ATTACHMENT_LOAD_OP_CLEAR。数组按附件号索引。只使用与已清除附件对应的元素。pClearValues的其他元素将被忽略。 renderArea渲染区域是受渲染通道实例影响的渲染区域。附件加载、存储和多样本解析操作的影响仅限于x和y坐标落在所有附件渲染区域内的像素。渲染区域扩展到framebuffer的所有层。应用程序必须确保(必要时使用scissor)所有的渲染都包含在渲染区域内。渲染区域必须包含在framebuffer尺寸内。 2.4.2 start a Render Pass应用程序一次记录一个render pass实例的命令，方法是开始一个render pass实例，遍历子通道(subpass)来记录该子通道的命令，然后结束render pass实例。 123456789101112131415VkRenderPassBeginInfo renderPassInfo = &#123;&#125;;renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;// 渲染通道本身和要绑定的附件renderPassInfo.renderPass = renderPass;// 每个交换链图像创建了一个framebuffer，将其指定为颜色附件。renderPassInfo.framebuffer = swapChainFramebuffers[i];// 渲染区域定义着色器加载和存储的位置。该区域之外的像素将具有未定义的值。它应该与附件的大小相匹配，以获得最佳性能。renderPassInfo.renderArea.offset = &#123;0, 0&#125;;renderPassInfo.renderArea.extent = swapChainExtent;// 定义用于VK_ATTACHMENT_LOAD_OP_CLEAR的清除值，我们将其用作颜色附件的加载操作。将透明颜色定义为100%不透明度的黑色。VkClearValue clearColor = &#123;0.0f, 0.0f, 0.0f, 1.0f&#125;;renderPassInfo.clearValueCount = 1;renderPassInfo.pClearValues = &amp;clearColor; 2.4.3 基本绘制指令123456789// 渲染通道现在可以开始了。所有记录命令的函数都可以通过它们的vkCmd前缀来识别。它们都返回void，所以在完成记录之前不会有错误处理。vkCmdBeginRenderPass(commandBuffers[i], &amp;renderPassInfo, VK_SUBPASS_CONTENTS_INLINE);vkCmdBindPipeline(commandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS, graphicsPipeline);vkCmdDraw(commandBuffers[i], 3, 1, 0, 0);vkCmdEndRenderPass(commandBuffers[i]);if (vkEndCommandBuffer(commandBuffers[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to record command buffer!&quot;);&#125; 2.4.3.1 vkCmdBindPipeline管道被创建后，可以使用以下命令将其绑定到指令缓冲区: 1234void vkCmdBindPipeline( VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipeline pipeline); commandBuffer: 是即将绑定到管道的命令缓冲区 pipelineBindPoint:是一个VkPipelineBindPoint值，指定管道对象是图形管道还是计算管道。 VK_PIPELINE_BIND_POINT_COMPUTE: 管道控制vkCmdDispatch和vkCmdDispatchIndirect的行为。 VK_PIPELINE_BIND_POINT_GRAPHICS: 管道控制所有绘制命令的行为。其他命令不受管道状态的影响。 pipeline: 即将绑定的管道 一旦绑定，管道绑定将影响命令缓冲区中的后续图形或计算命令，直到另一个管道绑定到绑定点。 2.4.3.2 vkCmdDraw123456void vkCmdDraw( VkCommandBuffer commandBuffer, uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance); commandBuffer: 绘制指令记录到的指令缓冲区 vertexCount: 要绘制的顶点数 instanceCount: 要绘制的实例数 firstVertex: 要绘制的第一个顶点的索引 firstInstance: 要绘制的第一个实例的索引 当执行该命令时，将使用当前基元拓扑和vertexCount连续顶点索引(第一个vertexIndex值等于firstVertex)组装基元。这些原语是用从firstInstance开始的instanceIndex绘制的instanceCount时间，并按顺序增加每个实例。组装的原语执行绑定的图形管道。 2.4.3.3 vkCmdEndRenderPass在记录了最后一个子过程的指令之后，结束渲染通道实例调用: 12void vkCmdEndRenderPass( VkCommandBuffer commandBuffer); 结束渲染通道实例在最终子通道上执行一切多样本解析操作。 2.4.3.4 vkEndCommandBuffer一旦开始记录，应用程序将记录指令序列(vkCmd*)，以在指令缓冲区、绘制、调度和其他指令中设置状态。调用完成vkEndCommandBuffer命令缓冲区的记录: 12VkResult vkEndCommandBuffer( VkCommandBuffer commandBuffer); 如果在记录过程中发生了错误，vkEndCommandBuffer将返回一个不成功的返回码来通知应用程序。 如果应用程序希望进一步使用指令缓冲区，则必须重置指令缓冲区。指令缓冲区必须处于记录状态，并被移动到可执行状态。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(7)-渲染过程及创建图形管道","slug":"Vulkan入门-7-渲染过程及创建图形管道","date":"2022-02-26T19:22:14.000Z","updated":"2022-02-26T19:29:57.058Z","comments":true,"path":"2022/02/27/Vulkan入门-7-渲染过程及创建图形管道/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-7-%E6%B8%B2%E6%9F%93%E8%BF%87%E7%A8%8B%E5%8F%8A%E5%88%9B%E5%BB%BA%E5%9B%BE%E5%BD%A2%E7%AE%A1%E9%81%93/","excerpt":"简述Render passes, 即渲染过程。在完成创建管道之前，我们需要告诉Vulkan渲染时将使用的帧缓冲区附件。 我们需要指定将有多少颜色和深度缓冲区，为每个缓冲区使用多少个样本，以及在整个渲染操作中应如何处理它们的内容。 所有这些信息都包装在一个render pass对象中，为其创建一个新的createRenderPass函数。在createGraphicsPipeline之前从initVulkan调用此函数。","text":"简述Render passes, 即渲染过程。在完成创建管道之前，我们需要告诉Vulkan渲染时将使用的帧缓冲区附件。 我们需要指定将有多少颜色和深度缓冲区，为每个缓冲区使用多少个样本，以及在整个渲染操作中应如何处理它们的内容。 所有这些信息都包装在一个render pass对象中，为其创建一个新的createRenderPass函数。在createGraphicsPipeline之前从initVulkan调用此函数。 123456789101112131415void initVulkan() &#123; createInstance(); setupDebugCallback(); createSurface(); pickPhysicalDevice(); createLogicalDevice(); createSwapChain(); createImageViews(); createRenderPass(); createGraphicsPipeline();&#125;void createRenderPass() &#123;&#125; Vulkan图形管线和计算管线的区别之一是，你使用图形管线来渲染出像素，组成图像以供处理或显示给用户。在复杂的图形应用程序中，图片经过很多遍构建，每一遍都生成场景的一部分，应用全帧效果如后期处理、合成、渲染用户界面元素等等。这样的一遍可以使用Vulkan 中 renderpass 对象表示。 一个单一的的renderpass对象封装了多个pass或者一系列最终图像的几个渲染阶段，renderpass对象包含输出图像所需的信息。 所有的绘制必须被包含在一个renderpass中。甚至，图形管线需要知道他们把渲染结果发往哪儿，因此，有必要在创建图形管线之前创建一个renderpass对象，告知正在生成图像的管线有关图像的信息。 参考资料一. Attachment description 附件说明在这里，我们仅有一个颜色缓冲区附件，由交换链中的一个图像表示。 12345void createRenderPass() &#123; VkAttachmentDescription colorAttachment = &#123;&#125;; colorAttachment.format = swapChainImageFormat; colorAttachment.samples = VK_SAMPLE_COUNT_1_BIT;&#125; 颜色附件的格式应该与交换链图像的格式匹配，而且我们还没有对多重采样做任何事情，所以只要使用1个样本。 12345colorAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;colorAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE;colorAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;colorAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE; loadOp和storeOp决定在呈现之前和呈现之后如何处理附件中的数据。loadOp和storeOp应用于颜色和深度数据，以及stencilLoadOp&#x2F;stencilStoreOp应用于模具数据。这里不会对模板缓冲区执行任何操作，因此加载和存储的结果是无关的。 1.1 loadOp VK_ATTACHMENT_LOAD_OP_LOAD: 指定将保留渲染区域中图像的先前内容。对于深度&#x2F;模具格式的附件，这将使用访问类型VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ位。对于颜色格式的附件，这将使用访问类型VK_ACCESS_COLOR_ATTACHMENT_READ位。 VK_ATTACHMENT_LOAD_OP_CLEAR: 指定将渲染区域中的内容清除为统一值，该值在渲染过程实例开始时指定。对于深度&#x2F;模板格式的附件，这将使用访问类型VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE位。对于颜色格式的附件，这将使用访问类型VK_ACCESS_COLOR_ATTACHMENT_WRITE位。 VK_ATTACHMENT_LOAD_OP_DONT_CARE: 指定不需要保留区域中的前一个内容；附件的内容将在渲染区域内未定义。对于深度&#x2F;模板格式的附件，这将使用访问类型VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE位。对于颜色格式的附件，这将使用访问类型VK_ACCESS_COLOR_ATTACHMENT_WRITE位。 1.2 storeOp VK_ATTACHMENT_STORE_OP_STORE: 指定在渲染过程中和渲染区域内生成的内容写入内存，以后可以读取 VK_ATTACHMENT_STORE_OP_DONT_CARE: 指定渲染后不需要渲染区域内的内容，这些内容可能会被丢弃；附件的内容将在渲染区域内未定义。 1.3 内存中像素的布局12colorAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;colorAttachment.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR; Vulkan中的纹理和帧缓冲区由具有特定像素格式的VkImage对象表示，但是，内存中像素的布局可能会根据您尝试对图像执行的操作而改变。 initialLayout指定在渲染过程开始之前图像将具有的布局。finalLayout最终布局指定渲染过程完成时自动转换到的布局。 对initialLayout使用VK_IMAGE_LAYOUT_UNDEFINED意味着我们不关心图像在以前的布局中是什么。这个特殊值的警告是图像的内容不能保证被保存，但这并不重要，因为我们无论如何都要清除它。我们希望图像在渲染后可以使用交换链进行显示，这就是为什么我们使用VK_IMAGE_LAYOUT_PRESENT_SRC_KHR作为finalLayout。 一些最常见的布局有： VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL: 用作颜色附件的图像 VK_IMAGE_LAYOUT_PRESENT_SRC_KHR: 交换链中要显示的图像 VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL: 要用作内存复制操作目标的图像 我们将在“纹理”一章中更深入地讨论这个主题，但现在需要知道的是，图像需要转换到适合其下一步将要涉及的操作的特定布局。 二. Subpasses and attachment references 子过程和附件引用单个渲染过程可以由多个子过程组成。子过程是依赖于先前过程中帧缓冲区的内容的后续呈现操作。 例如一系列相继应用的后处理效果。如果将这些渲染操作分组到一个渲染过程中，则Vulkan能够对操作重新排序，并节省内存带宽以获得可能更好的性能。 这里对于一个三角形，使用一个子过程。 每个子过程引用一个或多个附件，这些附件是我们使用前面部分中的结构描述的。这些引用本身就是VKatAttchmentReference结构，如下： 123VkAttachmentReference colorAttachmentRef = &#123;&#125;;colorAttachmentRef.attachment = 0;colorAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL; attachment参数通过附件描述数组中的索引指定要引用的附件。我们的数组由一个VkAttachmentDescription组成，所以它的索引是0。 layout指定在使用此引用的子过程期间希望附件具有的布局。当子进程启动时，Vulkan将自动将附件转换到此布局。使用附件作为一个颜色缓冲区，VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL LAYOUT会给我们带来最好的性能，顾名思义。 子过程使用VkSubpassDescription结构进行描述： 1234VkSubpassDescription subpass = &#123;&#125;;subpass.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;subpass.colorAttachmentCount = 1;subpass.pColorAttachments = &amp;colorAttachmentRef; // 指定对颜色附件的引用 Vulkan将来也可能支持计算子过程，所以我们必须明确表示这是一个图形子过程。此数组中附件的索引直接从具有layout（location&#x3D;0）out vec4 outColor指令的片段着色器引用！ 子过程可以引用以下类型的附件： pColorAttachments: 颜色附件 pInputAttachments: 从着色器读取的附件 pResolveAttachments: 用于多重采样颜色附件的附件 pDepthStencilAttachment: 深度和模板数据附件 pPreserveAttachments: 此子过程未使用但必须保留数据的附件 三. Render pass 渲染过程上面已经描述了附件和引用它的基本子过程，我们就可以创建渲染过程本身了。 渲染过程表示附件、子过程和子过程之间的依赖关系的集合，并描述如何在子过程中使用附件。 创建一个新的类成员变量，将VkRenderPass对象保持在pipelineLayout变量的正上方： 12VkRenderPass renderPass;VkPipelineLayout pipelineLayout; 可以通过使用附件和子过程数组填充VkRenderPassCreateInfo结构来创建渲染过程对象。VkAttachmentReference对象使用此数组的索引引用附件。 12345678910// 创建渲染过程VkRenderPassCreateInfo renderPassInfo = &#123;&#125;;renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;renderPassInfo.attachmentCount = 1;renderPassInfo.pAttachments = &amp;colorAttachment;renderPassInfo.subpassCount = 1;renderPassInfo.pSubpasses = &amp;subpass;if (vkCreateRenderPass(device, &amp;renderPassInfo, nullptr, &amp;renderPass) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create render pass!&quot;);&#125; 与管道布局一样，渲染过程将在整个程序中被引用，因此只应在结束时进行清理： 12345void cleanup() &#123; vkDestroyPipelineLayout(device, pipelineLayout, nullptr); vkDestroyRenderPass(device, renderPass, nullptr); ...&#125; 目前我们以及做了很多工作了，下一步就是创建图形管道对象了！ 四. 创建 pipeline快速回顾现在拥有的对象类型： shader stages: 定义图形管道可编程阶段功能的着色器模块 Fixed-function state: 定义管道固定函数阶段的所有结构，如输入程序集、光栅化器、视口和颜色混合 Pipeline layout: 可在绘制时更新的着色器引用的统一值和推送值 Render pass: 管道阶段引用的附件及其用法 所有这些组合都充分定义了图形管道的功能，因此现在可以开始在createGraphicsPipeline函数末尾填充VkGraphicsPipelineCreateInfo结构。但是是在调用vkDestroyShaderModule之前，因为在创建过程中使用仍然需要使用这些着色器！ VkGraphicsPipelineCreateInfo结构包括一个shader-reate-info结构数组，其中包含所有所需的活动着色器阶段、定义所有相关固定函数阶段的创建信息以及管道布局。 123456789101112131415161718VkGraphicsPipelineCreateInfo pipelineInfo = &#123;&#125;;pipelineInfo.sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO;pipelineInfo.stageCount = 2;pipelineInfo.pStages = shaderStages;// 首先引用VkPipelineShaderStageCreateInfo结构的数组。pipelineInfo.pVertexInputState = &amp;vertexInputInfo;pipelineInfo.pInputAssemblyState = &amp;inputAssembly;pipelineInfo.pViewportState = &amp;viewportState;pipelineInfo.pRasterizationState = &amp;rasterizer;pipelineInfo.pMultisampleState = &amp;multisampling;pipelineInfo.pDepthStencilState = nullptr; // OptionalpipelineInfo.pColorBlendState = &amp;colorBlending;pipelineInfo.pDynamicState = nullptr; // Optional// 然后引用所有描述固定函数阶段的结构。pipelineInfo.layout = pipelineLayout;// 之后是管道布局，它是一个Vulkan句柄而不是结构指针。pipelineInfo.renderPass = renderPass;pipelineInfo.subpass = 0; 最后，我们有了渲染过程的引用以及使用这个图形管道的子过程的索引。也可以将其他渲染过程用于此管道而不是此特定实例，但它们必须与renderPass兼容。下面描述了兼容性的要求，但这里不使用该特性。 实际上还有两个参数：basePipelineHandle和basePipelineIndex。 Vulkan允许通过从现有管道派生来创建新的图形管道。管道衍生品的想法是，当管道具有与现有管道具有许多相同功能时，设置管道成本更低，并且可以更快地在同一父管道之间切换。可以指定现有管道的句柄（带有basePipelineHandle），也可以引用另一个将由basePipelineIndex的索引创建的管道。 现在只有一个管道，所以只需要指定一个null句柄和一个无效的索引。只有在VkGraphicsPipelineCreateInfo的flags字段中指定VK_PIPELINE_CREATE_UBIT标志时，才使用这些值。 12pipelineInfo.basePipelineHandle = VK_NULL_HANDLE; // OptionalpipelineInfo.basePipelineIndex = -1; // Optional 通过创建一个类成员来保存VkPipeline对象： 1234567VkPipeline graphicsPipeline;// 创建图形管道if (vkCreateGraphicsPipelines(device, VK_NULL_HANDLE, 1, &amp;pipelineInfo, nullptr, &amp;graphicsPipeline) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create graphics pipeline!&quot;);&#125; vkCreateGraphicsPipelines实际上比Vulkan中常用的对象创建函数有更多的参数。它的设计是支持在一次调用中获取多个VkGraphicsPipelineCreateInfo对象并创建多个VkPipeline对象。 第二个参数（我们为其传递了VK_NULL_HANDLE参数）引用了一个可选的VkPipelineCache对象。管道缓存可用于在对vkCreateGraphicsPipelines的多个调用中存储和重用与管道创建相关的数据，如果缓存存储到文件中，甚至可以跨程序执行。这使得以后可以大大加快管道的创建速度。我们将在管道缓存中讨论这个问题。 所有常见的绘图操作都需要图形管道，因此也只能在程序结束时销毁： 12345void cleanup() &#123; vkDestroyPipeline(device, graphicsPipeline, nullptr); vkDestroyPipelineLayout(device, pipelineLayout, nullptr); ...&#125; 现在运行程序来确认所有这些艰苦的工作已经成功地创建了管道！我们已经非常接近看到屏幕上弹出一些东西(实际现在还没有看到任何东西，黑乎乎一片)。 接下来将从交换链图像设置实际的帧缓冲区，并准备绘图命令。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(6)-创建管道的几个固定操作","slug":"Vulkan入门-6-创建管道的几个固定操作","date":"2022-02-26T19:22:00.000Z","updated":"2022-02-26T19:29:09.449Z","comments":true,"path":"2022/02/27/Vulkan入门-6-创建管道的几个固定操作/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-6-%E5%88%9B%E5%BB%BA%E7%AE%A1%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9B%BA%E5%AE%9A%E6%93%8D%E4%BD%9C/","excerpt":"简述其他图形API为图形管道的大多数阶段提供了默认状态。但在Vulkan中，必须明确所有内容，从视口大小到颜色混合功能。接下来我们试着填写配置这些固定功能操作的所有结构。","text":"简述其他图形API为图形管道的大多数阶段提供了默认状态。但在Vulkan中，必须明确所有内容，从视口大小到颜色混合功能。接下来我们试着填写配置这些固定功能操作的所有结构。 参考资料一. Vertex inputVkPipelineVertexInputStateCreateInfo结构描述将传递给顶点着色器的顶点数据的格式。它以两种方式描述了这一点： 绑定( Bindings )：数据之间的间距以及数据是按顶点还是按实例（请参阅实例化） 属性描述( Attribute descriptions )：传递给顶点着色器的属性的类型，从哪个绑定加载它们 因为我们直接在顶点着色器中对顶点数据进行硬编码，所以我们将填充此结构以指定现在没有要加载的顶点数据。 12345678910111213141516void createGraphicsPipeline() &#123; ...... // 这里为管道指定着色器 VkPipelineShaderStageCreateInfo shaderStages[] = &#123;vertShaderStageInfo, fragShaderStageInfo&#125;; // 创建顶点着色器的数据输入 VkPipelineVertexInputStateCreateInfo vertexInputInfo = &#123;&#125;; vertexInputInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO; vertexInputInfo.vertexBindingDescriptionCount = 0; vertexInputInfo.pVertexBindingDescriptions = nullptr; // Optional vertexInputInfo.vertexAttributeDescriptionCount = 0; vertexInputInfo.pVertexAttributeDescriptions = nullptr; // Optional ......&#125; pVertexBindingDescriptions和pVertexAttributeDescriptions 成员指向一个结构数组，描述前面提到的加载顶点数据的细节。后续在学习顶点缓冲的时候详细分析。 二. Input assemblyVkPipelineInputAssemblyStateCreateInfo结构描述了两件事： 将从顶点绘制什么类型的几何, 由成员变量topology 指定。可以使用如下值： VK_PRIMITIVE_TOPOLOGY_POINT_LIST：来自顶点的点 VK_PRIMITIVE_TOPOLOGY_LINE_LIST：来自每2个顶点的行而不重用 VK_PRIMITIVE_TOPOLOGY_LINE_STRIP：每行的结束顶点用作下一行的起始顶点 VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST：每3个顶点的三角形，无需重复使用 VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP：每个三角形的第二个和第三个顶点用作下一个三角形的前两个顶点 是否应启用基元重启。 通常，顶点缓冲区按顺序从顶点缓冲区加载，但是使用元素缓冲区可以指定要自己使用的索引，这允许您执行重用顶点等优化。如果将primitiveRestartEnable成员设置为VK_TRUE，则可以通过使用特殊索引0xFFFF或0xFFFFFFFF来分解_STRIP拓扑模式中的行和三角形。 如果是绘制三角形，创建如下的 VkPipelineInputAssemblyStateCreateInfo： 12345VkPipelineInputAssemblyStateCreateInfo inputAssembly = &#123;&#125;;inputAssembly.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;inputAssembly.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;inputAssembly.primitiveRestartEnable = VK_FALSE; 三. Viewports and scissors3.1 Viewports视窗描述了输出将被渲染到的帧缓冲区域。 基本总是（0,0）到（宽度，高度），也就是窗口大小。 1234567VkViewport viewport = &#123;&#125;;viewport.x = 0.0f;viewport.y = 0.0f;viewport.width = (float) swapChainExtent.width; // 交换链，即帧缓冲区viewport.height = (float) swapChainExtent.height;viewport.minDepth = 0.0f;viewport.maxDepth = 1.0f; 交换链及其图像的大小可能与窗口的宽度和高度不同。 交换链图像将在以后用作帧缓冲区，因此我们不能轻易改变它们的大小。minDepth和maxDepth值指定用于帧缓冲区的深度值范围。 这些值必须在[0.0f，1.0f]范围内，但minDepth可能高于maxDepth。虽然视窗定义了从图像到帧缓冲的转换，但剪刀矩形定义了实际存储像素的区域。剪刀矩形外的任何像素都将被光栅化器丢弃。 它们的功能类似于过滤器而不是转换。差异如下所示。 请注意，左边的剪刀矩形只是导致该图像的众多可能性之一，只要它比视口大： 也就是说Viewport会缩放以显示完整的图片，而scissors会裁剪(或者说遮挡)图片内容。 3.2 Scissors简单定义一个可以绘制整个帧缓冲的Scissor: 123VkRect2D scissor = &#123;&#125;;scissor.offset = &#123;0, 0&#125;;scissor.extent = swapChainExtent; 3.3 使用方式现在使用VkPipelineViewportStateCreateInfo结构将此视口和剪刀矩形组合成视口状态。可以在某些图形卡上使用多个视口和剪刀矩形，因此其成员需要引用它们的数组。使用多个需要启用GPU功能。 1234567VkPipelineViewportStateCreateInfo viewportState = &#123;&#125;;viewportState.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;viewportState.viewportCount = 1;viewportState.pViewports = &amp;viewport;viewportState.scissorCount = 1;viewportState.pScissors = &amp;scissor; 四. Rasterizer (光栅化)光栅化器采用由顶点着色器的顶点整形的几何体，并将其转换为片段着色器着色的片段。它还可以执行深度测试，面部剔除和剪刀测试，并且可以配置为输出填充整个多边形或仅填充边缘的片段（线框渲染）。所有这些都是使用VkPipelineRasterizationStateCreateInfo结构配置的。 12345678910111213VkPipelineRasterizationStateCreateInfo rasterizer = &#123;&#125;;rasterizer.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;rasterizer.depthClampEnable = VK_FALSE;rasterizer.rasterizerDiscardEnable = VK_FALSE;rasterizer.polygonMode = VK_POLYGON_MODE_FILL;rasterizer.lineWidth = 1.0f;rasterizer.cullMode = VK_CULL_MODE_BACK_BIT;rasterizer.frontFace = VK_FRONT_FACE_CLOCKWISE;rasterizer.depthBiasEnable = VK_FALSE;rasterizer.depthBiasConstantFactor = 0.0f; // Optionalrasterizer.depthBiasClamp = 0.0f; // Optionalrasterizer.depthBiasSlopeFactor = 0.0f; // Optional depthClampEnable: 设置为VK_TRUE，那么超出近平面和远平面的fragment将被夹住，而不是丢弃它们。这在某些特殊情况下很有用，比如阴影贴图。使用此功能需要启用GPU功能。 rasterizerDiscardEnable: 设置为VK_TRUE，那么几何图形永远不会通过光栅化阶段。这基本上禁止任何输出到帧缓冲区。 polygonMode: 多边形模态决定了如何为几何图形生成fragment。有以下几种模式:(使用FILL以外的任何模式都需要启用GPU功能) VK_POLYGON_MODE_FILL: 用fragment填充多边形的区域 VK_POLYGON_MODE_LINE: 多边形边缘以直线的形式绘制 VK_POLYGON_MODE_POINT: 用点绘制多边形顶点 lineWidth: 用来描述线条的粗细。支持的最大线宽取决于硬件，任何超过1.0f的线路都需要启用宽带GPU功能。 cullMode: 确定要使用的面消隐的类型。可以禁用消隐、消隐正面、消隐背面或两者兼有。 frontFace: 指定要视为正面的面的顶点顺序，可以是顺时针或逆时针。 光栅化器可以通过添加一个常量值或根据fragment的坡度对深度值进行偏移来改变深度值。这有时用于阴影映射，一般不使用时只需将depthBiasEnable设置为VK_FALSE。 五. Multisampling 多重采样VkPipelineMultisampleStateCreateInfo结构体用于配置vulkan中的多重采样。 是通过将光栅化为同一像素的多个多边形的片段着色器结果组合在一起实现的，这也是抗锯齿的方式之一。主要是在图形边缘地区做多重采样，这是最明显的锯齿伪影发生的地方。 如果只有一个多边形映射到一个像素，它不需要多次运行片段着色器，因此它比简单地渲染到更高的分辨率然后缩小比例的开销小得多。 启用多重采样需要启用GPU功能。 12345678VkPipelineMultisampleStateCreateInfo multisampling = &#123;&#125;;multisampling.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;multisampling.sampleShadingEnable = VK_FALSE;multisampling.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT;multisampling.minSampleShading = 1.0f; // Optionalmultisampling.pSampleMask = nullptr; // Optionalmultisampling.alphaToCoverageEnable = VK_FALSE; // Optionalmultisampling.alphaToOneEnable = VK_FALSE; sampleShadingEnable: 可用于启用采样着色。 rasterizationSamples: 指定用于光栅化的样本数, 一共有7个可选 VK_SAMPLE_COUNT_1_BIT: 指定每像素1个采样的图像。 VK_SAMPLE_COUNT_2_BIT: 指定每像素2个采样的图像。 VK_SAMPLE_COUNT_4_BIT: 指定每像素4个采样的图像。 VK_SAMPLE_COUNT_8_BIT: 指定每像素8个采样的图像。 VK_SAMPLE_COUNT_16_BIT: 指定每像素16个采样的图像。 VK_SAMPLE_COUNT_32_BIT: 指定每像素32个采样的图像。 VK_SAMPLE_COUNT_64_BIT: 指定每像素64个采样的图像。 minSampleShading: 若sampleShadingEnable设置为VK_TRUE，则指定采样着色的最小部分。 后续详细研究，当前先暂时关闭该功能。 六. Color blending 颜色混合片段着色器返回颜色后，需要将其与帧缓冲区中已有的颜色组合。这种转换称为颜色混合，有两种方法： 将新旧值混合生成最终颜色 使用位运算组合新旧值 有两种类型的结构可以配置颜色混合。 VkPipelineColorBlendAttachmentState: 包含每个附加帧缓冲区的配置， VkPipelineColorBlendStateCreateInfo: 包含全局颜色混合设置。 6.1 VkPipelineColorBlendAttachmentState 结构1234567891011121314VkPipelineColorBlendAttachmentState colorBlendAttachment = &#123;&#125;;colorBlendAttachment.colorWriteMask = VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT | VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT;colorBlendAttachment.blendEnable = VK_FALSE;colorBlendAttachment.srcColorBlendFactor = VK_BLEND_FACTOR_ONE;// OptionalcolorBlendAttachment.dstColorBlendFactor = VK_BLEND_FACTOR_ZERO;// OptionalcolorBlendAttachment.colorBlendOp = VK_BLEND_OP_ADD; // OptionalcolorBlendAttachment.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE;// OptionalcolorBlendAttachment.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO;// OptionalcolorBlendAttachment.alphaBlendOp = VK_BLEND_OP_ADD; // Optional 此每帧缓冲区结构允许您配置颜色混合的第一种方式。将要执行的操作使用以下伪代码演示原理： 123456789if (blendEnable) &#123; finalColor.rgb = (srcColorBlendFactor * newColor.rgb) &lt;colorBlendOp&gt; (dstColorBlendFactor * oldColor.rgb); finalColor.a = (srcAlphaBlendFactor * newColor.a) &lt;alphaBlendOp&gt; (dstAlphaBlendFactor * oldColor.a);&#125; else &#123; finalColor = newColor;&#125;finalColor = finalColor &amp; colorWriteMask; 如果blendEnable设置为VK_FALSE，则片段着色器中的新颜色将不经修改地通过。否则，执行这两个混合操作来计算新颜色。生成的颜色与colorWriteMask进行AND运算，以确定实际通过哪些通道。 使用颜色混合最常用的方法是实现alpha混合，我们希望新颜色与基于不透明度的旧颜色混合。最终颜色的计算如下： 12finalColor.rgb = newAlpha * newColor + (1 - newAlpha) * oldColor;finalColor.a = newAlpha.a; 这可以通过以下参数实现： 12345678// 实现alpha混合colorBlendAttachment.blendEnable = VK_TRUE;colorBlendAttachment.srcColorBlendFactor = VK_BLEND_FACTOR_SRC_ALPHA;colorBlendAttachment.dstColorBlendFactor = VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA;colorBlendAttachment.colorBlendOp = VK_BLEND_OP_ADD;colorBlendAttachment.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE;colorBlendAttachment.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO;colorBlendAttachment.alphaBlendOp = VK_BLEND_OP_ADD; 可以在VkBlendFactor和VkBlendOp中找到所有可用的操作： VkBlendFactor RGB Blend Factors (Sr,Sg,Sb) or (Dr,Dg,Db) Alpha Blend Factor (Sa or Da) VK_BLEND_FACTOR_ZERO (0,0,0) 0 VK_BLEND_FACTOR_ONE (1,1,1) 1 VK_BLEND_FACTOR_SRC_COLOR (Rs0,Gs0,Bs0) As0 VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR (1-Rs0,1-Gs0,1-Bs0) 1-As0 VK_BLEND_FACTOR_DST_COLOR (Rd,Gd,Bd) Ad VK_BLEND_FACTOR_ONE_MINUS_DST_COLOR (1-Rd,1-Gd,1-Bd) 1-Ad VK_BLEND_FACTOR_SRC_ALPHA (As0,As0,As0) As0 VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA (1-As0,1-As0,1-As0) 1-As0 VK_BLEND_FACTOR_DST_ALPHA (Ad,Ad,Ad) Ad VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA (1-Ad,1-Ad,1-Ad) 1-Ad VK_BLEND_FACTOR_CONSTANT_COLOR (Rc,Gc,Bc) Ac VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR (1-Rc,1-Gc,1-Bc) 1-Ac VK_BLEND_FACTOR_CONSTANT_ALPHA (Ac,Ac,Ac) Ac VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA (1-Ac,1-Ac,1-Ac) 1-Ac VK_BLEND_FACTOR_SRC_ALPHA_SATURATE (f,f,f); f &#x3D; min(As0,1-Ad) 1 VK_BLEND_FACTOR_SRC1_COLOR (Rs1,Gs1,Bs1) As1 VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR (1-Rs1,1-Gs1,1-Bs1) 1-As1 VK_BLEND_FACTOR_SRC1_ALPHA (As1,As1,As1) As1 VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA (1-As1,1-As1,1-As1) 1-As1 备注: Rs0、Gs0、Bs0和As0分别表示与正在混合的颜色附件相对应的片段输出位置的第一源颜色R、G、B和A分量。 Rs1、Gs1、Bs1和As1分别表示第二源颜色R、G、B和A分量，用于对应于被混合的颜色附件的片段输出位置，这些分量在双源混合模式中使用。 Rd、Gd、Bd和Ad表示目的颜色的R、G、B和A分量。也就是说，此片段&#x2F;样本的相应颜色附件中当前的颜色。 Rc、Gc、Bc和Ac分别表示混合常数R、G、B和A组分。 选择源和目标混合因子后，它们连同源和目标组件一起传递给混合操作。RGB和alpha组件可以使用不同的操作。指定操作的VkBlendOp的可能值为： VkBlendOp RGB Components Alpha Component VK_BLEND_OP_ADD R &#x3D; Rs0 × Sr + Rd × DrG &#x3D; Gs0 × Sg + Gd × DgB &#x3D; Bs0 × Sb + Bd × Db A &#x3D; As0 × Sa + Ad × Da VK_BLEND_OP_SUBTRACT R &#x3D; Rs0 × Sr - Rd × DrG &#x3D; Gs0 × Sg - Gd × DgB &#x3D; Bs0 × Sb - Bd × Db A &#x3D; As0 × Sa - Ad × Da VK_BLEND_OP_REVERSE_SUBTRACT R &#x3D; Rd × Dr - Rs0 × SrG &#x3D; Gd × Dg - Gs0 × SgB &#x3D; Bd × Db - Bs0 × Sb A &#x3D; Ad × Da - As0 × Sa VK_BLEND_OP_MIN R &#x3D; min(Rs0,Rd)G &#x3D; min(Gs0,Gd)B &#x3D; min(Bs0,Bd) A &#x3D; min(As0,Ad) VK_BLEND_OP_MAX R &#x3D; max(Rs0,Rd)G &#x3D; max(Gs0,Gd)B &#x3D; max(Bs0,Bd) A &#x3D; max(As0,Ad) 备注: Rs0、Gs0、Bs0和As0分别表示第一源颜色R、G、B和A分量。 Rd、Gd、Bd和Ad表示目的颜色的R、G、B和A分量。也就是说，此片段&#x2F;样本的相应颜色附件中当前的颜色。 Sr、Sg、Sb和Sa分别表示源混合因子R、G、B和A组分。 Dr、Dg、Db和Da分别表示目标混合因子R、G、B和A分量。 6.2 VkPipelineColorBlendStateCreateInfo 全局颜色混合设置VkPipelineColorBlendStateCreateInfo结构引用所有帧缓冲区的结构数组，并允许您设置可以在上述计算中用作混合因子的混合常数。 12345678910VkPipelineColorBlendStateCreateInfo colorBlending = &#123;&#125;;colorBlending.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;colorBlending.logicOpEnable = VK_FALSE;colorBlending.logicOp = VK_LOGIC_OP_COPY; // OptionalcolorBlending.attachmentCount = 1;colorBlending.pAttachments = &amp;colorBlendAttachment;colorBlending.blendConstants[0] = 0.0f; // OptionalcolorBlending.blendConstants[1] = 0.0f; // OptionalcolorBlending.blendConstants[2] = 0.0f; // OptionalcolorBlending.blendConstants[3] = 0.0f; // Optional 如果要使用第二种混合方法（按位组合），则应将logicOpEnable设置为VK_TRUE。然后可以在logicOp字段中指定位操作。请注意，这将自动禁用第一个方法，就像为每个附加的帧缓冲区将blendEnable设置为VK_FALSE一样！colorWriteMask也将用于此模式，以确定帧缓冲区中的哪些通道将实际受到影响。也可以禁用这两种模式，这种情况下，片段颜色将被不修改地写入帧缓冲区。 七. Dynamic state 可动态修改状态一小部分状态是可以不需要重新创建管道，直接修改的；比如viewport的大小，线宽和颜色混合常数等。 可以使用 VkPipelineDynamicStateCreateInfo 来更改这些动态参数： 12345678VkDynamicState dynamicStates[] = &#123; VK_DYNAMIC_STATE_VIEWPORT, VK_DYNAMIC_STATE_LINE_WIDTH&#125;;VkPipelineDynamicStateCreateInfo dynamicState = &#123;&#125;;dynamicState.sType = VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO;dynamicState.dynamicStateCount = 2;dynamicState.pDynamicStates = dynamicStates; 这将导致忽略这些值的配置，并要求在绘图时指定相应配置。 八. Pipeline layout 管道布置图可以在着色器中使用统一的值，类似于可以在绘制时更改的动态状态变量，以更改着色器的行为，而无需重新创建它们。 通常用于将变换矩阵传递给顶点着色器，或在片段着色器中创建纹理采样器。 在创建管道期间，需要通过创建VkPipelineLayout对象来指定这些统一值。创建一个类成员来保存这个对象，稍后会从其他函数中引用它： 12345678910111213141516VkPipelineLayout pipelineLayout;void createGraphicsPipeline() &#123; // ...... VkPipelineLayoutCreateInfo pipelineLayoutInfo = &#123;&#125;; pipelineLayoutInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO; pipelineLayoutInfo.setLayoutCount = 0; // Optional pipelineLayoutInfo.pSetLayouts = nullptr; // Optional pipelineLayoutInfo.pushConstantRangeCount = 0; // Optional pipelineLayoutInfo.pPushConstantRanges = nullptr; // Optional if (vkCreatePipelineLayout(device, &amp;pipelineLayoutInfo, nullptr, &amp;pipelineLayout) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create pipeline layout!&quot;); &#125; // ......&#125; 该结构还指定了push常量，这是将动态值传递给着色器的另一种方式，我们将在以后的章节中讨论。 管道布局将在整个程序的整个生命周期内被引用，因此在结束时应销毁： 1234void cleanup() &#123; vkDestroyPipelineLayout(device, pipelineLayout, nullptr); ...&#125; 九. 小结所有的固定函数状态都是这样！这是一个很大的工作，以设置所有这些从头开始，但好处是，我们现在几乎完全了解一切正在进行的图形管道！这减少了运行到意外行为的机会，因为某些组件的默认状态不是您所期望的。不过，在我们最终创建图形管道之前，还有一个对象需要创建，那就是渲染过程。 总结一下到目前位为止，创建图形管道应该做的操作: Vertex Input 描述将传递给顶点着色器的顶点数据的格式 Input assembly 描述顶点绘制几何类型 Viewports and scissors 描述将被渲染到的帧缓冲区域 Rasterizer 光栅化配置 Multisampling 配置多重采样 Color blending 配置颜色混合 Pipeline layout 创建管道布置图","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(5)-图像视图及Pipeline简述","slug":"Vulkan入门-5-图像视图及Pipeline简述","date":"2022-02-26T19:21:47.000Z","updated":"2022-02-26T19:29:03.055Z","comments":true,"path":"2022/02/27/Vulkan入门-5-图像视图及Pipeline简述/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-5-%E5%9B%BE%E5%83%8F%E8%A7%86%E5%9B%BE%E5%8F%8APipeline%E7%AE%80%E8%BF%B0/","excerpt":"简述本文主要介绍VkImageView以及着色器的创建，并且我们将学习到如何编写一个渐变颜色的三角形着色器。","text":"简述本文主要介绍VkImageView以及着色器的创建，并且我们将学习到如何编写一个渐变颜色的三角形着色器。 参考资料 [SPIR-V] https://www.khronos.org/spir/ [SPIR-V doc] https://www.khronos.org/registry/spir-v/specs/unified1/SPIRV.html [GLSL开发手册] https://github.com/wshxbqq/GLSL-Card 一. Image views在Render pipeline中使用VkImage, 包括在交换链中，需要创建一个VkImageView的对象。VkImageView实际上就是图像的视图。它描述了如何访问图像以及要访问的图像部分，例如，如果它应被视为2D纹理深度纹理而没有任何mipmapping级别。接下来我们试试为交换链中的每个图像创建一个基本VkImageView。创建VkImageView的方式也是通过一个结构体：VkImageViewCreateInfo, 来指明细节. 12345678910typedef struct VkImageViewCreateInfo &#123; VkStructureType sType; const void* pNext; VkImageViewCreateFlags flags; VkImage image; VkImageViewType viewType; VkFormat format; VkComponentMapping components; VkImageSubresourceRange subresourceRange;&#125; VkImageViewCreateInfo; 参数说明： VkImage: 绑定对应图像 VkImageViewType: 图像视图类型 一维纹理: VK_IMAGE_VIEW_TYPE_1D、VK_IMAGE_VIEW_TYPE_1D_ARRAY 二维纹理: VK_IMAGE_VIEW_TYPE_2D、VK_IMAGE_VIEW_TYPE_2D_ARRAY 三维纹理: VK_IMAGE_VIEW_TYPE_3D 立方体贴图: VK_IMAGE_VIEW_TYPE_CUBE、VK_IMAGE_VIEW_TYPE_CUBE_ARRAY VkFormat: 图像格式 VkComponentMapping: 图像颜色通道，即RGB和Alpha通道 VkImageSubresourceRange:描述了图像的目的以及应该访问图像的哪个部分 特别的，如果是3D应用程序, 那应该创建一个带有多个layer的交换链。这样可以通过访问不同的图层为每个图像创建多个图像视图，以表示左右视图。 123456789101112131415161718192021222324252627282930313233343536373839404142void createImageViews() &#123; // 设置集合大小 swapChainImageViews.resize(swapChainImages.size()); for (size_t i = 0; i &lt; swapChainImageViews.size(); i++) &#123; VkImageViewCreateInfo createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO; createInfo.image = swapChainImages[i]; // 绑定 VkImage // viewType和format字段指定应如何解释图像数据 // viewType参数指定图像为一维纹理，二维纹理，三维纹理或立方体贴图 createInfo.viewType = VK_IMAGE_VIEW_TYPE_2D; // 图像格式 createInfo.format = swapChainImageFormat; // 图像颜色通道，即RGB和Alpha通道。比如将所有通道映射到红色通道以获得单色纹理，或者将常量值0和1映射到通道。这里选择默认映射: createInfo.components.r = VK_COMPONENT_SWIZZLE_IDENTITY; createInfo.components.g = VK_COMPONENT_SWIZZLE_IDENTITY; createInfo.components.b = VK_COMPONENT_SWIZZLE_IDENTITY; createInfo.components.a = VK_COMPONENT_SWIZZLE_IDENTITY; // subresourceRange字段描述了图像的目的是什么以及应该访问图像的哪个部分。 // 这里图像将用作颜色目标，没有任何mipmapping级别或多个层。 createInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; createInfo.subresourceRange.baseMipLevel = 0; createInfo.subresourceRange.levelCount = 1; createInfo.subresourceRange.baseArrayLayer = 0; createInfo.subresourceRange.layerCount = 1; // 注意，通过vkCreateXXX创建的对象，都需要我们主动去释放 if (vkCreateImageView(device, &amp;createInfo, nullptr, &amp;swapChainImageViews[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create image views!&quot;); &#125; &#125;&#125;void cleanup() &#123; // 释放交换链对应的图像视图 for (auto imageView : swapChainImageViews) &#123; vkDestroyImageView(device, imageView, nullptr); &#125; .....&#125; 有了图像视图足以开始将图像用作纹理，但还不能直接用作渲染目标。需要一个间接步骤，称为帧缓冲，但首先我们必须设置图形管道。 二. 图形管道 Pipeline 简介所谓图形管道就是一系列操作，它们将网格的顶点和纹理一直带到渲染目标中的像素。简化概述如下所示： 输入汇编程序(input assembler): 从指定的缓冲区收集原始顶点数据，也可以使用索引缓冲区重复某些元素，而不必复制顶点数据本身。 顶点着色器(vertex shader): 针对每个顶点运行，并且通常应用变换以将顶点位置从模型空间转换到屏幕空间。它还沿着管道传递每顶点数据。 曲面细分着色器(tessellation shaders): 根据特定规则细分几何体以提高网格质量。通常用于使砖墙和楼梯等表面在附近时看起来不那么平坦。 几何着色器(geometry shader): 在每个基元(三角形，直线，点)上运行，并且可以丢弃它或输出比原来更多的基元。类似于曲面细分着色器，但更灵活。但没有得到太多应用，因为大多数显卡的性能都不是很好。 光栅化阶段(rasterization stage): 将基元离散化为片段。这些是它们填充在帧缓冲区上的像素元素。在屏幕之外的片段都将被丢弃，顶点着色器输出的属性将在片段之间进行插值。由于深度测试，通常在这里也丢弃其他原始片段后面的片段。 片段着色器(fragment shader): 为存活的每个片段调用片段着色器，并确定片段写入哪些帧缓冲区以及使用哪些颜色和深度值。它可以使用来自顶点着色器的插值数据来完成此操作，其中可以包括纹理坐标和法线照明等内容。 颜色混合阶段(color blending stage): 应用操作来混合映射到帧缓冲区中的相同像素的不同片段。 碎片可以简单地相互覆盖，加起来或根据透明度进行混合。 绿色的阶段被称为固定功能阶段。这些阶段允许使用参数调整其操作，但它们的工作方式是预定义的。 橙色的阶段是可编程的，这意味着可以将代码上传到图形卡，以完全应用想要的操作。 例如，实现从纹理和光照到光线跟踪器的任何内容。这些程序同时在许多GPU内核上运行，以并行处理许多对象，如顶点和片段。，可以使用片段着色器 在OpenGL和Direct3D中，可以使用glBlendFunc和OMSetBlendState等调用随意更改任何管道设置。但Vulkan中的图形管道几乎完全不可变，因此如果要更改着色器，绑定不同的帧缓冲区或更改混合函数，则必须从头开始重新创建管道。缺点是您必须创建许多管道，这些管道代表您要在渲染操作中使用的所有状态组合。但是，因为您将在管道中执行的所有操作都是事先知道的，所以驱动程序可以更好地优化它。 根据您的目的，某些可编程阶段是可选的。例如，如果您只是绘制简单几何体，则可以禁用曲面细分和几何体阶段。如果您只对深度值感兴趣，则可以禁用片段着色器阶段，这对阴影贴图生成很有用。 记住创建管道需要在创建VkImageView之后。 具体的创建需要依赖上述各个着色器，我们先熟悉一下这些着色器。 三. 着色器(Shader modules)Vulkan中的着色器代码必须以字节码格式指定，而不是像GLSL和HLSL这样的人类可读语法。 GLSL是一种具有C风格语法的着色语言。写在其中的程序具有为每个对象调用的主函数。 GLSL使用全局变量来处理输入和输出，而不是使用输入参数和返回值作为输出。该语言包括许多有助于图形编程的功能，如内置向量和矩阵基元。包括交叉积，矩阵向量积和向量周围反射等操作的函数。 而Vulkan中的这种字节码格式称为SPIR-V，旨在与Vulkan和OpenCL（两种Khronos API）一起使用。SPIR-V是一种用于图形着色器和计算内核的简单二进制中间语言。 更多信息可以参考 https://www.khronos.org/registry/spir-v/specs/unified1/SPIRV.html 使用字节码格式的优点是比GPU供应商编写的将着色器代码转换为本机代码的编译器要简单的得多。过去已经表明，使用像GLSL这样的人类可读语法，一些GPU供应商对标准的解释相当灵活。如果碰巧使用其中一个供应商编写的不标准GPU着色器，那么由于语法错误，可能其他供应商的驱动程序会拒绝我们的代码，或者更糟糕的，由于编译器错误，着色器运行方式不同。而使用简单的字节码格式，如SPIR-V，则可以避免此类问题。 但是，这并不意味着我们需要手动编写这个字节码。 Khronos发布了自己独立于供应商的编译器，将GLSL编译为SPIR-V。此编译器旨在验证着色器代码是否完全符合标准，并生成一个可与程序一起提供的SPIR-V二进制文件。我们还可以将此编译器作为库包含在运行时生成SPIR-V。这个编译器已经包含在LunarG SDK中作为glslangValidator.exe，无需额外下载。 接下来我们使用GLSL语言(详细参考: https://github.com/wshxbqq/GLSL-Card)编写着色器。 3.1 顶点着色器 Vertex Shader矢量类型称为vec，其数字表示元素的数量。 例如，3D位置将存储在vec3中。可以通过.x等成员访问单个组件，但也可以同时从多个组件创建新的向量。 例如，表达式vec3（1.0,2.0,3.0）.xy将导致vec2。向量的构造函数也可以采用向量对象和标量值的组合。 例如，vec3可以用vec3（vec2（1.0,2.0），3.0）构建。 顶点着色器处理每个传入的顶点。 它将其属性（如世界位置，颜色，法线和纹理坐标）作为输入。输出是剪辑坐标中的最终位置以及需要传递到片段着色器的属性，如颜色和纹理坐标。然后，光栅化器将这些值插入片段上以产生平滑的梯度。剪辑坐标是来自顶点着色器的四维矢量，其随后通过将整个矢量除以其最后一个分量而变为标准化设备坐标。 这些标准化的设备坐标是齐次坐标，它将帧缓冲区映射到[-1,1]乘[-1,1]坐标系，如下所示： 注意xy轴的方向，类似Android中的坐标轴，而不是OpenGL中的坐标轴方向。接下来我们通过顶点着色器和片段着色器以在屏幕上呈现一个三角形,如下图： 我们可以直接输出归一化设备坐标，方法是将它们作为顶点着色器的剪辑坐标输出，最后一个组件设置为1.这样，将剪辑坐标转换为规范化设备坐标的划分不会改变任何东西。通常这些坐标将存储在顶点缓冲区中，但在Vulkan中创建顶点缓冲区并用数据填充它并不简单。如果我们直接在顶点着色器中包含坐标，那么可以这样写： 1234567891011#version 450vec2 positions[3] = vec2[]( vec2(0.0, -0.5), vec2(0.5, 0.5), vec2(-0.5, 0.5));void main() &#123; gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0);&#125; 每个顶点的生成都需要调用main函数。内置的gl_VertexIndex变量包含当前顶点的索引，一般是顶点缓冲区的索引。在这里，它是顶点数据的硬编码数组的索引。从着色器中的常量数组访问每个顶点的位置，并与虚拟z和w组件组合以在剪辑坐标中生成位置，内置变量gl_Position用作输出。 3.2 片段着色器 Fragment Shader由顶点着色器的位置形成的三角形用片段填充屏幕上的区域。在这些片段上调用片段着色器以生成帧缓冲区（或帧缓冲区）的颜色和深度。为整个三角形输出红色的简单片段着色器如下所示： 123456789#version 450#extension GL_ARB_separate_shader_objects : enable// 帧缓冲区的索引为0layout(location = 0) out vec4 outColor;void main() &#123; outColor = vec4(1.0, 0.0, 0.0, 1.0);&#125; GLSL中的颜色是4分量矢量，其中R，G，B和α通道在[0,1]范围内。与顶点着色器中的gl_Position不同，没有内置变量来输出当前片段的颜色。 所以必须为每个帧缓冲区指定自己的输出变量，其中layout（location &#x3D; 0）修饰符指定帧缓冲区的索引。红色将写入此outColor变量，该变量链接到索引0处的第一个（也是唯一的）帧缓冲区。 3.3 为每个顶点着色如果我们想要实现渐变颜色的三角形，如下： 这就需要我们为三个顶点中的每一个指定不同的颜色。 顶点着色器现在应该包含一个颜色的数组，就像它对位置一样. 123456vec3 colors[3] = vec3[]( // vec3(r,g,b) vec3(1.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0), vec3(0.0, 0.0, 1.0)); 每一个vec3对应一个顶点。现在我们只需要将这些顶点颜色传递给片段着色器，这样就可以将它们的插值输出到帧缓冲区。将颜色输出添加到顶点着色器并在main函数中写入： 1234567891011121314#version 450vec2 positions[3] = vec2[]( vec2(0.0, -0.5), vec2(0.5, 0.5), vec2(-0.5, 0.5));layout(location = 0) out vec3 fragColor;void main() &#123; gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0); fragColor = colors[gl_VertexIndex];&#125; 接下来，我们需要在片段着色器中添加匹配的输入： 123456789#version 450#extension GL_ARB_separate_shader_objects : enable// 帧缓冲区的索引为0layout(location = 0) in vec3 fragColor;void main() &#123; outColor = vec4(fragColor, 1.0);&#125; 输入变量不一定必须使用相同的名称，因为我们使用location指令指定的索引讲它们链接在一起。如上图所示，fragColor的值将自动插入三个顶点之间的片段，从而产生平滑的渐变。 3.4 编译着色器首先在我们的工程目录下创建一个 shaders 的目录，用于保存我们的着色器。首先是 shader.vert 文件： 123456789101112131415161718192021222324#version 450#extension GL_ARB_separate_shader_objects : enable// 输出为fragColorlayout(location = 0) out vec3 fragColor;// 三角形顶点坐标vec2 positions[3] = vec2[]( vec2(0.0, -0.5), vec2(0.5, 0.5), vec2(-0.5, 0.5));// 渐变颜色vec3 colors[3] = vec3[]( vec3(1.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0), vec3(0.0, 0.0, 1.0));void main() &#123; gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0); fragColor = colors[gl_VertexIndex];&#125; 还有 shader.frag 文件: 12345678910#version 450#extension GL_ARB_separate_shader_objects : enablelayout(location = 0) in vec3 fragColor;layout(location = 0) out vec4 outColor;void main() &#123; outColor = vec4(fragColor, 1.0);&#125; 3.4.1 Linux平台下编译方式使用 vulkan SDK中的glslangValidator来编译shader文件: 1234#/home/user/VulkanSDK/x.x.x.x/x86_64/bin/glslangValidator -V shader.vert#/home/user/VulkanSDK/x.x.x.x/x86_64/bin/glslangValidator -V shader.frag/home/jh/Program/vulkan/1.1.106.0/x86_64/bin/glslangValidator -V shader.vert/home/jh/Program/vulkan/1.1.106.0/x86_64/bin/glslangValidator -V shader.frag 执行上面的脚本后，会在当前目录生成对应的: frag.spv和vert.spv文件 3.4.2 Windows平台编译方式类似，不赘述 另外Vulkan SDK包含libshaderc库，用于从程序中将GLSL代码编译为SPIR-V。 3.5 加载着色器加载着色器就是读取我们编译好的shader文件:frag.spv和vert.spv.c++中读取文件如下： 1234567891011121314151617181920#include &lt;fstream&gt;static std::vector&lt;char&gt; readFile(const std::string&amp; filename) &#123; // ate: 从文件末尾开始阅读 // binary: 二进制流形式 std::ifstream file(filename, std::ios::ate | std::ios::binary); if (!file.is_open()) &#123; throw std::runtime_error(&quot;failed to open file!&quot;); &#125; size_t fileSize = (size_t) file.tellg(); std::vector&lt;char&gt; buffer(fileSize); file.seekg(0); file.read(buffer.data(), fileSize); file.close(); return buffer;&#125; 比如读取 vert.spv: 1auto vertShaderCode = readFile(&quot;shaders/vert.spv&quot;); 读取成功后，记得check一下文件大小是否匹配。 3.6 创建着色器模块(shader modules - VkShaderModule)在Vulkan中使用VkShaderModule存储着色器. 使用结构体： 1234567typedef struct VkShaderModuleCreateInfo &#123; VkStructureType sType; const void* pNext; VkShaderModuleCreateFlags flags; size_t codeSize; const uint32_t* pCode;&#125; VkShaderModuleCreateInfo; 封装成createShaderModule方法,方便后续调用.其实VkShaderModule只是一个对着色器文件的封装而已。使用方法：vkCreateShaderModule 123456789101112131415VkShaderModule createShaderModule(const std::vector&lt;char&gt;&amp; code) &#123; VkShaderModuleCreateInfo createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO; createInfo.codeSize = code.size(); createInfo.pCode = reinterpret_cast&lt;const uint32_t*&gt;(code.data()); VkShaderModule shaderModule; // vkResult device, const *pCreateInfo, const VkAllocationCallbacks *pAllocator, VkShaderModule *pShaderModule) if (vkCreateShaderModule(device, &amp;createInfo, nullptr, &amp;shaderModule) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create shader module!&quot;); &#125; return shaderModule;&#125; 3.7 着色器阶段创建(shader stage)只是有 VkShaderModule，还不够。要使用着色器，还需要在创建管道(Pipeline)时，使用VkPipelineShaderStageCreateInfo结构讲其分配到特定的管道阶段。比如在管道中填充顶点着色器: vert.spv 123456789VkPipelineShaderStageCreateInfo vertShaderStageInfo = &#123;&#125;;vertShaderStageInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;vertShaderStageInfo.stage = VK_SHADER_STAGE_VERTEX_BIT; // 指明当前是顶点阶段 (3.7.1)// 指定包含代码的着色器模块vertShaderStageInfo.module = vertShaderModule;// 指定要调用的着色器模块函数（称为入口点）vertShaderStageInfo.pName = &quot;main&quot;; 还有一个（可选的）成员pSpecializationInfo，这里不会在这里使用。它允许您指定着色器常量的值。当使用单个着色器模块，通过为其中使用的常量指定不同的值，就可以在创建管道时配置其行为。这比在渲染时使用变量配置着色器更有效，因为编译器可以执行优化，例如消除依赖于这些值的if语句。默认为nullptr，struct初始化会自动执行。 3.7.1 Shader Stage1234567891011typedef enum VkShaderStageFlagBits &#123; VK_SHADER_STAGE_VERTEX_BIT = 0x00000001, VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT = 0x00000002, VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT = 0x00000004, VK_SHADER_STAGE_GEOMETRY_BIT = 0x00000008, VK_SHADER_STAGE_FRAGMENT_BIT = 0x00000010, VK_SHADER_STAGE_COMPUTE_BIT = 0x00000020, VK_SHADER_STAGE_ALL_GRAPHICS = 0x0000001F, VK_SHADER_STAGE_ALL = 0x7FFFFFFF, VK_SHADER_STAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkShaderStageFlagBits; VK_SHADER_STAGE_VERTEX_BIT: 顶点阶段 VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT: 曲面细分控制阶段 VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT: 曲面细分评估阶段 VK_SHADER_STAGE_GEOMETRY_BIT: 几何阶段 VK_SHADER_STAGE_FRAGMENT_BIT: 片段阶段 VK_SHADER_STAGE_COMPUTE_BIT: 计算阶段 VK_SHADER_STAGE_ALL_GRAPHICS: 用作速记的位组合，用于指定上面定义的所有图形阶段（不包括计算阶段）。 VK_SHADER_STAGE_FLAG_BITS_MAX_ENUM: 用作速记的位组合，用于指定设备支持的所有着色器阶段，包括扩展引入的所有其他阶段。 3.7.2 为着色器指定管道1234567891011121314void createGraphicsPipeline() &#123; auto vertShaderCode = readFile(&quot;shaders/vert.spv&quot;); auto fragShaderCode = readFile(&quot;shaders/frag.spv&quot;); VkShaderModule vertShaderModule = createShaderModule(vertShaderCode); VkShaderModule fragShaderModule = createShaderModule(fragShaderCode); // 这里为管道指定着色器 VkPipelineShaderStageCreateInfo shaderStages[] = &#123;vertShaderStageInfo, fragShaderStageInfo&#125;; // 记得销毁shader vkDestroyShaderModule(device, vertShaderModule, nullptr); vkDestroyShaderModule(device, fragShaderModule, nullptr);&#125; 图形管道 其他部分设置在下个文章中讨论。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(4)-Surface和交换链","slug":"Vulkan入门-4-Surface和交换链","date":"2022-02-26T19:21:25.000Z","updated":"2022-02-26T19:25:56.402Z","comments":true,"path":"2022/02/27/Vulkan入门-4-Surface和交换链/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-4-Surface%E5%92%8C%E4%BA%A4%E6%8D%A2%E9%93%BE/","excerpt":"简述本文主要是学习Vulkan Tutorial.pdf文档中的Window Surface和Swap Chain的部分。","text":"简述本文主要是学习Vulkan Tutorial.pdf文档中的Window Surface和Swap Chain的部分。 参考资料 [Vulkan-文档]https://github.com/KhronosGroup/Vulkan-Docs 一. Window Surface由于Vulkan是一个与平台无关的API，因此无法直接与窗口系统进行交互。要在Vulkan和窗口系统之间建立连接以向屏幕显示结果，我们需要使用WSI（窗口系统集成）扩展。这就需要使用到VK_KHR_surface，它公开了一个VkSurfaceKHR对象，表示一个抽象类型的Surface，以呈现渲染图像。我们程序中的Surface将由我们已经使用GLFW打开的窗口支持。VK_KHR_surface扩展是一个实例级扩展，我们实际上已经启用它，因为它包含在glfwGetRequiredInstanceExtensions返回的列表中。 一般需要在创建实例后立即创建窗口Surface，因为它实际上可以影响物理设备选择。但如果你只需要离屏渲染，窗口Surface是Vulkan中完全可选的组件。 Vulkan允许这样做，而不是像OpenGL一样必须创建一个不可见的窗口。 1.1 创建窗口Surface在Vulkan中使用VkSurfaceKHR表示窗口Surface： 1VkSurfaceKHR surface; 虽然VkSurfaceKHR对象及其用法与平台无关，但它的创建并不是因为它取决于窗口系统的细节。例如，它需要Windows上的HWND和HMODULE句柄。因此，扩展中有一个特定于平台的添加，在Windows上称为VK_KHR_win32_surface，并且还自动包含在glfwGetRequiredInstanceExtensions的列表中。但使用像GLFW这样的库然后继续使用特定于平台的代码没有任何意义。GLFW实际上有glfwCreateWindowSurface来帮我们处理平台的差异。 12345678910111213 // 使用glfw创建WindowSurface void createWindowSurface() &#123; if (glfwCreateWindowSurface(instance, window, nullptr, &amp;surface) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create window surface!&quot;); &#125; &#125; // 记得释放 void cleanup() &#123; // 释放WindowSurface vkDestroySurfaceKHR(instance, surface, nullptr); ...... &#125; 二. Swap Chain-交换链Vulkan没有“默认帧缓冲区”的概念，取而代之的是名为 “swap chain” 即交换链，也就是渲染的缓冲区，必须在Vulkan中明确创建。交换链本质上是一个等待呈现给屏幕的图像队列。应用程序将获取这样的图像以绘制它，然后将其返回到队列中。队列的工作原理以及从队列中显示图像的条件取决于交换链的设置方式，但交换链的一般用途是将图像的显示与屏幕的刷新率同步。 2.1 检查GPU是否支持交换链并不是所有的GPU都支持图像显示(比如专为服务器设计的)，其次，由于图像显示严重依赖于窗口系统和与窗口相关的Surface，因此它实际上不是Vulkan核心的一部分。所以必须在查询其支持后才能启用K_KHR_swapchain设备扩展。 可以扩展isDeviceSuitable函数以检查是否支持此扩展。之前已经实现过如何列出VkPhysicalDevice支持的扩展，这样做法其实一样。值得注意的是，Vulkan头文件提供了一个很好的宏VK_KHR_SWAPCHAIN_EXTENSION_NAME，定义为VK_KHR_swapchain。使用此宏的优点是编译器将捕获拼写错误。首先声明所需设备扩展的列表，类似于要启用的验证层列表。 12345678910111213141516171819202122232425262728const std::vector&lt;const char*&gt; deviceExtensions = &#123; VK_KHR_SWAPCHAIN_EXTENSION_NAME&#125;;bool isDeviceSuitable(VkPhysicalDevice device) &#123; QueueFamilyIndices indices = findQueueFamilies(device); bool extensionsSupported = checkDeviceExtensionSupport(device); return indices.isComplete() &amp;&amp; extensionsSupported; &#125;bool checkDeviceExtensionSupport(VkPhysicalDevice device) &#123; uint32_t extensionCount; vkEnumerateDeviceExtensionProperties(device, nullptr, &amp;extensionCount, nullptr); std::vector&lt;VkExtensionProperties&gt; availableExtensions(extensionCount); vkEnumerateDeviceExtensionProperties(device, nullptr, &amp;extensionCount, availableExtensions.data()); std::set&lt;std::string&gt; requiredExtensions(deviceExtensions.begin(), deviceExtensions.end()); // 遍历当前所有可支持的扩展，并逐步移除也存在于deviceExtensions中的 for (const auto&amp; extension : availableExtensions) &#123; requiredExtensions.erase(extension.extensionName); &#125; // 为empty时，表示所有deviceExtensions中的扩展均支持 return requiredExtensions.empty();&#125; 2.2 使能设备扩展使用交换链需要首先使能VK_KHR_swapchain扩展。方法也很简单，只需要在创建逻辑设备的时候声明一下即可： 12createInfo.enabledExtensionCount = static_cast&lt;uint32_t&gt;(deviceExtensions.size());createInfo.ppEnabledExtensionNames = deviceExtensions.data(); 2.3 获取关于swap chain更多支持细节只检查交换链是否可用是不够的，因为它实际上可能与我们创建的窗口Surface不兼容（有点坑）。创建交换链还涉及比vulkan实例和设备创建时更多的设置，因此我们需要在能够继续之前查明更多的细节。需要检查的基本上有以下三种属性： 基本Surface功能（交换链中的最小&#x2F;最大图像数，图像的最小&#x2F;最大宽度和高度） Surface的格式（像素格式，色彩空间） 可用的呈现模式 与创建队列类似，同样可以使用一个结构体来存储传递这些细节部分： 12345struct SwapChainSupportDetails &#123; VkSurfaceCapabilitiesKHR capabilities; // 基本Surface功能 std::vector&lt;VkSurfaceFormatKHR&gt; formats; // Surface格式 std::vector&lt;VkPresentModeKHR&gt; presentModes; // 可用的呈现模式(presentation modes)&#125;; 接来下是查询细节部分： 123456789101112131415161718192021222324252627SwapChainSupportDetails querySwapChainSupport(VkPhysicalDevice device) &#123; SwapChainSupportDetails details; // 1. 查询基本Surface功能 // 需要使用到本机物理设备(GPU), 以及创建的逻辑设备对应的Surface，结果保存在VkSurfaceCapabilitiesKHR结构体中 // VkResult vkGetPhysicalDeviceSurfaceCapabilitiesKHR(VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, VkSurfaceCapabilitiesKHR *pSurfaceCapabilities) vkGetPhysicalDeviceSurfaceCapabilitiesKHR(device, surface, &amp;details.capabilities); // 2. 查询可支持的Surface格式 // 类似扩展，按例先查询一下数量，然后更新细节到VkSurfaceFormatKHR的队列中 uint32_t formatCount; vkGetPhysicalDeviceSurfaceFormatsKHR(device, surface, &amp;formatCount, nullptr); if (formatCount != 0) &#123; details.formats.resize(formatCount); vkGetPhysicalDeviceSurfaceFormatsKHR(device, surface, &amp;formatCount, details.formats.data()); &#125; // 3. 查询可用的呈现模式(presentation modes) uint32_t presentModeCount; vkGetPhysicalDeviceSurfacePresentModesKHR(device, surface, &amp;presentModeCount, nullptr); if (presentModeCount != 0) &#123; details.presentModes.resize(presentModeCount); vkGetPhysicalDeviceSurfacePresentModesKHR(device, surface, &amp;presentModeCount, details.presentModes.data()); &#125; return details;&#125; 2.4 为swap chain-交换链选择合适的设置满足了swapChainAnequate条件，那么物理设备肯定是支持我们的应用程序的，但还可以有许多不同的最优性模式。有三种类型的设置可以选择： Surface格式（颜色深度） 呈现模式（将图像“交换”到屏幕的条件） 交换范围（交换链中图像的分辨率） 2.4.1 Surface格式在Vulkan中，Surface格式使用结构体 VkSurfaceFormatKHR 来表示: 1234typedef struct VkSurfaceFormatKHR &#123; VkFormat format; // 格式 VkColorSpaceKHR colorSpace; // 色彩空间&#125; VkSurfaceFormatKHR; 如上每个VkSurfaceFormatKHR条目都包含一个格式和一个colorSpace成员。 格式成员指定颜色通道和类型。例如，VK_FORMAT_B8G8R8A8_UNORM意味着我们以8位无符号整数的顺序存储B，G，R和alpha通道，每个像素总共32位。 colorSpace成员使用VK_COLOR_SPACE_SRGB_NONLINEAR_KHR标志指示是否支持SRGB色彩空间。请注意，在旧版本的规范中，此标志曾被称为VK_COLORSPACE_SRGB_NONLINEAR_KHR。对于色彩空间，我们将使用SRGB（如果可用），因为它会产生更准确的感知色彩。直接使用SRGB颜色有点挑战，因此我们将使用标准RGB作为颜色格式，其中最常见的一种是VK_FORMAT_B8G8R8A8_UNORM。 最好的情况是 Surface 没有首选格式，Vulkan只通过返回一个格式成员设置为VK_FORMAT_UNDEFINED的VkSurfaceFormatKHR条目来指示。 1234567891011121314151617// 选择合适交换链和Surface的格式VkSurfaceFormatKHR chooseSwapSurfaceFormat(const std::vector&lt;VkSurfaceFormatKHR&gt;&amp; availableFormats) &#123; if (availableFormats.size() == 1 &amp;&amp; availableFormats[0].format == VK_FORMAT_UNDEFINED) &#123; return &#123;VK_FORMAT_B8G8R8A8_UNORM, VK_COLOR_SPACE_SRGB_NONLINEAR_KHR&#125;; &#125; for (const auto&amp; availableFormat : availableFormats) &#123; if (availableFormat.format == VK_FORMAT_B8G8R8A8_UNORM &amp;&amp; availableFormat.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR) &#123; return availableFormat; &#125; &#125; // 如果没有找到合适的，保险起见，直接使用第一个就好了 return availableFormats[0];&#125; 2.4.2 呈现模式(Presentation Mode)呈现模式可以说是交换链中最重要的设置，因为它代表了向屏幕显示图像的实际条件。Vulkan有四种可用的模式： VK_PRESENT_MODE_IMMEDIATE_KHR：应用程序提交的图像会立即传输到屏幕上，这可能会导致撕裂现象(上下或者左右图像不匹配，前后两帧合成)。 VK_PRESENT_MODE_FIFO_KHR：交换链是一个队列，当刷新显示并且程序在队列的后面插入渲染图像时，显示从队列前面获取图像。如果队列已满，则程序必须等待。这与现代游戏中的垂直同步最相似。刷新显示的那一刻被称为“垂直空白”。 VK_PRESENT_MODE_FIFO_RELAXED_KHR：如果应用程序延迟且队列在最后一个垂直空白处为空，则此模式仅与前一个模式不同。而不是等待下一个垂直空白，图像最终到达时立即传输。这可能会导致明显的撕裂。 VK_PRESENT_MODE_MAILBOX_KHR：这是第二种模式的另一种变体。当队列已满时，已排队的图像将被替换为较新的图像，而不是阻塞应用程序。此模式可用于实现三重缓冲，与使用双缓冲的标准垂直同步相比，可以避免使用明显更少的延迟问题进行撕裂。 比如我们试试机器是否支持三重缓冲, 即允许我们通过渲染尽可能最新的新图像直到垂直空白来避免撕裂，同时仍保持相当低的延迟: 123456789101112VkPresentModeKHR chooseSwapPresentMode(const std::vector&lt;VkPresentModeKHR&gt;&amp; availablePresentModes) &#123; VkPresentModeKHR bestMode = VK_PRESENT_MODE_FIFO_KHR; for (const auto&amp; availablePresentMode : availablePresentModes) &#123; if (availablePresentMode == VK_PRESENT_MODE_MAILBOX_KHR) &#123; return availablePresentMode; &#125; else if (availablePresentMode == VK_PRESENT_MODE_IMMEDIATE_KHR) &#123; bestMode = availablePresentMode; &#125; &#125; return bestMode;&#125; 2.4.3 交换范围(Swap extent)交换范围是交换链图像的分辨率，它几乎总是完全等于绘制的窗口的分辨率。可能的分辨率范围在 VkSurfaceCapabilitiesKHR 结构中定义。 Vulkan通过在currentExtent成员中设置宽度和高度来匹配窗口的分辨率。但是，一些窗口管理器允许在这里有所不同, 通过将currentExtent中的宽度和高度设置为特殊值来表示：uint32_t的最大值。在这种情况下，要选择与minImageExtent和maxImageExtent范围内的窗口最匹配的分辨率。 1234567891011// 选择交换链分辨率VkExtent2D chooseSwapExtent(const VkSurfaceCapabilitiesKHR&amp; capabilities) &#123; if (capabilities.currentExtent.width != std::numeric_limits&lt;uint32_t&gt;::max()) &#123; return capabilities.currentExtent; &#125; else &#123; VkExtent2D actualExtent = &#123;WIDTH, HEIGHT&#125;; actualExtent.width = std::max(capabilities.minImageExtent.width, std::min(capabilities.maxImageExtent.width, actualExtent.width)); actualExtent.height = std::max(capabilities.minImageExtent.height, std::min(capabilities.maxImageExtent.height, actualExtent.height)); return actualExtent; &#125;&#125; 2.5 创建交换链上述步骤已经把创建交换链的三个主要属性设置了，接下来就是创建交换链对象：VkSwapchainKHR swapChain;除了上述的三个主要属性，其实还需要做的是： 绑定窗口Surface 设置交换链图像细节，包括最小图像数量、图像图层数量 处理将在多个队列系列中使用的交换链图像。如果图形队列系列与呈现队列不同，需要从图形队列中绘制交换链中的图像，然后在呈现队列中提交它们。 有两种方法可以处理从多个队列访问的图像： VK_SHARING_MODE_EXCLUSIVE：映像一次由一个队列系列拥有，并且必须在将其用于另一个队列系列之前显式转移所有权。 此选项提供最佳性能。 VK_SHARING_MODE_CONCURRENT：可以跨多个队列系列使用映像，而无需显式所有权传输。 类似创建其他对象，交换链的创建依赖结构体：VkSwapchainCreateInfoKHR 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667void createSwapChain() &#123; // 获取物理设备可支持的交换链细节部分 SwapChainSupportDetails swapChainSupport = querySwapChainSupport(physicalDevice); // 选择合适的Surface格式 VkSurfaceFormatKHR surfaceFormat = chooseSwapSurfaceFormat(swapChainSupport.formats); // 选择合适的呈现模式 VkPresentModeKHR presentMode = chooseSwapPresentMode(swapChainSupport.presentModes); // 选择合适的分辨率 VkExtent2D extent = chooseSwapExtent(swapChainSupport.capabilities); // 必须设置交换链运行所需的最小图像数量： // 有时可能必须等待驱动程序完成内部操作才能获取另一个要渲染的图像。 因此，建议最小值加1： uint32_t imageCount = swapChainSupport.capabilities.minImageCount + 1; // 边界检查，防止越界，超出交换链可支持的最大图像数量 if (swapChainSupport.capabilities.maxImageCount &gt; 0 &amp;&amp; imageCount &gt; swapChainSupport.capabilities.maxImageCount) &#123; imageCount = swapChainSupport.capabilities.maxImageCount; &#125; // 创建交换链对象 VkSwapchainCreateInfoKHR createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR; createInfo.surface = surface; // 绑定窗口Surface createInfo.minImageCount = imageCount; // 设置最小图像数量 createInfo.imageFormat = surfaceFormat.format; // 设置图像格式 createInfo.imageColorSpace = surfaceFormat.colorSpace; // 设置图像颜色空间 createInfo.imageExtent = extent; // 设置分辨率 createInfo.imageArrayLayers = 1; // 指定每个图像所包含的图层数量, 除非是立体3D应用程序，否则始终为1。 // imageUsage 是 VkImageUsageFlags 类型, 指定将使用交换链中的图像进行哪种操作 createInfo.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT; // 指定该图像可用于创建适合用作颜色的VkImageView或解析VkFramebuffer中的附件。 QueueFamilyIndices indices = findQueueFamilies(physicalDevice); uint32_t queueFamilyIndices[] = &#123;indices.graphicsFamily.value(), indices.presentFamily.value()&#125;; if (indices.graphicsFamily != indices.presentFamily) &#123; createInfo.imageSharingMode = VK_SHARING_MODE_CONCURRENT; createInfo.queueFamilyIndexCount = 2; createInfo.pQueueFamilyIndices = queueFamilyIndices; &#125; else &#123; createInfo.imageSharingMode = VK_SHARING_MODE_EXCLUSIVE; createInfo.queueFamilyIndexCount = 0; // Optional createInfo.pQueueFamilyIndices = nullptr; // Optional &#125; // 可以指定某个变换应该应用于交换链中的图像（支持变换功能），如顺时针旋转90度或水平翻转。 要指定您不需要任何转换，只需指定当前转换。 createInfo.preTransform = swapChainSupport.capabilities.currentTransform; // compositeAlpha字段指定是否应该使用alpha通道与窗口系统中的其他窗口进行混合。 一般都是忽略alpha通道，因此设置为VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR。 createInfo.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR; // 设置呈现模式 createInfo.presentMode = presentMode; // 如果剪裁的成员设置为VK_TRUE，那么这意味着我们不关心被遮挡的像素的颜色 // 例如因为另一个窗口位于它们前面。 除非真的需要能够读回这些像素并获得可预测的结果，否则可以通过启用剪辑获得最佳性能。 createInfo.clipped = VK_TRUE; // 使用Vulkan时，交换链可能会在应用程序运行时变为无效或未优化，例如因为窗口已调整大小。 // 在这种情况下，交换链实际上需要从头开始重新创建，并且必须在此字段中指定对旧交换链的引用, 后续在研究。 // 假设我们只会创建一个交换链 createInfo.oldSwapchain = VK_NULL_HANDLE; if (vkCreateSwapchainKHR(device, &amp;createInfo, nullptr, &amp;swapChain) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create swap chain!&quot;); &#125;&#125; 2.5.1 VkImageUsageFlagsVkImageUsageFlags是一个位掩码类型，用于设置零或更多VkImageUsageFlagBits的掩码。用于指定图像进行的操作类型, 有如下 1234567891011typedef enum VkImageUsageFlagBits &#123; VK_IMAGE_USAGE_TRANSFER_SRC_BIT = 0x00000001, VK_IMAGE_USAGE_TRANSFER_DST_BIT = 0x00000002, VK_IMAGE_USAGE_SAMPLED_BIT = 0x00000004, VK_IMAGE_USAGE_STORAGE_BIT = 0x00000008, VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT = 0x00000010, VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT = 0x00000020, VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT = 0x00000040, VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT = 0x00000080, VK_IMAGE_USAGE_FLAG_BITS_MAX_ENUM = 0x7FFFFFFF&#125; VkImageUsageFlagBits; VK_IMAGE_USAGE_TRANSFER_SRC_BIT: 指定图像可用作传输命令的源。 VK_IMAGE_USAGE_TRANSFER_DST_BIT: 指定图像可用作传输命令的目标。 VK_IMAGE_USAGE_SAMPLED_BIT: 指定该图像可用于创建适合占用VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE或VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER类型的VkDescriptorSet槽的VkImageView，并由着色器进行采样。 VK_IMAGE_USAGE_STORAGE_BIT: 指定该图像可用于创建适合占用VK_DESCRIPTOR_TYPE_STORAGE_IMAGE类型的VkDescriptorSet插槽的VkImageView。 VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT: 指定该图像可用于创建适合用作颜色的VkImageView或解析VkFramebuffer中的附件。 VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT: 指定该图像可用于创建适合用作VkFramebuffer中的深度&#x2F;模板附件的VkImageView。 VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT: 指定绑定到此映像的内存将使用VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT进行分配。可以为任何可用于创建适合用作颜色，分辨率，深度&#x2F;模板或输入附件的VkImageView的图像设置此位。 VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT: 指定该图像可用于创建适合占用VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT类型的VkDescriptorSet槽的VkImageView; 从着色器读取作为输入附件; 并用作帧缓冲区中的输入附件。 2.5.2 处理将在多个队列系列中使用的交换链图像如果队列系列不同，那么需要使用并发模式来避免必须执行所有权。并发模式要求使用queueFamilyIndexCount和pQueueFamilyIndices参数预先指定将共享哪些队列系列所有权。如果图形队列系列和表示队列系列是相同的（大多数硬件都是这种情况），那么我们应该坚持独占模式，因为并发模式要求指定至少两个不同的队列系列。 2.6 检索交换链图像创建了交换链对象后，就可以检索其中的VkImages的句柄，这些VkImages是用于后续渲染操作的。我们可以使用一个Set集合存储这些VkImages: 1std::vector&lt;VkImage&gt; swapChainImages; 类似于Surface, 这些VkImage是不需要我们主动销毁的。在交换链被销毁时，Vulkan自动就会销毁这些VkImage了。 一般在vkCreateSwapchainKHR调用之后立即检索createSwapChain函数末尾的句柄。在交换链中只是指定了最少数量的图像，Vulkan允许实现创建更多的图像。创建后记得调整容器大小，最后再次调用它来检索VkImage。 123456// 先获取交换链中图像数量vkGetSwapchainImagesKHR(device, swapChain, &amp;imageCount, nullptr);// 调整set集合大小swapChainImages.resize(imageCount);// 获取VkImage对象vkGetSwapchainImagesKHR(device, swapChain, &amp;imageCount, swapChainImages.data()); 2.7 小结这部分内容比较多，小结一下： 2.7.1 什么是交换链？交换链本质上是一个等待呈现给屏幕的图像队列。应用程序将获取这样的图像以绘制它，然后将其返回到队列中。 2.7.2 创建交换链的一般步骤 确认当前物理设备(GPU)是否支持交换链 创建逻辑设备时，使能交换链扩展(ppEnabledExtensionNames) 获取当前设备支持swap chain的更多细节 创建swap chain对象 绑定窗口Surface 设置最小图像数量 minImageCount 选择合适的图像格式 imageFormat 选择合适的图像颜色空间 imageColorSpace 选择合适的图像分辨率 imageExtent 设置图像图层 imageArrayLayers 设置图像操作方式 imageUsage 选择图像呈现模式 presentMode 是否需要裁剪功能 clipped(VK_TRUE, VK_FALSE) 设置旧交换链的引用 oldSwapchain 获取交换链图像(VkImage)对象集合 虽然到目前为止，我们编出来的程序还只是一个800*600的黑窗口。但是已经万事具备了，下一步就可以把图像内容呈现到窗口里了。","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(3)-设置物理设备和逻辑设备","slug":"Vulkan入门-3-设置物理设备和逻辑设备","date":"2022-02-26T19:16:37.000Z","updated":"2022-02-26T19:20:43.723Z","comments":true,"path":"2022/02/27/Vulkan入门-3-设置物理设备和逻辑设备/","link":"","permalink":"https://swallowjoe.github.io/2022/02/27/Vulkan%E5%85%A5%E9%97%A8-3-%E8%AE%BE%E7%BD%AE%E7%89%A9%E7%90%86%E8%AE%BE%E5%A4%87%E5%92%8C%E9%80%BB%E8%BE%91%E8%AE%BE%E5%A4%87/","excerpt":"简述本文主要是学习Vulkan Tutorial.pdf文档中的Physical devices and queue families(物理设备和队列系列)部分以及Logical device and queues(逻辑设备与队列)部分。","text":"简述本文主要是学习Vulkan Tutorial.pdf文档中的Physical devices and queue families(物理设备和队列系列)部分以及Logical device and queues(逻辑设备与队列)部分。 参考资料 [Vulkan-文档]https://github.com/KhronosGroup/Vulkan-Docs [Vulkan-feature查询]https://vulkan.lunarg.com/doc/view/1.0.26.0/linux/vkspec.chunked/ch31s01.html 一. Physical devices and queue families(物理设备和队列系列)1.1 选择物理显卡GPU在通过VkInstance初始化Vulkan库之后，需要在系统中查找并选择支持我们所需功能的图形显卡。事实上，我们可以选择任意数量的显卡并同时使用。但在这里，只使用第一个适合我们需求的显卡。我们将添加一个函数pickPhysicalDevice并在initVulkan函数中添加对它的调用。 12345678910111213void initVulkan() &#123; checkAvailableExtensions(); createInstance(); // 创建DEBUG消息回调 setupDebugMessenger(); // 选择物理设备 pickPhysicalDevice();&#125;void pickPhysicalDevice() &#123; &#125; 最终选择的图形卡将存储在VkPhysicalDevice句柄中，该句柄作为新的类成员添加。当VkInstance被销毁时，该对象将被隐式销毁，因此我们不需要在清理函数中做任何新的操作。 VkPhysicalDevice对象不能被显式销毁。相反，当检索到它们的VkInstance对象被撤销时，它们将隐式撤销。 一旦所有由VkPhysicalDevice对象创建的VkDevice对象都被销毁，VkInstance对象就可以被销毁。 1VkPhysicalDevice physicalDevice = VK_NULL_HANDLE; 列出物理显卡的过程和列出vulkan扩展的过程类似，首先是获取本机物理显卡的数量： 123456789101112131415161718192021222324252627void pickPhysicalDevice() &#123; uint32_t deviceCount = 0; // 首先获取本机物理显卡数量 vkEnumeratePhysicalDevices(instance, &amp;deviceCount, nullptr); // 当然没有GPU时，抛出异常 if (deviceCount == 0) &#123; throw std::runtime_error(&quot;failed to find GPUs with Vulkan support!&quot;); &#125; std::vector&lt;VkPhysicalDevice&gt; devices(deviceCount); vkEnumeratePhysicalDevices(instance, &amp;deviceCount, devices.data()); // 遍历所有GPU, 选择合适的使用 for (const auto&amp; device : devices) &#123; if (isDeviceSuitable(device)) &#123; physicalDevice = device; break; &#125; &#125;&#125;bool isDeviceSuitable(VkPhysicalDevice device) &#123; // 暂时没什么可以挑剔的，都可以吧 // 其实大部分的机器只会有一个显卡 return true;&#125; 1.2 基础设备适配性检查通过查询细节来评估设备的适用性。可以使用vkGetPhysicalDeviceProperties查询基本设备属性，如名称，类型和支持的Vulkan版本。 12VkPhysicalDeviceProperties deviceProperties;vkGetPhysicalDeviceProperties(device, &amp;deviceProperties); 使用vkGetPhysicalDeviceFeatures查询对纹理压缩，64位浮点和多视口渲染（对VR有用）等可选功能的支持： 12VkPhysicalDeviceFeatures deviceFeatures;vkGetPhysicalDeviceFeatures(device, &amp;deviceFeatures); 基本操作就是： 通过vkGetPhysicalDeviceProperties获取本机设备的属性 查询vkGetPhysicalDeviceFeatures中可以被支持的feature 举个例子，假设我们的应用程序仅适用于支持几何着色器的专用显卡。 那么isDeviceSuitable函数将如下所示： 12345678910bool isDeviceSuitable(VkPhysicalDevice device) &#123; VkPhysicalDeviceProperties deviceProperties; VkPhysicalDeviceFeatures deviceFeatures; vkGetPhysicalDeviceProperties(device, &amp;deviceProperties); vkGetPhysicalDeviceFeatures(device, &amp;deviceFeatures); return ((deviceProperties.deviceType == VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU) &amp;&amp; deviceFeatures.geometryShader);&#125; 所有可支持的feature见附录。根据Vulkan Tutorial文档，有推荐使用评分机制来选择最合适的GPU，这个就见仁见智，看个人喜好，这里就不赘述了。 1.3 Queue families几乎所有Vulkan中的操作，从绘图到上传纹理，都需要将命令提交到队列中(这一点研究过hwui的童鞋肯定深有体会)。存在来自不同队列系列的不同类型的队列，并且每个队列族仅允许命令的子集。例如，可能存在仅允许处理计算命令的队列系列或仅允许与存储器传输相关的命令的队列系列。 所有我们需要检查本机设备支持哪些队列系列，以及哪一个支持我们要使用的命令。添加一个新函数findQueueFamilies，用于查找我们需要的所有队列系列。比如查找支持图形命令的队列： 123456789101112131415161718192021222324252627282930313233343536373839404142struct QueueFamilyIndices &#123; // 别忘了添加头文件：including &lt;optional&gt; // optional用途如其名，它可以容纳一个对象值或是为空。 // 典型的应用情景是函数调用时，如需根据条件返回一个对象（有效）或默认对象（无效） // 若该对象构造成本很高（资源分配等），可用optional返回一个空对象，提高效率。 std::optional&lt;uint32_t&gt; graphicsFamily; bool isComplete() &#123; return graphicsFamily.has_value(); &#125;&#125;;QueueFamilyIndices findQueueFamilies(VkPhysicalDevice device) &#123; QueueFamilyIndices indices; // 先检查数量 uint32_t queueFamilyCount = 0; // 使用 vkGetPhysicalDeviceQueueFamilyProperties 检索队列系列是否正是我们需要的： vkGetPhysicalDeviceQueueFamilyProperties(device, &amp;queueFamilyCount, nullptr); // VkQueueFamilyProperties结构包含有关队列系列的一些详细信息 // 包括支持的操作类型以及可基于该系列创建的队列数 std::vector&lt;VkQueueFamilyProperties&gt; queueFamilies(queueFamilyCount); vkGetPhysicalDeviceQueueFamilyProperties(device, &amp;queueFamilyCount, queueFamilies.data()); // 比如我们找到一个支持VK_QUEUE_GRAPHICS_BIT的队列系列 int i = 0; for (const auto&amp; queueFamily : queueFamilies) &#123; if (queueFamily.queueCount &gt; 0 &amp;&amp; queueFamily.queueFlags &amp; VK_QUEUE_GRAPHICS_BIT) &#123; indices.graphicsFamily = i; &#125; if (indices.isComplete()) &#123; break; &#125; i++; &#125; return indices;&#125; 把这个检查加入isDeviceSuitable函数。现在已经找到合适的物理设备了， 下一步是创建一个与之适配的逻辑设备。 二. Logical device and queues选择要使用的物理设备后，就可以创建一个与之适配的逻辑设备。逻辑设备创建过程类似于实例创建过程，还需要指定现在要创建的队列（已经查询了哪些队列系列可用）。并且从同一物理设备可以创建多个逻辑设备。 存储逻辑设备类似物理设备，也是使用句柄： 1VkDevice device; 2.1 指定要创建的队列创建逻辑设备也是在结构体中指定一堆细节，其中第一个是VkDeviceQueueCreateInfo。此结构描述了我们为单个队列系列所需的队列数。比如创建具有图形功能的队列： 1234567QueueFamilyIndices indices = findQueueFamilies(physicalDevice);VkDeviceQueueCreateInfo queueCreateInfo = &#123;&#125;;queueCreateInfo.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;queueCreateInfo.queueFamilyIndex = indices.graphicsFamily.value();queueCreateInfo.queueCount = 1; 当前可用的驱动程序只允许为每个队列系列创建少量队列，实际上也不需要多个队列。因为可以在多个线程上创建所有命令缓冲区，然后使用一个低开销调用在主线程上一次性提交。 Vulkan允许为队列分配优先级，以使用介于0.0和1.0之间的浮点数来影响命令缓冲区执行的调度。即使只有一个队列，也是必需的： 12float queuePriority = 1.0f;queueCreateInfo.pQueuePriorities = &amp;queuePriority; 2.2 指定使用的设备功能(feature)要指定的下一个信息是我们将要使用的一组设备feature。这些是在[1.2]中使用vkGetPhysicalDeviceFeatures查询支持的功能，例如几何着色器。如果不需要任何特殊的东西，可以简单地定义它并默认为VK_FALSE。但一旦即将开始用Vulkan做更多有趣的事情，就需要设定这个结构了。 1VkPhysicalDeviceFeatures deviceFeatures = &#123;&#125;; 2.3 创建逻辑设备在VkDeviceQueueCreateInfo和VkPhysicalDeviceFeatures创建完毕后，就可以根据这个创建逻辑设备实例了。 12345678VkDeviceCreateInfo createInfo = &#123;&#125;;createInfo.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;// 首先指定VkDeviceQueueCreateInfocreateInfo.pQueueCreateInfos = &amp;queueCreateInfo;createInfo.queueCreateInfoCount = 1;// 指定VkPhysicalDeviceFeaturescreateInfo.pEnabledFeatures = &amp;deviceFeatures; 其余信息与VkInstanceCreateInfo结构相似，并要求指定扩展(Extensions)和验证层(Validation Layers)。不同之处在于这次是逻辑设备的。设备特定扩展的其中之一是VK_KHR_swapchain，它允许您将该设备的渲染图像呈现给窗口。系统中可能存在缺乏此功能的Vulkan设备，比如因为它们仅支持计算操作。 Vulkan的先前实现区分了实例和设备特定的验证层，但现在不做区分了。也就是说VkDeviceCreateInfo的enabledLayerCount和ppEnabledLayerNames字段在最新实现中可以忽略。 12345678createInfo.enabledExtensionCount = 0;if (enableValidationLayers) &#123; createInfo.enabledLayerCount = static_cast&lt;uint32_t&gt;(validationLayers.size()); createInfo.ppEnabledLayerNames = validationLayers.data();&#125; else &#123; createInfo.enabledLayerCount = 0;&#125; 类似创建vulkan实例，这里使用 vkCreateDevice 函数创建逻辑设备： 1234// 调用 vkCreateDevice 创建逻辑设备，别忘了在cleanup函数中销毁if (vkCreateDevice(physicalDevice, &amp;createInfo, nullptr, &amp;device) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create logical device!&quot;);&#125; 2.4 检索队列句柄队列是与逻辑设备一起自动创建的，现在创建与它们接口的句柄。使用 VkQueue 来存储队列的句柄，如存储图形队列的句柄： 1VkQueue graphicsQueue; 当设备被销毁时，会隐式清除设备队列，因此我们不需要在清理中执行任何操作(vkCreateXXX才需要主动释放哦)。 我们可以使用vkGetDeviceQueue函数来检索每个队列系列的队列句柄。参数是逻辑设备，队列系列，队列索引和指向存储队列句柄的变量的指针。因为我们只是从这个系列创建一个队列，所以我们只使用索引0。 1vkGetDeviceQueue(device, indices.graphicsFamily.value(), 0, &amp;graphicsQueue); 有了逻辑设备和队列句柄，我们现在可以开始使用显卡来做事了！准备工作基本完成，后续我们可以设置资源并用窗口显示结果！这次就不贴代码了。 附录vulkan feature vulkan feature 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 定义在 vulkan_core.h 文件中typedef struct VkPhysicalDeviceFeatures &#123; VkBool32 robustBufferAccess; VkBool32 fullDrawIndexUint32; VkBool32 imageCubeArray; VkBool32 independentBlend; VkBool32 geometryShader; VkBool32 tessellationShader; VkBool32 sampleRateShading; VkBool32 dualSrcBlend; VkBool32 logicOp; VkBool32 multiDrawIndirect; VkBool32 drawIndirectFirstInstance; VkBool32 depthClamp; VkBool32 depthBiasClamp; VkBool32 fillModeNonSolid; VkBool32 depthBounds; VkBool32 wideLines; VkBool32 largePoints; VkBool32 alphaToOne; VkBool32 multiViewport; VkBool32 samplerAnisotropy; VkBool32 textureCompressionETC2; VkBool32 textureCompressionASTC_LDR; VkBool32 textureCompressionBC; VkBool32 occlusionQueryPrecise; VkBool32 pipelineStatisticsQuery; VkBool32 vertexPipelineStoresAndAtomics; VkBool32 fragmentStoresAndAtomics; VkBool32 shaderTessellationAndGeometryPointSize; VkBool32 shaderImageGatherExtended; VkBool32 shaderStorageImageExtendedFormats; VkBool32 shaderStorageImageMultisample; VkBool32 shaderStorageImageReadWithoutFormat; VkBool32 shaderStorageImageWriteWithoutFormat; VkBool32 shaderUniformBufferArrayDynamicIndexing; VkBool32 shaderSampledImageArrayDynamicIndexing; VkBool32 shaderStorageBufferArrayDynamicIndexing; VkBool32 shaderStorageImageArrayDynamicIndexing; VkBool32 shaderClipDistance; VkBool32 shaderCullDistance; VkBool32 shaderFloat64; VkBool32 shaderInt64; VkBool32 shaderInt16; VkBool32 shaderResourceResidency; VkBool32 shaderResourceMinLod; VkBool32 sparseBinding; VkBool32 sparseResidencyBuffer; VkBool32 sparseResidencyImage2D; VkBool32 sparseResidencyImage3D; VkBool32 sparseResidency2Samples; VkBool32 sparseResidency4Samples; VkBool32 sparseResidency8Samples; VkBool32 sparseResidency16Samples; VkBool32 sparseResidencyAliased; VkBool32 variableMultisampleRate; VkBool32 inheritedQueries;&#125; VkPhysicalDeviceFeatures; 1. robustBufferAccess指定对缓冲区的访问是根据缓冲区描述符的范围进行边界检查的(由VkDescriptorBufferInfo::range，VkBufferViewCreateInfo::range或缓冲区的大小确定）。超出范围访问不得导致应用程序终止，并且着色器加载，存储和原子的效果必须符合与如下相关的行为： 如果满足以下任何条件，则认为缓冲区访问超出范围： 指针由OpImageTexelPointer形成，坐标小于零或大于或等于绑定范围内的整个元素的数量。 指针不是由OpImageTexelPointer形成的，并且指向的对象并不完全包含在绑定范围内。这包括通过变量指针执行的访问，其中不能静态地确定被访问的缓冲区描述符。未初始化的指针和指向OpConstantNull的指针被视为指向零大小的对象，因此通过这些指针的所有访问都被视为超出范围。 注意：如果SPIR-V OpLoad指令加载结构并且结构的尾端超出边界，则结构的所有成员都被视为超出边界，即使最终的成员未被静态使用。 如果确定给定SPIR-V块中的任何缓冲区访问超出范围，则在同一SPIR-V块中访问小于16字节的地址的任何其他相同类型（加载，存储或原子）访问 远离界外地址也可能被认为是超出界限。 超出范围的缓冲区加载将返回以下任何值： 从绑定到缓冲区的内存范围内的任何位置开始的值（可能包括超出缓冲区末尾的内存字节，直到绑定范围的末尾）。 向量读取的零值或（0,0,0，x）向量，其中x是向量组件类型中表示的有效值，可以是以下任意一种： 有符号或无符号整数分量的0,1或最大可表示正整数值 0.0或1.0，用于浮点组件 越界写入可以修改绑定到缓冲区的内存范围内的值，但不能修改任何其他内存。 越界原子可以修改绑定到缓冲区的内存范围内的值，但不能修改任何其他内存，并返回未定义的值。 如果绑定顶点缓冲区范围中属性的偏移量加上属性的大小大于以下值，则顶点输入属性被视为超出边界。 vertexBufferRangeSize, if bindingStride &#x3D;&#x3D; 0; 或者 (vertexBufferRangeSize - (vertexBufferRangeSize % bindingStride)) 其中vertexBufferRangeSize是绑定到顶点缓冲区绑定的内存范围的字节大小，bindingStride是相应顶点输入绑定的字节跨度。此外，如果使用特定顶点输入绑定的任何顶点输入属性超出边界，则使用该顶点着色器调用的顶点输入绑定的所有顶点输入属性被视为超出边界。 一旦顶点输入属性超出范围，将为其分配以下值之一： 来自绑定到缓冲区的内存范围内任何位置的值，根据属性的格式进行转换。 零值，或（0,0,0，x）向量，格式根据属性的格式转换。 如果未启用robustBufferAccess，则应用程序不得执行越界访问。而一般来讲，robustBufferAccess都是需要开启的。 2. fullDrawIndexUint32指定当使用VKIndexType为VK_INDEX_TYPE_UINT32时，索引绘制调用支持完整的32位索引范围。maxDrawIndexedIndexValue是可以使用的最大索引值（除了原始重启索引，当VkIndexType是VK_INDEX_TYPE_UINT32时，它总是2^32-1）。如果支持此功能，则maxDrawIndexedIndexValue必须为2^32-1; 否则它必须不小于2^24-1。 3. imageCubeArray指定是否可以创建VkImageViewType为VK_IMAGE_VIEW_TYPE_CUBE_ARRAY的图像视图，以及是否可以在着色器代码中使用相应的SampledCubeArray和ImageCubeArray SPIR-V功能。 4. independentBlend指定是否每个附件独立控制VkPipelineColorBlendAttachmentState设置。如果未启用此功能，则所有颜色附件的VkPipelineColorBlendAttachmentState设置必须相同。如果启用，可以为每个绑定的颜色附件提供不同的VkPipelineColorBlendAttachmentState。 5. geometryShader指定是否支持几何着色器。如果未启用此功能，则不得使用VK_SHADER_STAGE_GEOMETRY_BIT和VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT枚举值。这还指定着色器模块是否可以声明几何功能。 6. tessellationShader指定是否支持曲面细分控制和评估着色器。如果未启用此功能，则不得使用： VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT：指定曲面细分控制阶段 VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT：指定曲面细分评估阶段 VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT：指定曲面细分控制着色器阶段 VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT：指定曲面细分评估着色器阶段 VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_STATE_CREATE_INFO 这还指定着色器模块是否可以声明Tessellation功能。 7. sampleRateShading指定是否支持样本着色和多重采样插值。如果未启用此功能，则必须将VkPipelineMultisampleStateCreateInfo结构的sampleShadingEnable成员设置为VK_FALSE，并忽略minSampleShading成员。这还指定着色器模块是否可以声明SampleRateShading功能。 8. dualSrcBlend指定是否支持采用两个源的混合操作。如果未启用此功能，则不得将： VK_BLEND_FACTOR_SRC1_COLOR： VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR VK_BLEND_FACTOR_SRC1_ALPHA VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA 以上枚举值用作源或目标混合因子。详细信息参阅 vkspec.html: 26.1.2. Dual-Source Blending 9. logicOp指定是否支持逻辑运算。 如果未启用此功能，则必须将VkPipelineColorBlendStateCreateInfo结构的logicOpEnable成员设置为VK_FALSE，并忽略logicOp成员。 10. multiDrawIndirect指定是否支持多个draw间接。如果未启用此功能，则vkCmdDrawIndirect和vkCmdDrawIndexedIndirect命令的drawCount参数必须为0或1.如果不支持此功能，则VkPhysicalDeviceLimits结构的maxDrawIndirectCount(间接绘制调用支持的最大绘制计数)成员也必须为1。 11. drawIndirectFirstInstance指定间接绘制调用是否支持firstInstance参数。如果未启用此功能，则提供给vkCmdDrawIndirect和vkCmdDrawIndexedIndirect命令的所有VkDrawIndirectCommand和VkDrawIndexedIndirectCommand结构的firstInstance成员必须为0。 12. depthClamp指定是否支持深度Clamp。如果未启用此功能，则必须将VkPipelineRasterizationStateCreateInfo结构的depthClampEnable成员设置为VK_FALSE。如果启用，将depthClampEnable设置为VK_TRUE将启用深度Clamp。 13. depthBiasClamp指定是否支持深度偏置Clamp。如果未启用此功能，则必须将VkPipelineRasterizationStateCreateInfo结构的depthBiasClamp成员设置为0.0，除非启用VK_DYNAMIC_STATE_DEPTH_BIAS动态状态，并且必须将vkCmdSetDepthBias的depthBiasClamp参数设置为0.0。 14. fillModeNonSolid指定是否支持点和线框填充模式。如果未启用此功能，则VkPipelineRasterizationStateCreateInfo::polygonMode不得使用: VK_POLYGON_MODE_POINT:指定将多边形顶点绘制为点 VK_POLYGON_MODE_LINE:指定将多边形的边绘制为点 15. depthBounds指定是否支持深度边界测试。如果未启用此功能，则必须将VkPipelineDepthStencilStateCreateInfo结构的depthBoundsTestEnable成员设置为VK_FALSE。 当depthBoundsTestEnable设置为VK_FALSE时，将忽略VkPipelineDepthStencilStateCreateInfo结构的minDepthBounds和maxDepthBounds成员。 16. wideLines指定是否支持宽度不是1.0的行。如果未启用此功能，则必须将VkPipelineRasterizationStateCreateInfo结构的lineWidth成员设置为1.0，除非启用VK_DYNAMIC_STATE_LINE_WIDTH动态状态，并且必须将vWCmdSetLineWidth的lineWidth参数设置为1.0。支持此功能时，支持的线宽的范围和粒度分别由VkPhysicalDeviceLimits结构的lineWidthRange和lineWidthGranularity成员指示。 17. largePoints指定是否支持大小大于1.0的点。如果未启用此功能，则仅支持着色器写入的点大小1.0。 支持的点大小的范围和粒度分别由VkPhysicalDeviceLimits结构的pointSizeRange和pointSizeGranularity成员指示。 18. alphaToOne指定实现是否能够使用定点颜色的最大可表示alpha值或浮点颜色的1.0替换片段着色器中输出的颜色片段的alpha值。如果未启用此功能，则必须将VkPipelineMultisampleStateCreateInfo结构的alphaToOneEnable成员设置为VK_FALSE。否则，将alphaToOneEnable设置为VK_TRUE将启用alpha-to-one行为。 19. multiViewport指定是否支持多个Viewport。 如果未启用此功能： 必须将VkPipelineViewportStateCreateInfo结构的viewportCount和scissorCount成员设置为1。 vkCmdSetViewport命令的firstViewport和viewportCount参数必须分别设置为0和1。 vkCmdSetScissor命令的firstScissor和scissorCount参数必须分别设置为0和1。 20. samplerAnisotropy指定是否支持各向异性过滤。如果未启用此功能，则VkSamplerCreateInfo结构的anisotropyEnable成员必须为VK_FALSE。 21. textureCompressionETC2指定是否支持所有ETC2和EAC压缩纹理格式。如果启用此功能，则OptimalTilingFeatures中必须支持: VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT:指定可以从中采样图像视图 VK_FORMAT_FEATURE_BLIT_SRC_BIT:指定图像可用作vkCmdBlitImage命令的srcImage VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT：图像视图可以与采样器一起使用(详细信息 vkspec.html:VkFormatFeatureFlagBits) 以上格式的功能： VK_FORMAT_ETC2_R8G8B8_UNORM_BLOCK VK_FORMAT_ETC2_R8G8B8_SRGB_BLOCK VK_FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK VK_FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK VK_FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK VK_FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK VK_FORMAT_EAC_R11_UNORM_BLOCK VK_FORMAT_EAC_R11_SNORM_BLOCK VK_FORMAT_EAC_R11G11_UNORM_BLOCK VK_FORMAT_EAC_R11G11_SNORM_BLOCK 要查询其他属性，或者未启用该功能，可以使用vkGetPhysicalDeviceFormatProperties和vkGetPhysicalDeviceImageFormatProperties来检查各个格式的支持属性。 22. textureCompressionASTC_LDR指定是否支持所有ASTC LDR压缩纹理格式。如果启用此功能，则OptimalTilingFeatures中必须支持: VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT VK_FORMAT_FEATURE_BLIT_SRC_BIT和VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT 以上格式的功能： VK_FORMAT_ASTC_4x4_UNORM_BLOCK VK_FORMAT_ASTC_4x4_SRGB_BLOCK VK_FORMAT_ASTC_5x4_UNORM_BLOCK VK_FORMAT_ASTC_5x4_SRGB_BLOCK VK_FORMAT_ASTC_5x5_UNORM_BLOCK VK_FORMAT_ASTC_5x5_SRGB_BLOCK VK_FORMAT_ASTC_6x5_UNORM_BLOCK VK_FORMAT_ASTC_6x5_SRGB_BLOCK VK_FORMAT_ASTC_6x6_UNORM_BLOCK VK_FORMAT_ASTC_6x6_SRGB_BLOCK VK_FORMAT_ASTC_8x5_UNORM_BLOCK VK_FORMAT_ASTC_8x5_SRGB_BLOCK VK_FORMAT_ASTC_8x6_UNORM_BLOCK VK_FORMAT_ASTC_8x6_SRGB_BLOCK VK_FORMAT_ASTC_8x8_UNORM_BLOCK VK_FORMAT_ASTC_8x8_SRGB_BLOCK VK_FORMAT_ASTC_10x5_UNORM_BLOCK VK_FORMAT_ASTC_10x5_SRGB_BLOCK VK_FORMAT_ASTC_10x6_UNORM_BLOCK VK_FORMAT_ASTC_10x6_SRGB_BLOCK VK_FORMAT_ASTC_10x8_UNORM_BLOCK VK_FORMAT_ASTC_10x8_SRGB_BLOCK VK_FORMAT_ASTC_10x10_UNORM_BLOCK VK_FORMAT_ASTC_10x10_SRGB_BLOCK VK_FORMAT_ASTC_12x10_UNORM_BLOCK VK_FORMAT_ASTC_12x10_SRGB_BLOCK VK_FORMAT_ASTC_12x12_UNORM_BLOCK VK_FORMAT_ASTC_12x12_SRGB_BLOCK 要查询其他属性，或者未启用该功能，可以使用vkGetPhysicalDeviceFormatProperties和vkGetPhysicalDeviceImageFormatProperties来检查各个格式的支持属性。 23. textureCompressionBC指定是否支持所有BC压缩纹理格式。如果启用此功能，则OptimalTilingFeatures中必须支持： VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT VK_FORMAT_FEATURE_BLIT_SRC_BIT VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT 以上格式的功能： VK_FORMAT_BC1_RGB_UNORM_BLOCK VK_FORMAT_BC1_RGB_SRGB_BLOCK VK_FORMAT_BC1_RGBA_UNORM_BLOCK VK_FORMAT_BC1_RGBA_SRGB_BLOCK VK_FORMAT_BC2_UNORM_BLOCK VK_FORMAT_BC2_SRGB_BLOCK VK_FORMAT_BC3_UNORM_BLOCK VK_FORMAT_BC3_SRGB_BLOCK VK_FORMAT_BC4_UNORM_BLOCK VK_FORMAT_BC4_SNORM_BLOCK VK_FORMAT_BC5_UNORM_BLOCK VK_FORMAT_BC5_SNORM_BLOCK VK_FORMAT_BC6H_UFLOAT_BLOCK VK_FORMAT_BC6H_SFLOAT_BLOCK VK_FORMAT_BC7_UNORM_BLOCK VK_FORMAT_BC7_SRGB_BLOCK 要查询其他属性，或者未启用该功能，可以使用vkGetPhysicalDeviceFormatProperties和vkGetPhysicalDeviceImageFormatProperties来检查各个格式的支持属性。 24. occlusionQueryPrecise指定是否支持返回实际样本计数的遮挡查询。通过在VkQueryPoolCreateInfo结构中指定VK_QUERY_TYPE_OCCLUSION的queryType并将其传递给vkCreateQueryPool，可以在VkQueryPool中创建遮挡查询。如果启用此功能，则此类查询可以将flags参数中的VK_QUERY_CONTROL_PRECISE_BIT启用为vkCmdBeginQuery。如果不支持此功能，则实现仅支持布尔遮挡查询。传递任何样本时，布尔查询将返回非零结果值，否则返回结果值为零。启用此功能并设置VK_QUERY_CONTROL_PRECISE_BIT后，遮挡查询将报告传递的实际样本数。 25. pipelineStatisticsQuery指定是否支持管道统计信息查询。如果未启用此功能，则无法创建类型为VK_QUERY_TYPE_PIPELINE_STATISTICS的查询，并且无法在VkQueryPoolCreateInfo结构的pipelineStatistics成员中设置任何VkQueryPipelineStatisticFlagBits位。 26. vertexPipelineStoresAndAtomics指定存储缓冲区和图像是否支持顶点，曲面细分和几何着色器阶段中的存储和原子操作。如果未启用此功能，则着色器模块中这些阶段使用的所有存储器映像，存储纹理缓冲区缓冲区和存储缓冲区变量必须使用NonWritable修饰（或GLSL中的只读内存限定符）进行修饰。 27. fragmentStoresAndAtomics指定存储缓冲区和图像是否支持片段着色器阶段中的存储和原子操作。如果未启用此功能，则着色器模块中片段阶段使用的所有存储器映像，存储纹理缓冲区缓冲区和存储缓冲区变量必须使用NonWritable修饰（或GLSL中的只读内存限定符）进行修饰。 28. shaderTessellationAndGeometryPointSize指定曲面细分控件，曲面细分评估和几何着色器阶段中是否提供PointSize内置修饰。如果未启用此功能，则不得读取或写入使用PointSize内置修饰的成员，并且从曲面细分或几何着色器写入的所有点的大小均为1.0。这还指定着色器模块是否可以为曲面细分控制和评估着色器声明TessellationPointSize功能，或者着色器模块是否可以为几何着色器声明GeometryPointSize功能。支持此功能的实现还必须支持tessellationShader或geometryShader功能中的一个或两个。 29. shaderImageGatherExtended指定着色器代码中是否可以使用扩展的图像收集指令集。如果未启用此功能，则OpImage * Gather指令不支持Offset和ConstOffsets操作数。 这还指定着色器模块是否可以声明ImageGatherExtended功能。 30. shaderStorageImageExtendedFormats指定着色器代码中是否所有扩展存储器图像格式都可用。如果启用此功能，则必须在所有扩展格式的optimalTilingFeatures中支持VK_FORMAT_FEATURE_STORAGE_IMAGE_BIT功能。要查询其他属性，或者未启用该功能，可以使用vkGetPhysicalDeviceFormatProperties和vkGetPhysicalDeviceImageFormatProperties来检查各个格式的支持属性。 31. shaderStorageImageMultisample指定是否支持多重采样存储映像。如果未启用此功能，则必须使用等于VK_SAMPLE_COUNT_1_BIT的样本创建使用包含VK_IMAGE_USAGE_STORAGE_BIT的用法创建的图像。这还指定着色器模块是否可以声明StorageImageMultisample功能。 32. shaderStorageImageReadWithoutFormat指定存储图像是否需要在从存储器映像读取时指定格式限定符。如果未启用此功能，则OpImageRead指令的OpTypeImage不得为Unknown。这还指定着色器模块是否可以声明StorageImageReadWithoutFormat功能。 33. shaderStorageImageWriteWithoutFormat指定存储图像是否需要在写入存储图像时指定格式限定符。如果未启用此功能，则OpImageWrite指令的OpTypeImage不得为Unknown。这还指定着色器模块是否可以声明StorageImageWriteWithoutFormat功能。 34. shaderUniformBufferArrayDynamicIndexing指定是否可以通过着色器代码中的动态统一整数表达式对统一缓冲区的数组建立索引。如果未启用此功能，则在着色器代码中聚合到数组中时，描述符类型为VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER或VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC的资源必须仅由常量整数表达式编制索引。这还指定着色器模块是否可以声明UniformBufferArrayDynamicIndexing功能。 35. shaderSampledImageArrayDynamicIndexing指定采样器阵列或采样图像是否可以通过着色器代码中的动态统一整数表达式进行索引。如果未启用此功能，则在着色器代码中聚合到数组中时，描述符类型为VK_DESCRIPTOR_TYPE_SAMPLER，VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER或VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE的资源必须仅由常量整数表达式编制索引。这还指定着色器模块是否可以声明SampledImageArrayDynamicIndexing功能。 36. shaderStorageBufferArrayDynamicIndexing指定是否可以通过着色器代码中的动态统一整数表达式索引存储缓冲区的数组。如果未启用此功能，则在着色器代码中聚合到数组中时，描述符类型为VK_DESCRIPTOR_TYPE_STORAGE_BUFFER或VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC的资源必须仅由常量整数表达式编制索引。这还指定着色器模块是否可以声明StorageBufferArrayDynamicIndexing功能。 37. shaderStorageImageArrayDynamicIndexing指定是否可以通过着色器代码中的动态统一整数表达式索引存储器图像数组。如果未启用此功能，则在着色器代码中聚合到数组中时，描述符类型为VK_DESCRIPTOR_TYPE_STORAGE_IMAGE的资源必须仅通过常量整数表达式编制索引。这还指定着色器模块是否可以声明StorageImageArrayDynamicIndexing功能。 38. shaderClipDistance指定着色器代码中是否支持ClipDistance。如果未启用此功能，则不得在着色器模块中读取或写入使用ClipDistance内置装饰的任何成员。这还指定着色器模块是否可以声明ClipDistance功能。 39. shaderCullDistance指定着色器代码中是否支持CullDistance。如果未启用此功能，则不得在着色器模块中读取或写入使用CullDistance内置装饰的任何成员。这还指定着色器模块是否可以声明CullDistance功能。 40. shaderFloat64指定着色器代码中是否支持64位浮点（双精度）。如果未启用此功能，则不得在着色器代码中使用64位浮点类型。这还指定着色器模块是否可以声明Float64功能。 41. shaderInt64指定着色器代码中是否支持64位整数（有符号和无符号）。如果未启用此功能，则不得在着色器代码中使用64位整数类型。这还指定着色器模块是否可以声明Int64功能。 42. shaderInt16指定着色器代码中是否支持16位整数（有符号和无符号）。如果未启用此功能，则不得在着色器代码中使用16位整数类型。这还指定着色器模块是否可以声明Int16功能。 43. shaderResourceResidency指定着色器代码是否支持返回资源驻留信息的图像操作。如果未启用此功能，则不得在着色器代码中使用OpImageSparse *指令。这还指定着色器模块是否可以声明SparseResidency功能。该功能至少需要支持一个sparseResidency *功能。 44. shaderResourceMinLod指定着色器代码中是否支持指定最小资源LOD的图像操作。如果未启用此功能，则不得在着色器代码中使用MinLod图像操作数。这还指定着色器模块是否可以声明MinLod功能。 45. sparseBinding指定是否可以在不透明的稀疏块级别而不是在对象级别管理资源内存。如果未启用此功能，则必须使用vkBindBufferMemory和vkBindImageMemory命令仅基于每个对象绑定资源内存。 在这种情况下，不能分别使用VkBufferCreateInfo和VkImageCreateInfo结构的flags成员中设置的VK_BUFFER_CREATE_SPARSE_BINDING_BIT和VK_IMAGE_CREATE_SPARSE_BINDING_BIT创建缓冲区和映像。 否则，可以按稀疏资源特征中的描述管理资源存储器。 46. sparseResidencyBuffer指定设备是否可以访问部分驻留缓冲区。如果未启用此功能，则不能使用VkBufferCreateInfo结构的flags成员中设置的VK_BUFFER_CREATE_SPARSE_RESIDENCY_BIT创建缓冲区。 47. sparseResidencyImage2D指定设备是否可以访问每个像素1个样本的部分驻留的2D图像。如果未启用此功能，则不得使用VkImageCreateInfo结构的flags成员中设置的VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT创建imageType为VK_IMAGE_TYPE_2D且样本设置为VK_SAMPLE_COUNT_1_BIT的图像。 48. sparseResidencyImage3D指定设备是否可以访问部分驻留的3D图像。如果未启用此功能，则不得使用VkImageCreateInfo结构的flags成员中设置的VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT创建imageType为VK_IMAGE_TYPE_3D的映像。 49. sparseResidency2Samples指定物理设备是否可以访问具有每像素2个样本的部分驻留的2D图像。如果未启用此功能，则不得使用VkImageCreateInfo结构的flags成员中设置的VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT创建imageType为VK_IMAGE_TYPE_2D且样本设置为VK_SAMPLE_COUNT_2_BIT的图像。 50. sparseResidency4Samples指定物理设备是否可以访问每个像素有4个样本的部分驻留的2D图像。如果未启用此功能，则不得使用VkImageCreateInfo结构的flags成员中设置的VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT创建imageType为VK_IMAGE_TYPE_2D且样本设置为VK_SAMPLE_COUNT_4_BIT的图像。 51. sparseResidency8Samples指定物理设备是否可以访问具有每像素8个样本的部分驻留的2D图像。如果未启用此功能，则不得使用VkImageCreateInfo结构的flags成员中设置的VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT创建imageType为VK_IMAGE_TYPE_2D且样本设置为VK_SAMPLE_COUNT_8_BIT的图像。 52. sparseResidency16Samples指定物理设备是否可以访问每个像素16个样本的部分驻留的2D图像。如果未启用此功能，则不得使用VkImageCreateInfo结构的flags成员中设置的VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT创建imageType为VK_IMAGE_TYPE_2D且样本设置为VK_SAMPLE_COUNT_16_BIT的图像。 53. sparseResidencyAliased指定物理设备是否可以正确访问别名到多个位置的数据。如果未启用此功能，则不得分别在VkBufferCreateInfo和VkImageCreateInfo结构的flags成员中使用VK_BUFFER_CREATE_SPARSE_ALIASED_BIT和VK_IMAGE_CREATE_SPARSE_ALIASED_BIT枚举值。 54. variableMultisampleRate指定在没有附件的子通行期间将绑定到命令缓冲区的所有管道是否必须具有VkPipelineMultisampleStateCreateInfo::rasterizationSamples的相同值。如果设置为VK_TRUE，则实现支持不带附件的子通道中的可变多重采样率。如果设置为VK_FALSE，则绑定在此子通道中的所有管道必须具有相同的多采样率。 但这在子通道使用任何附件的情况下无效。 55. inheritedQueries指定在查询处于活动状态时是否可以执行辅助命令缓冲区。 说明：vkspec.html（2019&#x2F;05&#x2F;03）是从官方文档 https://github.com/KhronosGroup/Vulkan-Docs/ 中制作生成的。可以自行下载最新代码制作，也可以直接下载： csdn（需要5积分，不知道怎么去掉这个）：https://download.csdn.net/download/u014535072/11158246 百度网盘：链接: https://pan.baidu.com/s/1IyPnb-2ti1SjU0puFKwYUQ 提取码: f2c2","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(2)-创建Vulkan示例及验证层","slug":"Vulkan入门-2-创建Vulkan示例及验证层","date":"2022-02-26T14:24:59.000Z","updated":"2022-02-26T19:17:36.499Z","comments":true,"path":"2022/02/26/Vulkan入门-2-创建Vulkan示例及验证层/","link":"","permalink":"https://swallowjoe.github.io/2022/02/26/Vulkan%E5%85%A5%E9%97%A8-2-%E5%88%9B%E5%BB%BAVulkan%E7%A4%BA%E4%BE%8B%E5%8F%8A%E9%AA%8C%E8%AF%81%E5%B1%82/","excerpt":"简述本文主要是实现Vulkan Tutorial.pdf文档中的Base Code, Instance和Validation Layers部分。","text":"简述本文主要是实现Vulkan Tutorial.pdf文档中的Base Code, Instance和Validation Layers部分。 参考资料 https://github.com/KhronosGroup/Vulkan-Docs https://www.khronos.org/registry/vulkan/specs/1.1-extensions/html/vkspec.html#vkCreateInstance https://github.com/SaschaWillems/Vulkan/blob/master/base/vulkanexamplebase.h 一. 创建 vulkan 实例1.1 创建 Window 实例先创建个 window 窗口 12345678910111213141516void initWindow() &#123; // 第一步一定是先初始化GLFW库. glfwInit(); // 因为GLFW最初是为创建OpenGL上下文而设计的， // 所以我们需要告诉它不要通过后续调用创建OpenGL上下文：GLFW_NO_API glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API); // 因为处理大小可变的窗口比较复杂，暂时先让窗口不可变 glfwWindowHint(GLFW_RESIZABLE, GLFW_FALSE); // 创建窗口 // GLFWwindow *glfwCreateWindow(int width, int height, const char *title, GLFWmonitor *monitor, GLFWwindow *share) window = glfwCreateWindow(WIDTH, HEIGHT, WINDOW_TITLE, nullptr, nullptr);&#125; 1.2 创建 Vulkan 实例 创建 VkApplicationInfo 结构体变量，参数可选 创建 VkInstanceCreateInfo 结构体变量，必须指明 使用 GLFW (glfwGetRequiredInstanceExtensions) 创建 glfwExtensions, 以便为GLFW窗口创建Vulkan surface 调用 vkCreateInstance, 创建 vulkan 实例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950void createInstance() &#123; // 创建一个实例首先必须填写一个包含有关我们应用程序的信息的结构: VkApplicationInfo // 这些数据在技术上是可选的，但它可以为驱动程序提供一些有用的信息，以便针对我们的特定应用进行优化 VkApplicationInfo appInfo = &#123;&#125;; // Vulkan中的许多结构要求在sType成员中明确指定类型。 // 这也是具有pNext成员的许多结构中的一个，该成员可以在将来指向扩展信息。 appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO; appInfo.pApplicationName = &quot;Hello Triangle&quot;; appInfo.applicationVersion = VK_MAKE_VERSION(1, 1, 0); appInfo.pEngineName = &quot;No Engine&quot;; appInfo.engineVersion = VK_MAKE_VERSION(1, 1, 0); appInfo.apiVersion = VK_API_VERSION_1_1; // Vulkan中的很多信息都是通过结构而不是函数参数传递的， // 我们必须再填充一个结构体 VkInstanceCreateInfo 来为创建实例提供足够的信息。 // VkInstanceCreateInfo结构是必须指明的，它告诉Vulkan驱动程序我们想要使用哪些全局扩展和验证层。 VkInstanceCreateInfo createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO; createInfo.pNext = nullptr; createInfo.pApplicationInfo = &amp;appInfo; // 前两个参数很简单。 // Vulkan是一个与平台无关的API，这意味着需要一个与窗口系统接口的扩展。 // GLFW有一个方便的内置函数，它返回它需要做的扩展，我们可以传递给结构体：VkInstanceCreateInfo uint32_t glfwExtensionCount = 0; const char** glfwExtensions; // 返回GLFW所需的Vulkan实例扩展。 // 此函数返回GLFW所需的Vulkan实例扩展名的数组，以便为GLFW窗口创建Vulkan surface。 // 如果成功，列表将始终包含`VK_KHR_surface`，因此如果您不需要任何其他扩展，则可以将此列表直接传递给`VkInstanceCreateInfo`结构。 // 如果机器上没有Vulkan，则此函数返回“NULL”并生成 GLFW_API_UNAVAILABLE错误。 glfwExtensions = glfwGetRequiredInstanceExtensions(&amp;glfwExtensionCount); createInfo.enabledExtensionCount = glfwExtensionCount; // createInfo.ppEnabledLayerNames = glfwExtensions; // 笔者曾在这里栽了个跟头，写错了。如上写，编译不出问题，但运行时会报 Segmentation fault (core dumped) // 打印堆栈，看了半天，才发现的，引以为戒，不过这两变量名字很像。 createInfo.ppEnabledExtensionNames = glfwExtensions; // 结构体的最后两个成员确定要启用的全局验证层。 createInfo.enabledLayerCount = 0; // VkResult vkCreateInstance(const VkInstanceCreateInfo *pCreateInfo, const VkAllocationCallbacks *pAllocator, VkInstance *pInstance) VkResult res = vkCreateInstance(&amp;createInfo, nullptr, &amp;instance); if (res != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create instance!&quot;); &#125;&#125; 二. 验证层(Validation layers)2.1 什么是 Validation layers？Vulkan API围绕最小驱动程序开销的想法而设计，该目标的一个表现形式是默认情况下API中的错误检查非常有限。即使是将枚举设置为不正确的值或将空指针传递给所需参数这样简单的错误通常也不会被显式处理，只会导致崩溃或未定义的行为。这一点，笔者已经深刻体会到了，(╯﹏╰)因为Vulkan要求你对你所做的一切都非常明确，所以很容易犯很多小错误，例如使用新的GPU功能而忘记在逻辑设备创建时请求它。 但是，这并不意味着无法将这些检查添加到API中。Vulkan为这种称为验证层的系统引入了一个优雅的系统: Validation layers.验证层是可选组件，它挂接到Vulkan函数调用以应用其他操作。 验证层中的常见操作是： 根据规范检查参数值以检测误用 跟踪对象的创建和销毁以查找资源泄漏 通过跟踪调用的线程来检查线程安全性 将每个调用及其参数记录到标准输出方便调试 跟踪Vulkan要求进行性能分析和重放 2.2 Validation layers示例123456789101112VkResult vkCreateInstance( const VkInstanceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkInstance* instance) &#123; if (pCreateInfo == nullptr || instance == nullptr) &#123; log(&quot;Null pointer passed to required parameter!&quot;); return VK_ERROR_INITIALIZATION_FAILED; &#125; return real_vkCreateInstance(pCreateInfo, pAllocator, instance);&#125; 比如上面的vkCreateInstance中的if语句。官方文档上如此说： 1234567891011这些验证层可以自由堆叠，以包含您感兴趣的所有调试功能。您可以简单地为调试版本启用验证层，并为发布版本完全禁用它们，这将为您提供两全其美的优势！Vulkan没有内置任何验证层，但LunarG Vulkan SDK提供了一组很好的层来检查常见错误。它们也是完全开源的，因此您可以检查它们检查和贡献的错误类型。使用验证层是避免应用程序因意外依赖未定义行为而破坏不同驱动程序的最佳方法。验证层只有在已安装到系统上时才能使用。例如，LunarG验证层仅适用于安装了Vulkan SDK的PC。Vulkan中以前有两种不同类型的验证层：实例和设备特定。我们的想法是，实例层只会检查与全局Vulkan对象（如实例）相关的调用，而设备特定层只会检查与特定GPU相关的调用。现在已弃用特定于设备的层，这意味着实例验证层适用于所有Vulkan调用。规范文档仍建议您在设备级别启用验证层以及兼容性，这是某些实现所需的。 2.3 启用验证层如何启用Vulkan SDK提供的标准诊断层? 就像扩展一样，需要通过指定其名称来启用验证层。所有有用的标准验证都捆绑在SDK中包含的层中，称为VK_LAYER_KHRONOS_validation。让我们首先向程序添加两个配置变量，以指定要启用的层以及是否启用它们。 我已经选择将该值作为程序是否在调试模式下编译。NDEBUG宏是C ++标准的一部分，意味着“不调试”。 123456789const std::vector&lt;const char*&gt; validationLayers = &#123; &quot;VK_LAYER_KHRONOS_validation&quot;&#125;;#ifdef NDEBUG const bool enableValidationLayers = false;#else const bool enableValidationLayers = true;#endif 2.4 消息回调仅启用这些层并没有多大帮助，因为它们目前无法将调试消息中继回我们的程序。要接收这些消息，我们必须设置一个带回调的调试信使，这需要VK_EXT_debug_utils扩展。我们将首先创建一个getRequiredExtensions函数，根据是否启用验证层返回所需的扩展名列表： 12345678910111213std::vector&lt;const char*&gt; getRequiredExtensions() &#123; uint32_t glfwExtensionCount = 0; const char** glfwExtensions; glfwExtensions = glfwGetRequiredInstanceExtensions(&amp;glfwExtensionCount); std::vector&lt;const char*&gt; extensions(glfwExtensions, glfwExtensions + glfwExtensionCount); if (enableValidationLayers) &#123; extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME); &#125; return extensions;&#125; GLFW指定的扩展始终是必需的，但有条件地添加了调试信使扩展(VK_EXT_debug_utils)。请注意，在这里使用了VK_EXT_DEBUG_UTILS_EXTENSION_NAME宏，它等于文字字符串“VK_EXT_debug_utils”。 使用此宏可以避免拼写错误。我们现在可以在createInstance中使用此函数： 123auto extensions = getRequiredExtensions();createInfo.enabledExtensionCount = static_cast&lt;uint32_t&gt;(extensions.size());createInfo.ppEnabledExtensionNames = extensions.data(); 2.4.1 调试回调函数 debugCallback现在让我们看一下调试回调函数的样子。使用PFN_vkDebugUtilsMessengerCallbackEXT原型添加一个名为debugCallback的新静态成员函数。VKAPI_ATTR和VKAPI_CALL确保该函数具有Vulkan调用它的正确签名。 12345678910static VKAPI_ATTR VkBool32 VKAPI_CALL debugCallback( VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity, VkDebugUtilsMessageTypeFlagsEXT messageType, const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData, void* pUserData) &#123; std::cerr &lt;&lt; &quot;validation layer: &quot; &lt;&lt; pCallbackData-&gt;pMessage&lt;&lt; std::endl; return VK_FALSE;&#125; 第一个参数: VkDebugUtilsMessageSeverityFlagBitsEXT 指明了消息的严重程度•VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT：诊断消息•VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT：信息性消息，如创建资源•VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT：有关行为的消息不一定是错误，但很可能是应用程序中的错误•VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT：有关无效行为的消息，可能导致崩溃可以根据这个参数过滤所需的信息。 第二个参数: VkDebugUtilsMessageTypeFlagsEXT 指明了消息的类型•VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT：发生了与规范或性能无关的某些事件•VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT：发生了违反规范或表明可能存在错误的事情•VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT：潜在的非最佳使用Vulkan 第三个参数: VkDebugUtilsMessengerCallbackDataEXT 这个结构体包含了消息更多的细节内容•pMessage：调试消息为以空字符结尾的字符串•pObjects：与消息相关的Vulkan对象句柄数组•object Count：数组中的对象数 第四个参数: pUserData 包含在回调设置期间指定的指针，并允许您将自己的数据传递给它。 回调返回一个布尔值，指示是否应该中止触发验证层消息的Vulkan调用。如果回调返回true，则调用将因VK_ERROR_VALIDATION_FAILED_EXT错误而中止。这通常仅用于测试验证层本身，因此应始终返回VK_FALSE。 2.4.2 注册调试回调在Vulkan中, 调试回调也是通过需要显式创建和销毁的句柄来管理的。 这样的回调是debug message的一部分，可以根据需要设置尽可能多的回调。 12345678910111213141516171819202122232425// 在成员变量中添加：VkDebugUtilsMessengerEXTVkDebugUtilsMessengerEXT debugMessenger;void initVulkan() &#123; createInstance(); setupDebugMessenger();&#125;void setupDebugMessenger() &#123; if (!enableValidationLayers) return; VkDebugUtilsMessengerCreateInfoEXT createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT; createInfo.messageSeverity = VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT; createInfo.messageType = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT; // 指定消息回调函数 createInfo.pfnUserCallback = debugCallback; createInfo.pUserData = nullptr; // 可选&#125; messageSeverity字段允许指定要为其调用回调的所有类型的严重性。在这里指定了除VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT之外的所有类型，以接收有关可能问题的通知，同时省略详细的一般调试信息。类似地，messageType字段可以过滤通知回调的消息类型。 在这里启用了所有类型。最后，pfnUserCallback字段指定回调函数的指针。可以选择将指针传递给pUserData字段，该字段将通过pUserData参数传递给回调函数。例如，可以使用它来传递指向HelloTriangleApplication类的指针。 应该将结构体 VkDebugUtilsMessengerEXT 传递给vkCreateDebugUtilsMessengerEXT函数以创建VkDebugUtilsMessengerEXT对象。然而因为这个function是一个扩展函数，它不会自动加载。必须使用vkGetInstanceProcAddr查找其地址。 创建代理函数，然后在处理它，如下: 12345678910111213VkResult CreateDebugUtilsMessengerEXT(VkInstance instance, const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugUtilsMessengerEXT* pDebugMessenger) &#123; auto func = (PFN_vkCreateDebugUtilsMessengerEXT) vkGetInstanceProcAddr(instance,&quot;vkCreateDebugUtilsMessengerEXT&quot;); if (func != nullptr) &#123; return func(instance, pCreateInfo, pAllocator, pDebugMessenger); &#125; else &#123; return VK_ERROR_EXTENSION_NOT_PRESENT; &#125;&#125; 现在我们可以在 setupDebugMessenger 中调用此函数： 12345678910void setupDebugMessenger() &#123; if (!enableValidationLayers) return; ...... // 实例化DebugUtilsMessengerEXT if (CreateDebugUtilsMessengerEXT(instance, &amp;createInfo, nullptr, &amp;debugMessenger) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to set up debug messenger!&quot;); &#125;&#125; 最后注意，既然有 vkCreateXXX, 就需要显示调用 vkDestroyXXX 哦！ 12345678910void DestroyDebugUtilsMessengerEXT(VkInstance instance, VkDebugUtilsMessengerEXT debugMessenger, const VkAllocationCallbacks* pAllocator) &#123; auto func = (PFN_vkDestroyDebugUtilsMessengerEXT) vkGetInstanceProcAddr(instance, &quot;vkDestroyDebugUtilsMessengerEXT&quot;); if (func != nullptr) &#123; func(instance, debugMessenger, pAllocator); &#125;&#125; 如果你忘了调用DestroyDebugUtilsMessengerEXT去销毁debugMessenger，在关闭窗口的时候就会打印如下信息: 三. 代码3.1 Makefile12345678910111213141516VULKAN_SDK_PATH = /home/jh/Program/vulkan/1.1.160.0/x86_64CFLAGS = -std=c++17 -I$(VULKAN_SDK_PATH)/includeLDFLAGS = -L$(VULKAN_SDK_PATH)/lib -lvulkan `pkg-config --static --libs glfw3`LDFLAGS += -ldlHelloTriangleApplication: main.cpp g++ $(CFLAGS) -o HelloTriangleApplication main.cpp $(LDFLAGS).PHONY: test cleantest: HelloTriangleApplication LD_LIBRARY_PATH=$(VULKAN_SDK_PATH)/lib VK_LAYER_PATH=$(VULKAN_SDK_PATH)/etc/explicit_layer.d ./HelloTriangleApplicationclean:rm -f HelloTriangleApplication 3.2 main.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294/** * #include &lt;vulkan/vulkan.h&gt; // vulkan 头文件 * 使用下面两行替换 vulkan头文件 * #define GLFW_INCLUDE_VULKAN * #include &lt;GLFW/glfw3.h&gt; * * GLFW 会自动加载 vulkan 头文件的。 * GLFW是一个开源，多平台的库，用于桌面上的OpenGL，OpenGL ES和Vulkan开发。 * 它提供了一个简单的API，用于创建窗口，上下文和曲面，接收输入和事件。 * GLFW是用C语言编写的，并且使用X Window系统（例如Linux和FreeBSD）对Windows，macOS和许多类Unix系统提供原生支持。 */#define GLFW_INCLUDE_VULKAN#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;#include &lt;stdexcept&gt; // 包含用于报告错误的头文件#include &lt;functional&gt; // 用于资源管理部分中的lambda函数#include &lt;cstdlib&gt; // cstdlib: EXIT_FAILURE, EXIT_SUCCESS#include &lt;vector&gt;#include &lt;string.h&gt; #ifdef NDEBUG const bool enableValidationLayers = false;#else const bool enableValidationLayers = true;#endifclass HelloTriangleApplication &#123;public: void run() &#123; initWindow(); initVulkan(); mainLoop(); cleanup(); &#125; const int WIDTH = 800; const int HEIGHT = 600; const char * WINDOW_TITLE = &quot;Vulkan&quot;;private: void initWindow() &#123; // 第一步一定是先初始化GLFW库. glfwInit(); // 因为GLFW最初是为创建OpenGL上下文而设计的， // 所以我们需要告诉它不要通过后续调用创建OpenGL上下文：GLFW_NO_API glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API); // 因为处理大小可变的窗口比较复杂，暂时先让窗口不可变 glfwWindowHint(GLFW_RESIZABLE, GLFW_FALSE); // 创建窗口 // GLFWwindow *glfwCreateWindow(int width, int height, const char *title, GLFWmonitor *monitor, GLFWwindow *share) window = glfwCreateWindow(WIDTH, HEIGHT, WINDOW_TITLE, nullptr, nullptr); &#125; void initVulkan() &#123; checkAvailableExtensions(); createInstance(); // 创建DEBUG消息回调 setupDebugMessenger(); &#125; void setupDebugMessenger() &#123; if (!enableValidationLayers) return; VkDebugUtilsMessengerCreateInfoEXT createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT; createInfo.messageSeverity = VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT; createInfo.messageType = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT; // 指定消息回调函数 createInfo.pfnUserCallback = debugCallback; createInfo.pUserData = nullptr; // 可选 // 实例化DebugUtilsMessengerEXT if (CreateDebugUtilsMessengerEXT(instance, &amp;createInfo, nullptr, &amp;debugMessenger) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to set up debug messenger!&quot;); &#125; &#125; void checkAvailableExtensions() &#123; uint32_t extensionCount = 0; vkEnumerateInstanceExtensionProperties(nullptr, &amp;extensionCount, nullptr); std::vector&lt;VkExtensionProperties&gt; extensions(extensionCount); vkEnumerateInstanceExtensionProperties(nullptr, &amp;extensionCount, extensions.data()); std::cout &lt;&lt; &quot;available extensions:&quot; &lt;&lt; std::endl; for (const auto&amp; extension : extensions) &#123; std::cout &lt;&lt; &quot;\\t&quot; &lt;&lt; extension.extensionName &lt;&lt; std::endl; &#125; &#125; bool checkValidationLayerSupport() &#123; uint32_t layerCount; vkEnumerateInstanceLayerProperties(&amp;layerCount, nullptr); std::vector&lt;VkLayerProperties&gt; availableLayers(layerCount); vkEnumerateInstanceLayerProperties(&amp;layerCount, availableLayers.data()); for (const char* layerName : validationLayers) &#123; //bool layerFound = false; for (const auto&amp; layerProperties : availableLayers) &#123; if (strcmp(layerName, layerProperties.layerName) == 0) &#123; //layerFound = true; return true; &#125; &#125; &#125; return false; &#125; void createInstance() &#123; // 验证层，检验VK_LAYER_KHRONOS_validation if (enableValidationLayers &amp;&amp; !checkValidationLayerSupport()) &#123; throw std::runtime_error(&quot;validation layers requested, but not available!&quot;); &#125; // 创建一个实例首先必须填写一个包含有关我们应用程序的信息的结构: VkApplicationInfo // 这些数据在技术上是可选的，但它可以为驱动程序提供一些有用的信息，以便针对我们的特定应用进行优化 VkApplicationInfo appInfo = &#123;&#125;; // Vulkan中的许多结构要求在sType成员中明确指定类型。 // 这也是具有pNext成员的许多结构中的一个，该成员可以在将来指向扩展信息。 appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO; appInfo.pApplicationName = &quot;Hello Triangle&quot;; appInfo.applicationVersion = VK_MAKE_VERSION(1, 1, 0); appInfo.pEngineName = &quot;No Engine&quot;; appInfo.engineVersion = VK_MAKE_VERSION(1, 1, 0); appInfo.apiVersion = VK_API_VERSION_1_1; // Vulkan中的很多信息都是通过结构而不是函数参数传递的， // 我们必须再填充一个结构体 VkInstanceCreateInfo 来为创建实例提供足够的信息。 // VkInstanceCreateInfo结构是必须指明的，它告诉Vulkan驱动程序我们想要使用哪些全局扩展和验证层。 VkInstanceCreateInfo createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO; createInfo.pNext = nullptr; createInfo.pApplicationInfo = &amp;appInfo; /* // 前两个参数很简单。 // Vulkan是一个与平台无关的API，这意味着需要一个与窗口系统接口的扩展。 // GLFW有一个方便的内置函数，它返回它需要做的扩展，我们可以传递给结构体：VkInstanceCreateInfo uint32_t glfwExtensionCount = 0; const char** glfwExtensions; // 返回GLFW所需的Vulkan实例扩展。 // 此函数返回GLFW所需的Vulkan实例扩展名的数组，以便为GLFW窗口创建Vulkan surface。 // 如果成功，列表将始终包含`VK_KHR_surface`，因此如果您不需要任何其他扩展，则可以将此列表直接传递给`VkInstanceCreateInfo`结构。 // 如果机器上没有Vulkan，则此函数返回“NULL”并生成 GLFW_API_UNAVAILABLE错误。 glfwExtensions = glfwGetRequiredInstanceExtensions(&amp;glfwExtensionCount); // 笔者曾在这里栽了个跟头，写错了。如上写，编译不出问题，但运行时会报 Segmentation fault (core dumped) // 打印堆栈，看了半天，才发现的，引以为戒，不过这两变量名字很像。 createInfo.ppEnabledLayerNames = glfwExtensions; createInfo.ppEnabledExtensionNames = glfwExtensions; createInfo.enabledExtensionCount = glfwExtensionCount; */ // 返回GLFW所需的Vulkan实例扩展, 支持消息回调 auto extensions = getRequiredExtensions(); createInfo.enabledExtensionCount = static_cast&lt;uint32_t&gt;(extensions.size()); createInfo.ppEnabledExtensionNames = extensions.data(); // 结构体的最后两个成员确定要启用的全局验证层。 if (enableValidationLayers) &#123; createInfo.enabledLayerCount = static_cast&lt;uint32_t&gt;(validationLayers.size()); createInfo.ppEnabledLayerNames = validationLayers.data(); &#125; else &#123; createInfo.enabledLayerCount = 0; &#125; // VkResult vkCreateInstance(const VkInstanceCreateInfo *pCreateInfo, const VkAllocationCallbacks *pAllocator, VkInstance *pInstance) VkResult res = vkCreateInstance(&amp;createInfo, nullptr, &amp;instance); if (res != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create instance!&quot;); &#125; &#125; void mainLoop() &#123; // 添加一个事件循环, 使应用程序保持运行直到发生错误或窗口关闭 while (!glfwWindowShouldClose(window)) &#123; glfwPollEvents(); &#125; &#125; // 在 vulkan 中推荐在创建的资源不需要后主动释放 void cleanup() &#123; // 释放debugMessenger(VkDebugUtilsMessengerEXT, 用于打印调试信息) if (enableValidationLayers) &#123; DestroyDebugUtilsMessengerEXT(instance, debugMessenger, nullptr); &#125; // 在 vulkan 中资源一般都是 vkCreateXXX 创建，由 vkDestroyXXX 或 vkFreeXXX 释放. vkDestroyInstance(instance, nullptr); // 此函数会破坏指定的窗口及其上下文。 在调用此函数时，不会为该窗口调用其他回调。 // 如果指定窗口的上下文在主线程上是最新的，则在销毁之前将其分离。 glfwDestroyWindow(window); // 此功能会释放所有剩余的窗口和光标并释放任何其他已分配的资源。 // 调用此函数后，必须再次成功调用@ref glfwInit，然后才能使用大多数GLFW函数。 glfwTerminate(); &#125; // 用于消息回调Message Callback std::vector&lt;const char*&gt; getRequiredExtensions() &#123; uint32_t glfwExtensionCount = 0; const char** glfwExtensions; glfwExtensions = glfwGetRequiredInstanceExtensions(&amp;glfwExtensionCount); std::vector&lt;const char*&gt; extensions(glfwExtensions, glfwExtensions + glfwExtensionCount); if (enableValidationLayers) &#123; extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME); &#125; return extensions; &#125; // 打印debug信息 static VKAPI_ATTR VkBool32 VKAPI_CALL debugCallback( VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity, VkDebugUtilsMessageTypeFlagsEXT messageType, const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData, void* pUserData) &#123; std::cerr &lt;&lt; &quot;validation layer: &quot; &lt;&lt; pCallbackData-&gt;pMessage&lt;&lt; std::endl; return VK_FALSE; &#125; // 创建 VkDebugUtilsMessengerEXT 对象debugMessenger VkResult CreateDebugUtilsMessengerEXT(VkInstance instance, const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugUtilsMessengerEXT* pDebugMessenger) &#123; // 将结构体 VkDebugUtilsMessengerEXT 传递给vkCreateDebugUtilsMessengerEXT函数以创建VkDebugUtilsMessengerEXT对象。 // 然而因为这个function是一个扩展函数，它不会自动加载。 // 必须使用vkGetInstanceProcAddr查找其地址。 auto func = (PFN_vkCreateDebugUtilsMessengerEXT) vkGetInstanceProcAddr(instance,&quot;vkCreateDebugUtilsMessengerEXT&quot;); if (func != nullptr) &#123; return func(instance, pCreateInfo, pAllocator, pDebugMessenger); &#125; else &#123; return VK_ERROR_EXTENSION_NOT_PRESENT; &#125; &#125; // 销毁VkDebugUtilsMessengerEXT void DestroyDebugUtilsMessengerEXT(VkInstance instance, VkDebugUtilsMessengerEXT debugMessenger, const VkAllocationCallbacks* pAllocator) &#123; auto func = (PFN_vkDestroyDebugUtilsMessengerEXT) vkGetInstanceProcAddr(instance, &quot;vkDestroyDebugUtilsMessengerEXT&quot;); if (func != nullptr) &#123; func(instance, debugMessenger, pAllocator); &#125; &#125; // Window实例 GLFWwindow* window; // Vulkan实例 VkInstance instance; // DEBUG消息回调 VkDebugUtilsMessengerEXT debugMessenger; // 验证层 const std::vector&lt;const char*&gt; validationLayers = &#123; &quot;VK_LAYER_KHRONOS_validation&quot; &#125;;&#125;;int main() &#123; HelloTriangleApplication app; try &#123; app.run(); &#125; catch (const std::exception&amp; e) &#123; std::cerr &lt;&lt; e.what() &lt;&lt; std::endl; return EXIT_FAILURE; &#125; return EXIT_SUCCESS;&#125;","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]},{"title":"Vulkan入门(1)-环境配置","slug":"Vulkan入门-1-环境配置","date":"2022-02-26T13:13:24.000Z","updated":"2022-02-26T18:05:46.367Z","comments":true,"path":"2022/02/26/Vulkan入门-1-环境配置/","link":"","permalink":"https://swallowjoe.github.io/2022/02/26/Vulkan%E5%85%A5%E9%97%A8-1-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"简述本文主要是介绍如何在 ubuntu 机器上安装并编译Vulkan程序。","text":"简述本文主要是介绍如何在 ubuntu 机器上安装并编译Vulkan程序。 参考资料 https://vulkan.lunarg.com/doc/sdk/1.2.170.0/linux/getting_started.html https://github.com/google/glog [pkg-config的用法]https://www.cnblogs.com/chris-cp/p/3580002.html [解决&#x2F;usr&#x2F;local&#x2F;lib&#x2F;libglog.so.0: error adding symbols: DSO missing from command line]https://blog.csdn.net/u010987458/article/details/72235408 https://www.glfw.org/docs/3.3/build_guide.html#build_link_cmake_package [GLFW]https://www.glfw.org/ [GLM]https://github.com/g-truc/glm 一. 准备环境1.1 开发环境12345sudo apt-get updatesudo apt-get dist-upgradesudo apt-get install libglm-dev cmake libxcb-dri3-0 libxcb-present0 libpciaccess0 libpng-dev libxcb-keysyms1-dev libxcb-dri3-dev libx11-dev libmirclient-dev libwayland-dev libxrandr-dev libxcb-ewmh-devsudo apt-get install git libpython2.7 1.2 下载 SDK官方网站：https://vulkan.lunarg.com/ 下载SDK包：vulkan-sdk.tar.gz 1234cd ~/Programmkdir vulkancd vulkantar zxf $HOME/Downloads/vulkan-sdk.tar.gz 解压后的文件目录如下： 文件夹 描述 x86_64&#x2F;bin Vulkan工具和命令 x86_64&#x2F;include&#x2F;vulkan 编译链接头文件 x86_64&#x2F;lib Vulkan加载程序库和layer运行时库 x86_64&#x2F;etc&#x2F;explicit_layer.d .json 用于Vulkan验证层的清单文件 config 样本层设置文件，系统配置说明 doc Khronos SPIRV，Vulkan，Loader和WSI规范 examples Vulkan程序示例 samples Vulkan的示例代码 source glslang和所选Vulkan组件的源和调试库 1.3 安装SDK123456source ~/Program/vulkan/1.2.170.0/setup-env.shexport VULKAN_SDK=~/vulkan/1.2.170.0/x86_64export PATH=$VULKAN_SDK/bin:$PATHexport LD_LIBRARY_PATH=$VULKAN_SDK/lib:$LD_LIBRARY_PATHexport VK_LAYER_PATH=$VULKAN_SDK/etc/explicit_layer.d 大功告成，检查一下：输入vulkaninfo&#117;&#98;&#117;&#110;&#x74;&#x75;&#64;&#x31;&#x38;&#x2e;&#48;&#x34;&#x4c; ~ vulkaninfoCannot create Vulkan instance.&#x2F;home&#x2F;lunarg&#x2F;sdk-build&#x2F;Vulkan-Tools&#x2F;vulkaninfo&#x2F;vulkaninfo.c:921: failed with VK_ERROR_INCOMPATIBLE_DRIVER wtf, 发生了什么？等等，貌似我们没有检查是否安装了驱动。。。 1.4 安装驱动123456789sudo add-apt-repository ppa:oibaf/graphics-driverssudo apt updatesudo apt upgradeapt install libvulkan1 mesa-vulkan-drivers vulkan-utils// 或者试试：sudo add-apt-repository ppa:graphics-drivers/ppasudo apt upgradesudo apt install nvidia-graphics-drivers-396 nvidia-settings vulkan vulkan-utils 检查一下：输入vulkaninfo 或者：vulkaninfo –html , 在当前目录生成 vulkaninfo.html 文件，用浏览器打开，可以看到更多信息 1.5. 运行示例程序12345cd Program/vulkan/1.1.160.0/examplesmkdir buildcd buildcmake ..make make成功后会在当前目录生成： 运行示例程序： 1./vkcube 一个旋转的立方体～ 二. GLFW 安装Vulkan本身是一个与平台无关的API，不包括用于创建显示渲染结果的窗口的工具。 为了从Vulkan的跨平台优势中受益并避免X11的限制，我们将使用GLFW库来创建一个支持Windows，Linux和MacOS的窗口。还有其他可用于此目的的库，如SDL，但GLFW的优势在于它除了窗口创建之外，还抽象了Vulkan中一些其他特定于平台的东西。我们将从源代码安装GLFW而不是使用软件包，因为Vulkan支持需要最新版本。 可以在官方网站上找到这些来源。将源代码解压缩到一个方便的目录，并使用CMakeLists.txt等文件打开目录中的终端。 github地址：https://github.com/glfw/glfw解压后进入其主目录：cmake .有报错： 12345678-- Looking for shmat - found-- Found X11: /usr/lib/x86_64-linux-gnu/libX11.soCMake Error at CMakeLists.txt:220 (message): The Xinerama headers were not found-- Configuring incomplete, errors occurred!See also &quot;/home/jh/Program/vulkan/glfw-master/CMakeFiles/CMakeOutput.log&quot;.See also &quot;/home/jh/Program/vulkan/glfw-master/CMakeFiles/CMakeError.log&quot;. 缺少环境： 1$ ~/Program/vulkan/glfw-master  sudo apt-get install libsdl2-dev 然后重新: cmake . 123456🦄  ~/Program/vulkan/glfw-master  cmake .-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE) -- Using X11 for window creation-- Configuring done-- Generating done-- Build files have been written to: /home/jh/Program/vulkan/glfw-master 濡染没有报错，但这个也是没有成功的：缺少Doxygensudo apt-get install doxygen 重新: cmake .最后: make成功后：sudo make install 三. GLM 安装与DirectX 12不同，Vulkan不包含用于线性代数运算的库，因此我们必须下载一个。GLM是一个很好的库，设计用于图形API，也常用于OpenGL。它是一个只有头的库，可以从libglm-dev包安装： sudo apt install libglm-dev 四. 手动编译示例代码4.1 在编译示例代码的时候老是报错，找不到vulkan头文件。123456$ gcc -o main main.cpp -lglfw3In file included from main.cpp:2:/usr/local/include/GLFW/glfw3.h:215:12: fatal error: vulkan/vulkan.h: 没有那个文件或目录 #include &lt;vulkan/vulkan.h&gt; ^~~~~~~~~~~~~~~~~compilation terminated. 当然是环境设置的问题：需要将头文件等拷贝到对应system文件夹 12345678cd Program/vulkan/1.2.170.0/x86_64sudo cp -r include/vulkan/ /usr/local/include/sudo cp -P lib/libvulkan.so* /usr/local/lib/sudo cp lib/libVkLayer_*.so /usr/local/lib/sudo mkdir -p /usr/local/share/vulkan/explicit_layer.dsudo cp etc/explicit_layer.d/VkLayer_*.json /usr/local/share/vulkan/explicit_layer.d sudo ldconfig 4.2 error adding symbols: DSO missing from command line123456makeg++ -std=c++17 -I/home/jh/Program/vulkan/1.1.160.0/x86_64/include -o VulkanTest main.cpp -L/home/jh/Program/vulkan/1.1.160.0/x86_64/lib -lvulkan -lglfw3/usr/bin/ld: //usr/local/lib/libglfw3.a(vulkan.c.o): undefined reference to symbol &#x27;dlclose@@GLIBC_2.2.5&#x27;/usr/bin/ld: //lib/x86_64-linux-gnu/libdl.so.2: error adding symbols: DSO missing from command linecollect2: error: ld returned 1 exit statusmake: *** [Makefile:8：VulkanTest] 错误 1 cd &#x2F;usr&#x2F;lib&#x2F;ll |grep -iE “liblog”没有文件 https://github.com/google/glog下载解压, 进入解压后的主目录，执行：.&#x2F;autogen.sh &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install 如果报错：autogen.sh: 5: autogen.sh: autoreconf: not foundsudo apt-get install autoconfsudo apt-get install automakesudo apt-get install libtool 重新执行：.&#x2F;autogen.sh &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install可能还有权限问题： 123456-- Up-to-date: /usr/local/include/GLFWCMake Error at cmake_install.cmake:41 (file): file INSTALL cannot set permissions on &quot;/usr/local/include/GLFW&quot;make: *** [Makefile:118：install] 错误 1 执行：cd ..chmod a+x glog-master -Rcd glog-mastermake &amp;&amp; make install okay,现在可以在Makefile文件中添加：-lglog 重新 make 还是会存在这个问题，笔者查阅各种资料，大部分指明在Makefile中加入 -ldl 即可，尝试后失败。最后发现是 Makefile 文件写的有问题，改成如[#5.2]即可. 4.3 运行示例make 成功后，会在当前目录生成 VulkanTest 可执行文件: 1./VulkanTest 结果如下: 五. 主要代码5.1 main.cpp123456789101112131415161718192021222324252627282930313233#define GLFW_INCLUDE_VULKAN#include &lt;GLFW/glfw3.h&gt;#define GLM_FORCE_RADIANS#define GLM_FORCE_DEPTH_ZERO_TO_ONE#include &lt;glm/vec4.hpp&gt;#include &lt;glm/mat4x4.hpp&gt;#include &lt;iostream&gt;int main() &#123; glfwInit(); glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API); GLFWwindow* window = glfwCreateWindow(800, 600, &quot;Vulkan window&quot;, nullptr, nullptr); uint32_t extensionCount = 0; vkEnumerateInstanceExtensionProperties(nullptr, &amp;extensionCount, nullptr); std::cout &lt;&lt; extensionCount &lt;&lt; &quot; extensions supported&quot; &lt;&lt; std::endl; glm::mat4 matrix; glm::vec4 vec; auto test = matrix * vec; while(!glfwWindowShouldClose(window)) &#123; glfwPollEvents(); &#125; glfwDestroyWindow(window); glfwTerminate(); return 0;&#125; 5.2 Makefile12345678910111213141516VULKAN_SDK_PATH = /home/jh/Program/vulkan/1.1.160.0/x86_64CFLAGS = -std=c++17 -I$(VULKAN_SDK_PATH)/includeLDFLAGS = -L$(VULKAN_SDK_PATH)/lib -lvulkan `pkg-config --static --libs glfw3`LDFLAGS += -ldlVulkanTest: main.cpp g++ $(CFLAGS) -o VulkanTest main.cpp $(LDFLAGS).PHONY: test cleantest: VulkanTest LD_LIBRARY_PATH=$(VULKAN_SDK_PATH)/lib VK_LAYER_PATH=$(VULKAN_SDK_PATH)/etc/explicit_layer.d ./VulkanTestclean:rm -f VulkanTest","categories":[{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]}],"categories":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/categories/Android/"},{"name":"Vsync","slug":"Android/Vsync","permalink":"https://swallowjoe.github.io/categories/Android/Vsync/"},{"name":"Looper","slug":"Android/Looper","permalink":"https://swallowjoe.github.io/categories/Android/Looper/"},{"name":"图像引擎","slug":"图像引擎","permalink":"https://swallowjoe.github.io/categories/%E5%9B%BE%E5%83%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://swallowjoe.github.io/tags/Android/"},{"name":"Vsync","slug":"Vsync","permalink":"https://swallowjoe.github.io/tags/Vsync/"},{"name":"Looper","slug":"Looper","permalink":"https://swallowjoe.github.io/tags/Looper/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://swallowjoe.github.io/tags/Vulkan/"}]}